{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142493e9",
   "metadata": {
    "id": "142493e9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(0)\n",
    "XLA_PYTHON_CLIENT_MEM_FRACTION=.499\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.integrate\n",
    "import time\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "import diffrax\n",
    "from jax.scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d59cf27-de74-4dbd-846d-ad7dcfd915bd",
   "metadata": {
    "id": "0d59cf27-de74-4dbd-846d-ad7dcfd915bd"
   },
   "outputs": [],
   "source": [
    "import jaxopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9P6weRnbrVZ8",
   "metadata": {
    "id": "9P6weRnbrVZ8"
   },
   "source": [
    "define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cb2960e-c42a-4f33-b134-0449f9b1bb1e",
   "metadata": {
    "id": "5cb2960e-c42a-4f33-b134-0449f9b1bb1e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SP_XY_Network:\n",
    "    \n",
    "    '''\n",
    "    This is aimed to implement a neural network consisting of XY oscillators with bias term.\n",
    "    We only define the network. The datat need to be got from outside.\n",
    "\n",
    "\n",
    "    Terms: \n",
    "        data: original data\n",
    "        phase: a configuration of every cells\n",
    "    \n",
    "    ===========================================\n",
    "    \n",
    "    Variables: \n",
    "    \n",
    "        Parameters: \n",
    "        \n",
    "            (set in __init__())\n",
    "            N: number of neurons (including input and output cells)\n",
    "            N_ev: maximum number of updating when looking for the equilibrium (free and with cost function)\n",
    "            N_epoch: maximum number of iteration when doing gradient descent for the weights\n",
    "            dt: time step for evolution to find equilibrium\n",
    "            tol_eq: tolerance for searcheng for the equilibrium\n",
    "            tol_W: tolerance for optimizing weights\n",
    "            N_input: number of input cells\n",
    "            N_output: number of output cells\n",
    "            \n",
    "            (set in get_training/test_data)\n",
    "            N_sample: number of samples for training\n",
    "            N_test: number of data sets fot validation test\n",
    "            \n",
    "            (set to be 0 in __init__ and updated when getting data)\n",
    "            wieghts_0: initiate value for couplings\n",
    "            phase_0: initiate configuration of all cells\n",
    "            \n",
    "        --------------------------\n",
    "            \n",
    "        External Data:\n",
    "        \n",
    "            (set in __init__())\n",
    "            input_index: indices of input cells\n",
    "            output_index: indices of output cells\n",
    "            \n",
    "            (set to be 0 in __init__(), get from get_xxx_data)\n",
    "            training_data: data to input cells for training\n",
    "            test_data: data to input cells for validation test\n",
    "            \n",
    "            training_target: data to output cells for training\n",
    "            target_output: desired output of output cells, used for validation tests\n",
    "            \n",
    "        ---------------------------\n",
    "        \n",
    "        Internal Variables:\n",
    "            \n",
    "            weights: weights, couplings between cells. N x N\n",
    "            bias: set to be [[h0,h1,h2...h_N],[psi_0,psi_1,psi_2...psi_N]]. \n",
    "            h: strength of local field\n",
    "            psi: direction of the local field \n",
    "            \n",
    "            equi_free: configuration at free equilibrium (all cells). Used for training\n",
    "            equi_nudge: configuration at total equilibrium (all cells). Used for training\n",
    "            test_result_phase: phase figuration for output in validation test (all cells)\n",
    "            test_result_data: data to output cells for validation test (output cells)\n",
    "            \n",
    "            input_data: ...\n",
    "            output_data: ...\n",
    "            \n",
    "            validity_training: ......\n",
    "            validity_test: ......\n",
    "            \n",
    "            -----------------------\n",
    "        \n",
    "        Functions: \n",
    "            \n",
    "            Setting the Network: \n",
    "                \n",
    "                __init__: set the number of cells, determine input and output cells, set all data to be zero\n",
    "                get_training_data(input_data, output_data): input the training data, prepare for the training stage\n",
    "                get_test_data(input_data, target_output): \n",
    "                random_state_initiation(): initiate the phase_0 and weights_0 randomly for the cells other than input and output cells\n",
    "                \n",
    "            -----------------------\n",
    "            \n",
    "            Calculation of Internal Properties:\n",
    "            \n",
    "                internal_energy(self,...): calculate the internal energy: E=1/2 \\sum_{ij} W_{ij} cos(\\phi_i-\\phi_j)\n",
    "                bias_term(self,...): calculate the bias term\n",
    "                internal_energy(self,...): internal_energy+bias_term\n",
    "                \n",
    "                sinlge_cost(self,phase,target_phase): calculate the cost function for single phases\n",
    "                total_energy(self,...): internal_energy+single_cost\n",
    "                cost_function(self, output, target_output): calculate cost function for outputs and target outputs\n",
    "                \n",
    "                internal_force: gradient of free term of internal energy\n",
    "                bias_force: gradient of bias term of internal energy\n",
    "                cost_force: ......\n",
    "                internal_force: internal_force+bias_force\n",
    "                total_force: internal_force+cost_force\n",
    "                \n",
    "                ...force45: used for 4th Runge Kutte method\n",
    "                \n",
    "                weights_gradient(self,...): calculate the gradient for training\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #------------- Setting the system ------------------\n",
    "    \n",
    "    def __init__(self, N, N_ev, dt, input_index, output_index):\n",
    "        \n",
    "        # Setting parameters from the input\n",
    "        self.N=N\n",
    "        self.N_ev=N_ev\n",
    "        self.dt=dt\n",
    "        self.input_index=input_index\n",
    "        self.output_index=output_index\n",
    "        \n",
    "        self.variable_index = np.delete(np.arange(0,N), input_index)\n",
    "        \n",
    "        self.N_input=len(input_index)\n",
    "        self.N_output=len(output_index)\n",
    "        self.T=self.dt*self.N_ev\n",
    "        \n",
    "        # Initalize all the other parameters. Default values are all zero\n",
    "        self.N_sample=0\n",
    "        self.N_test=0\n",
    "        \n",
    "        self.weights=np.zeros([N,N])\n",
    "        self.weights_0=np.zeros([N,N])\n",
    "\n",
    "        self.bias=np.zeros([2,N])\n",
    "        self.bias_0=np.zeros([2,N])\n",
    "        \n",
    "        self.beta=0.001\n",
    "        \n",
    "    #---------------------------Initiation Module: initiate the network---------------------------------\n",
    "        \n",
    "    def get_initial_state(self, weights_0,phase_0,bias_0):\n",
    "        # Set weights_0 and phase_0 manually\n",
    "        \n",
    "        self.weights_0=weights_0\n",
    "        self.weights=weights_0\n",
    "        self.phase_0=phase_0\n",
    "        self.bias=bias_0\n",
    "        self.bias_0=bias_0\n",
    "\n",
    "        \n",
    "    def random_state_initiation(self):\n",
    "        # Randomly set the weights and the phase_0 and bias\n",
    "        \n",
    "        # Set weights, ~N(0,1)\n",
    "        self.weights_0=np.random.randn(self.N, self.N)\n",
    "        for k in range(0,self.N):\n",
    "            self.weights_0[k,k]=0\n",
    "        self.weights_0=(self.weights_0+np.transpose(self.weights_0))/2\n",
    "        \n",
    "        self.weights=self.weights_0\n",
    "        \n",
    "        #Set bias, ~U(-0.5,0.5),U(-pi,pi)\n",
    "        bias=np.random.rand(2,self.N)\n",
    "        bias[0,:]=bias[0,:]-0.5\n",
    "        bias[1,:]=2*np.pi*(bias[1,:]-0.5)\n",
    "        self.bias_0=bias\n",
    "        self.bias=bias\n",
    "\n",
    "        # Set phase_0\n",
    "        self.phase_0=np.pi*np.random.rand(self.N)-np.pi/2*np.ones(self.N)\n",
    "\n",
    "\n",
    "        \n",
    "    def get_beta(self,beta):\n",
    "        \n",
    "        self.beta=beta\n",
    "        \n",
    "    #--------------------------Energy Module: Calculate the energy and cost functions--------------------------\n",
    "    ''' \n",
    "        Functions here are design to simultaneousle deal with a set of phase. \n",
    "        The value will be returned and used for other calculations such as assess the reliability of the system.  \n",
    "    '''\n",
    "    def dphase(self,phase):\n",
    "        # Calculate dphase[i,j]=phase[i]-phase[j]\n",
    "        \n",
    "        aux_ones=np.ones(self.N)\n",
    "        phase_mat=np.tensordot(aux_ones,phase,0)\n",
    "        phase_i=np.transpose(phase_mat,(1,2,0))\n",
    "        phase_j=np.transpose(phase_i,(0,2,1))\n",
    "        dphase=phase_i-phase_j\n",
    "        \n",
    "        return dphase\n",
    "\n",
    "    def internal_energy(self,W,phase):\n",
    "        # Calculate free term of internal energy for a set of phase\n",
    "        # !!Note: phase should be a 2-d tensor (N_sample (or others) x N_cell). For single phase, use [phase] as the input.\n",
    "        \n",
    "        dphase=self.dphase(phase)\n",
    "        E_list=0.5*np.sum(W*np.cos(dphase),(1,2))\n",
    "        \n",
    "        return E_list\n",
    "    \n",
    "    def bias_term(self,bias,phase):\n",
    "        # Calculate bias term of internal energy for a set of phase\n",
    "        # !!Note: phase should be a 2-d tensor (N_sample (or others) x N_cell). For single phase, use [phase] as the input. \n",
    "        \n",
    "        h=bias[0,:]\n",
    "        psi=bias[1,:]\n",
    "        N_data=np.shape(phase)[0]\n",
    "\n",
    "        aux_ones=np.ones(N_data)\n",
    "        psi_mat=np.tensordot(aux_ones,psi,0)\n",
    "        E_list=np.sum(h*np.cos(phase-psi_mat),axis=1)\n",
    "        return E_list\n",
    "    \n",
    "    def cost_function(self,phase,target):\n",
    "        # Calculate the cost function for each sample\n",
    "        # !!Note: phase should be a 2-d tensor (N_sample (or others) x N_cell). For single phase, use [phase] as the input.\n",
    "        \n",
    "        doutput=phase[:,self.output_index]-target\n",
    "        cost_mat=np.ones(np.shape(doutput))-np.cos(1*doutput)\n",
    "        cost_list=np.sum(cost_mat,1)\n",
    "        \n",
    "        return cost_list\n",
    "\n",
    "    def total_energy(self, W, bias, phase, target):\n",
    "\n",
    "        return self.internal_energy(W,phase)+self.bias_term(bias,phase)+self.cost_function(phase,target)\n",
    "        \n",
    "    #----------------------Force Module: Calculate the force induced by the energy for evolution----------------------------\n",
    "    \n",
    "    def internal_force(self,W,phase):\n",
    "        # Calculate the force induced by the free term of energy\n",
    "        # Here is a sign problem\n",
    "        \n",
    "        dphase=self.dphase(phase)\n",
    "        F_list=np.sum(W*np.sin(dphase),2)\n",
    "        return F_list\n",
    "    \n",
    "    def bias_force(self,bias,phase):\n",
    "        # Calculate the force induced by bias term \n",
    "        \n",
    "        h=bias[0,:]\n",
    "        psi=bias[1,:]\n",
    "        N_data=np.shape(phase)[0]\n",
    "        psi=np.tensordot(np.ones(N_data),psi,0)\n",
    "        F_list=-h*np.sin(phase-psi)\n",
    "        return F_list\n",
    "    \n",
    "    def cost_force(self, phase, target):\n",
    "        \n",
    "        #print(phase,target)\n",
    "        F=np.zeros(np.shape(phase))\n",
    "        F[:,self.output_index]=-np.sin(1*(phase[:,self.output_index]-target))\n",
    "        return F\n",
    "\n",
    "    def reg_force(self, phase, target):\n",
    "        \n",
    "        #print(phase,target)\n",
    "        F=np.zeros(np.shape(phase))\n",
    "        F[:,self.output_index]=-np.sin(0.5*(phase[:,self.output_index]-target))\n",
    "        return F\n",
    "    \n",
    "    def total_force(self, t, con_phase, W, bias, target, beta):\n",
    "        '''\n",
    "        Give the total force under different requirement: \n",
    "        bias_flag==0: no bias.\n",
    "        bias_flag==1: with bias.\n",
    "        '''\n",
    "        \n",
    "        Nh=int(len(con_phase)/self.N)\n",
    "        phase=np.reshape(con_phase,(Nh,self.N))\n",
    "\n",
    "        F0=self.internal_force(W,phase)\n",
    "        F1=self.bias_force(bias,phase)\n",
    "\n",
    "        F2 = beta*self.cost_force(phase,target)\n",
    "\n",
    "        F3 = beta*beta*self.reg_force(phase,target)\n",
    "        F = -F0+F1+F2+F3\n",
    "        F[:,self.input_index]=0\n",
    "        \n",
    "        return np.concatenate(F) \n",
    "        \n",
    "    \n",
    "    #-----------------------Evolution Module: Do evolutions and find the equilibrium ---------------------\n",
    "        \n",
    "\n",
    "    def run_network(self, W, bias, phase_0, target, beta, T):\n",
    "        \n",
    "        # Use scipy.integrate.solve_ivp\n",
    "        N_data = np.shape(phase_0)[0]\n",
    "        con_phase=np.concatenate(phase_0)\n",
    "        t_span=[0,T]\n",
    "        temp_model=sp.integrate.solve_ivp(self.total_force,t_span,con_phase,method='RK45',args=[W,bias,target,beta])\n",
    "        \n",
    "        L=len(temp_model.t)\n",
    "\n",
    "        phase = np.zeros([L, N_data, self.N])\n",
    "\n",
    "        for k in range(0,L): \n",
    "            phase[k,:,:] = np.reshape(temp_model.y[:,k], [N_data, self.N])\n",
    "        \n",
    "        #return temp_model.t, phase\n",
    "\n",
    "        return phase[L-1]\n",
    "\n",
    "\n",
    "    #------------------------Inverse Evolution-----------------------------\n",
    "\n",
    "    def inverse_force(self, t, con_phase, W, bias, target, beta):\n",
    "        \n",
    "        return -self.total_force(t, con_phase, W, bias, target, beta)\n",
    "\n",
    "    def inverse_evolution(self, W, bias, phase_0, phase_drift, target, T):\n",
    "\n",
    "        # Here phase_0 should be a stable equilibrium\n",
    "        # phase drift is some random perturbatio of the equilibrium so that the evolution could start. \n",
    "\n",
    "        N_data = np.shape(phase_0)[0]\n",
    "        phase_0 = phase_0 + phase_drift\n",
    "        con_phase=np.concatenate(phase_0)\n",
    "        t_span=[0,T]\n",
    "        temp_model=sp.integrate.solve_ivp(self.inverse_force,t_span,con_phase,method='RK45',args=[W,bias,target,0])\n",
    "        \n",
    "        L=len(temp_model.t)\n",
    "\n",
    "        phase = np.zeros([L, N_data, self.N])\n",
    "\n",
    "        for k in range(0,L): \n",
    "            phase[k,:,:] = np.reshape(temp_model.y[:,k], [N_data, self.N])\n",
    "        \n",
    "        return temp_model.t, phase\n",
    "\n",
    "\n",
    "    #=========================Calculate Exact Gradient==========================\n",
    "\n",
    "\n",
    "    def prod_phase(self,phase):\n",
    "        \n",
    "        N_data=np.shape(phase)[0]\n",
    "        \n",
    "        # Calculate the kroneck product prod_phase_ij = phase_i * phase_j\n",
    "        prod_phase=np.tensordot(phase,phase,0)\n",
    "        prod_phase=np.diagonal(prod_phase,axis1=0,axis2=2)\n",
    "        prod_phase=np.transpose(prod_phase,[2,0,1])\n",
    "        \n",
    "        return prod_phase\n",
    "    \n",
    "    def merge_weights(self,M_IS,M_SI,M_SS):\n",
    "        dim=len(np.shape(M_IS))\n",
    "        shape=np.shape(M_IS)[0:dim-2]\n",
    "\n",
    "        N_I=np.shape(M_IS)[dim-2]\n",
    "        N_S=np.shape(M_IS)[dim-1]\n",
    "        \n",
    "        M_II=np.zeros(np.concatenate((shape,[N_I,N_I]),axis=0))\n",
    "        M_up=np.concatenate((M_II,M_IS),axis=dim-1)\n",
    "        M_down=np.concatenate((M_SI,M_SS),axis=dim-1)\n",
    "        M=np.concatenate((M_up,M_down),axis=dim-2)\n",
    "        \n",
    "        return M\n",
    "        \n",
    "    \n",
    "    def destruct_weights(self,W):\n",
    "        \n",
    "        input_index=self.input_index\n",
    "        free_index=list(set(range(0,self.N))-set(input_index))\n",
    "        M_II=(W[...,input_index,:])[...,input_index]\n",
    "        M_IS=(W[...,input_index,:])[...,free_index]\n",
    "        M_SI=(W[...,free_index,:])[...,input_index]\n",
    "        M_SS=(W[...,free_index,:])[...,free_index]\n",
    "        \n",
    "        return M_II,M_IS,M_SI,M_SS\n",
    "        \n",
    "    def data_prod(self, A, B):\n",
    "        # This is to calculate M_nij=A_ni * B_nj. Here i and j can be either single or multiple index. \n",
    "        # We first do tensor product P_nimj=A_ni * B_mj. Then take the diagonal over index m and n. Then do the transpose. \n",
    "\n",
    "        dim_A=len(np.shape(A))\n",
    "        dim_B=len(np.shape(B))\n",
    "        M=np.tensordot(A,B,0)\n",
    "        T_prod=np.diagonal(M,axis1=0,axis2=dim_A)\n",
    "        prod=np.transpose(T_prod,[dim_A+dim_B-2]+list(range(0,dim_A+dim_B-2)))\n",
    "\n",
    "        return prod\n",
    "\n",
    "\n",
    "    def E_2nd_derivatives(self,W,bias,phase):\n",
    "        \n",
    "        # This calculate the dependence tensor to calculate the exact gradient. \n",
    "        \n",
    "        N_data=np.shape(phase)[0]\n",
    "        h=np.tensordot(np.ones(N_data),bias[0,:],0)\n",
    "        psi=np.tensordot(np.ones(N_data),bias[1,:],0)\n",
    "\n",
    "        prod_phase=self.prod_phase(phase)\n",
    "        diff_phase=self.dphase(phase)\n",
    "        Id=np.eye(self.N)\n",
    "        \n",
    "        # Calculate Hessian martix H and its inverse A=pinv(H). \n",
    "        # H_nij= (d^2E/(dx_i dx_j))_n = \\sum_k W_ik cos(x_ni - x_nk) + h_ni cos(x_ni-psi_ni) \\delta_ij - W_ij*cos(x_ni-x_nj)\n",
    "        M=W*np.cos(diff_phase)\n",
    "        B=h*np.cos(phase-psi)\n",
    "        G=np.sum(M,axis=2)+B\n",
    "        \n",
    "        H_diagonal=np.tensordot(G,Id,0)\n",
    "        H_diagonal=np.diagonal(H_diagonal,axis1=1,axis2=2)\n",
    "        H_diagonal=np.transpose(H_diagonal,[0,2,1])\n",
    "        \n",
    "        Hess=H_diagonal-M\n",
    "        #print(\"shape of A is: \", np.shape(A))\n",
    "\n",
    "        # Calculate half of matrix dEdW_nikl = d^2 E/(dx_i dW_kl)_n = (RW_nikl + RW_nilk)/2\n",
    "        RW=np.tensordot(np.sin(diff_phase),Id,0)\n",
    "        RW=np.diagonal(RW,axis1=2,axis2=4)\n",
    "        RW=np.transpose(RW,[0,2,1,3])/2\n",
    "        # Reconsturct the blocks to guarantee the boundary condition\n",
    "        '''\n",
    "        dExW_II, dExW_IS, dExW_SI, dExW_SS = self.destruct_weights(RW)\n",
    "        print(dExW_II, dExW_IS, dExW_SI, dExW_SS)\n",
    "        dExW_II = 0*dExW_II\n",
    "        '''\n",
    "        dExW = (RW + np.transpose(RW, [0,1,3,2]))/2\n",
    "        #dExW = self.merge_weights(dExW_IS, dExW_SI, dExW_SS)\n",
    "        #print(\"shape of RW is: \", np.shape(RW))\n",
    "        #print(\"RW= \\n\", RW)\n",
    "        #print(\"dExW= \\n\", dExW)\n",
    "        \n",
    "\n",
    "        # Calculate dExh_ik = d^2E/(dh_k dx_i) = sin(phi_k-psi_k) * delta_ik\n",
    "        Rh=-np.tensordot(np.sin(phase-psi),Id,0)\n",
    "        dExh=np.diagonal(Rh,axis1=1,axis2=3)\n",
    "        #dExh[:,:,self.input_index]=0\n",
    "        #dExh[:,self.input_index,:]=0\n",
    "        #print(\"shape of Rh is: \", np.shape(Rh))\n",
    "        \n",
    "        \n",
    "        # Calculate dExp_ik = d^2E/(dpsi_k dx_i) = -h_k * cos(phi_k-psi_k) * delta_ik\n",
    "        RP = -h*np.cos(phase-psi)\n",
    "        RP = np.tensordot(RP, Id, 0)\n",
    "        RP = np.diagonal(RP, axis1=1,axis2=2)\n",
    "        dExP = np.transpose(RP, [0,2,1])\n",
    "        #dExP[:,:,self.input_index]=0\n",
    "        #dExP[:,self.input_index,:]=0\n",
    "\n",
    "        return Hess, dExW, dExh, dExP\n",
    "\n",
    "\n",
    "    def x_dep(self,W,bias,phase):\n",
    "        # Calculate x dependence over internal parameters dx/dW, dx/dh, dx/dpsi\n",
    "        # dx_i/d W_k = sum_j inv(Hess)_ij dExW_k\n",
    "\n",
    "        Hess, dExW, dExh, dExP = self.E_2nd_derivatives(W,bias,phase) \n",
    "        # Calculate inverse Hessian: A=H^-1\n",
    "\n",
    "        A=np.linalg.pinv(Hess)\n",
    "        print(\"A=\",A)\n",
    "        A_II, A_IS, A_SI, A_SS = self.destruct_weights(A)\n",
    "        A=self.merge_weights(A_IS*0, A_SI*0, A_SS)\n",
    "        print(\"A=\",A)\n",
    "        dxdW=self.data_prod(A,dExW)\n",
    "        dxdW=np.diagonal(dxdW,axis1=2, axis2=3)\n",
    "        dxdW=np.sum(dxdW,axis=4)\n",
    "\n",
    "\n",
    "        dxdh=self.data_prod(A,dExh)\n",
    "        dxdh=np.diagonal(dxdh,axis1=2, axis2=3)\n",
    "        dxdh=np.sum(dxdh,axis=3)\n",
    "\n",
    "        dxdP=self.data_prod(A,dExP)\n",
    "        dxdP=np.diagonal(dxdP,axis1=2, axis2=3)\n",
    "        dxdP=np.sum(dxdP,axis=3)\n",
    "        \n",
    "        return dxdW, dxdh, dxdP\n",
    "    \n",
    "    def exact_gradient(self,W,h,phase,target):\n",
    "        \n",
    "        # This calculate the exact gradient of loss function over weights and bias with linear self-consistent function. \n",
    "        \n",
    "        # Calculate the naive gradient\n",
    "        NG=np.zeros(np.shape(phase))\n",
    "        NG[:,self.output_index] = -np.sin(phase[:,self.output_index]-target)\n",
    "        \n",
    "        dxdW, dxdh, dxdP = self.x_dep(W,h,phase)\n",
    "        \n",
    "        #print(\"shape of NG is: \", np.shape(NG))\n",
    "        \n",
    "        dLW=np.tensordot(NG,dxdW,(1,1))\n",
    "        dLW=np.diagonal(dLW,axis1=0,axis2=1)\n",
    "        dLW=np.transpose(dLW,[2,0,1])\n",
    "        \n",
    "        dLh=np.tensordot(NG,dxdh,(1,1))\n",
    "        dLh=np.diagonal(dLh,axis1=0,axis2=1)\n",
    "        dLh=np.transpose(dLh,[1,0])\n",
    "\n",
    "        dLP=np.tensordot(NG,dxdP,(1,1))\n",
    "        dLP=np.diagonal(dLP,axis1=0,axis2=1)\n",
    "        dLP=np.transpose(dLP,[1,0])\n",
    "        \n",
    "        return dLW,dLh,dLP\n",
    "    #----------------------Calculate the gradient of weights and bias throught EP-------------------------\n",
    "\n",
    "    def half_search(self, W, bias, internal_gradient, bias_gradient, study_rate):\n",
    "        \n",
    "        #print(study_rate)\n",
    "        \n",
    "        if study_rate<0.001:\n",
    "            W=W-study_rate*internal_gradient\n",
    "            bias=bias-study_rate*bias_gradient\n",
    "            return W, bias\n",
    "        else:\n",
    "            E0=np.sum(self.cost_function(self.equi_free,self.training_target))/self.N_sample\n",
    "\n",
    "            equi_temp1=self.find_free_equilibrium(W-study_rate/2*internal_gradient, bias-study_rate/2*bias_gradient, self.bias_flag, self.equi_free,self.dt)\n",
    "            E1=np.sum(self.cost_function(equi_temp1,self.training_target))/self.N_sample\n",
    "\n",
    "            equi_temp2=self.find_free_equilibrium(W-study_rate/2*internal_gradient, bias-study_rate/2*bias_gradient, self.bias_flag, equi_temp1,self.dt)\n",
    "            E2=np.sum(self.cost_function(equi_temp2,self.training_target))/self.N_sample\n",
    "\n",
    "            E_min=np.min([E0,E1,E2])\n",
    "            if E_min==E2: \n",
    "                W=W-study_rate*internal_gradient\n",
    "                bias=bias-study_rate*bias_gradient\n",
    "                return W, bias\n",
    "            elif E_min==E1:\n",
    "                W=W-study_rate/2*internal_gradient\n",
    "                bias=bias-study_rate/2*bias_gradient\n",
    "                return W, bias\n",
    "            else:\n",
    "                return self.half_search(W, bias, internal_gradient, bias_gradient, study_rate/2)\n",
    "        \n",
    "    \n",
    "    def train_with_exact_gradient(self):\n",
    "        \n",
    "        print(\"start training with exact gradient\")\n",
    "        \n",
    "        W=self.weights_0\n",
    "        bias=self.bias\n",
    "        self.equi_nudge=self.equi_free\n",
    "        target=self.training_target\n",
    "        N_data=np.shape(target)[0]\n",
    "        \n",
    "        old_cost=10*self.N*self.N\n",
    "        temp_cost=10\n",
    "        nr=0\n",
    "        self.validity_training=np.zeros(self.N_epoch)\n",
    "        \n",
    "        #print(W,bias,nr,np.abs((old_cost-temp_cost)/temp_cost))\n",
    "        \n",
    "        # Use this for one_d search\n",
    "            \n",
    "        while np.abs((old_cost-temp_cost)/temp_cost)>self.tol_W:\n",
    "            if nr==self.N_epoch: \n",
    "                break\n",
    "            #self.equi_free=self.find_free_equilibrium(W,bias,self.bias_flag,self.equi_nudge,self.dt)\n",
    "            \n",
    "            self.equi_free=self.find_nudge_equilibrium(W, bias, self.bias_flag, self.equi_nudge, self.training_target, 0, self.dt)\n",
    "            \n",
    "            gW,gh=self.exact_gradient(W,bias,self.equi_free,target)\n",
    "            internal_gradient=np.sum(gW,axis=0)/N_data\n",
    "            bias_gradient=np.sum(gh,axis=0)/N_data\n",
    "            \n",
    "            if self.bias_flag==0:\n",
    "                bias_gradient=np.zeros(np.shape(self.bias))\n",
    "                \n",
    "            W=W-self.study_rate*internal_gradient\n",
    "            bias=bias-self.study_rate*bias_gradient\n",
    "            \n",
    "            old_cost=temp_cost\n",
    "            temp_cost=self.cost_function(self.equi_free,self.training_target)\n",
    "            temp_cost=np.sqrt(np.sum(temp_cost)/self.N_sample/self.N_output)\n",
    "            self.validity_training[nr]=temp_cost\n",
    "            print(temp_cost,np.sum(np.abs(internal_gradient)),nr)\n",
    "            #print(nr)\n",
    "            \n",
    "            \n",
    "            print(\"EP gradient=\", internal_gradient,bias_gradient)\n",
    "            #print(\"Exact gradient=\", np.sum(gW,axis=0)/4,np.sum(gh,axis=0)/4)\n",
    "            nr=nr+1\n",
    "                \n",
    "        self.weights=W\n",
    "        self.bias=bias\n",
    "        \n",
    "        \n",
    "        \n",
    "    #-------------------------Test Module: test the ytrained network--------------------\n",
    "    \n",
    "    def initiate_test(self):\n",
    "        \n",
    "        '''\n",
    "        aux_ones=np.ones(self.N_test)\n",
    "        self.equi_test=np.tensordot(aux_ones, self.phase_0,0)\n",
    "        \n",
    "        '''\n",
    "        # For total irrelevant random initiate, use the code below:\n",
    "        \n",
    "        self.equi_test=2*np.pi*np.random.rand-np.pi*np.ones(np.shape(self.N_test,self.N))\n",
    "        \n",
    "        \n",
    "        self.equi_test[:,self.input_index]=self.test_data\n",
    "        \n",
    "    def validation_test(self):\n",
    "        \n",
    "        # Do the validity test. Run initiate_test() first.\n",
    "        # The validity is defined as \\sqrt((\\sum_test cost)/N)\n",
    "        \n",
    "        phase=self.find_free_equilibrium(self.weights,self.bias,self.bias_flag,self.equi_test,self.dt)\n",
    "        validity_list=self.cost_function(phase,self.target_output)\n",
    "        validity=np.sqrt(np.sum(validity_list)/self.N_test)\n",
    "        \n",
    "        self.validity_test=validity\n",
    "        self.equi_test=phase\n",
    "        \n",
    "    #------------------------Output Module: give the result for input------------------\n",
    "    \n",
    "    \n",
    "\n",
    "class SP_XY_masked_Layer_Network(SP_XY_Network):\n",
    "    def __init__(self, N, N_ev, dt, structure_list):\n",
    "        \n",
    "        # Setting parameters from the input\n",
    "        self.N=N\n",
    "        self.N_ev=N_ev\n",
    "        self.dt=dt\n",
    "        self.structure_list = structure_list\n",
    "        self.T=self.dt*self.N_ev\n",
    "        \n",
    "        # Initalize all the other parameters. Default values are all zero\n",
    "        self.N_sample=0\n",
    "        self.N_test=0\n",
    "        \n",
    "        self.weights=np.zeros([N,N])\n",
    "        self.weights_0=np.zeros([N,N])\n",
    "\n",
    "        self.bias=np.zeros([2,N])\n",
    "        self.bias_0=np.zeros([2,N])\n",
    "        \n",
    "        self.beta=0\n",
    "\n",
    "        #depth\n",
    "        self.L = len(structure_list)\n",
    "        self.mask = np.zeros([N,N])\n",
    "\n",
    "        for k in range(0, self.L-1):\n",
    "            self.mask[np.sum(structure_list[0:k]):np.sum(structure_list[0:k+1]), np.sum(structure_list[0:k+1]):np.sum(structure_list[0:k+2])] = 1\n",
    "\n",
    "        self.mask = self.mask + np.transpose(self.mask)\n",
    "        \n",
    "        self.split_points = np.zeros(len(structure_list)-1)\n",
    "        for k in range(0,len(structure_list)-1):\n",
    "            self.split_points[k] = np.sum(structure_list[0:k+1])\n",
    "            \n",
    "        self.split_points = np.asarray(self.split_points, dtype=np.int32)\n",
    "        \n",
    "    def random_state_initiation(self):\n",
    "        # Randomly set the weights and the phase_0 and bias\n",
    "        \n",
    "        # Set weights, ~N(0,1)\n",
    "        self.weights_0 = np.random.randn(self.N, self.N)\n",
    "        for k in range(0,self.N):\n",
    "            self.weights_0[k,k] = 0\n",
    "        self.weights_0 = self.mask * (self.weights_0+np.transpose(self.weights_0))/2\n",
    "        \n",
    "        self.weights = self.weights_0\n",
    "        \n",
    "        #Set bias, ~U(-0.5,0.5),U(-pi,pi)\n",
    "        bias = np.random.rand(2,self.N)\n",
    "        bias[0,:] = bias[0,:]-0.5\n",
    "        bias[1,:] = 2*np.pi*(bias[1,:]-0.5)\n",
    "        self.bias_0 = bias\n",
    "        self.bias = bias\n",
    "\n",
    "        # Set phase_0\n",
    "        self.phase_0 = np.pi*np.random.rand(self.N)-np.pi/2*np.ones(self.N)\n",
    "\n",
    "\n",
    "class SP_XY_Layer_Network(SP_XY_Network):\n",
    "    def __init__(self, N, N_ev, dt, structure_list):\n",
    "        \n",
    "        # Setting parameters from the input\n",
    "        self.N = N\n",
    "        self.N_ev = N_ev\n",
    "        self.dt = dt\n",
    "        self.structure_list = structure_list\n",
    "        self.T = self.dt * self.N_ev\n",
    "        \n",
    "        # Initalize all the other parameters. Default values are all zero\n",
    "        self.N_sample = 0\n",
    "        self.N_test = 0\n",
    "        \n",
    "        self.weights = np.zeros([N,N])\n",
    "        self.weights_0 = np.zeros([N,N])\n",
    "\n",
    "        self.bias = np.zeros([2,N])\n",
    "        self.bias_0 = np.zeros([2,N])\n",
    "        \n",
    "        self.beta = 0\n",
    "\n",
    "        #depth\n",
    "        self.L = structure_list.shape[0]\n",
    "        self.mask = np.zeros([N,N])\n",
    "        \n",
    "        self.split_points = np.zeros(self.L-1)\n",
    "        for k in range(0,self.L-1):\n",
    "            self.split_points[k] = np.sum(structure_list[0:k+1])\n",
    "            \n",
    "        self.split_points = np.asarray(self.split_points, dtype=np.int32)\n",
    "        \n",
    "        self.input_index = np.arange(0, self.split_points[0])\n",
    "        self.variable_index = np.arange(self.split_points[0], self.N)\n",
    "        self.output_index = np.arange(self.split_points[-1], self.N)\n",
    "        \n",
    "        self.WL = []\n",
    "        \n",
    "        self.structure_shape = []\n",
    "        for k in range(0,len(self.split_points)):\n",
    "            self.structure_shape.append(np.zeros(self.split_points[k]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def random_state_initiation(self):\n",
    "        # Randomly set the weights and the phase_0 and bias\n",
    "        \n",
    "        # Set weights, ~N(0,1)\n",
    "        self.WL = []\n",
    "        init_strength = 1\n",
    "        for k in range(0, len(self.structure_list)-1):\n",
    "            is_mid = 1 - (k==0) - (k==len(self.structure_list)-2)\n",
    "            init_W = init_strength * is_mid * np.eye(self.structure_list[k], self.structure_list[k+1])\n",
    "            #self.WL.append( init_W + 0.1*(1-is_mid)/np.sqrt(self.structure_list[k]+self.structure_list[k+1]) * np.random.randn(self.structure_list[k], self.structure_list[k+1]))\n",
    "            self.WL.append(1/np.sqrt(self.structure_list[k]+self.structure_list[k+1]) * np.random.randn(self.structure_list[k], self.structure_list[k+1]))\n",
    "            #self.WL.append(1/np.sqrt(self.N) * np.random.randn(self.structure_list[k], self.structure_list[k+1]))\n",
    "            \n",
    "        \n",
    "        #Set bias, ~U(-0.5,0.5),U(-pi,pi)\n",
    "        bias = np.asanyarray([0*np.random.randn(self.N), np.random.rand(self.N)])\n",
    "        #bias[0,:] = bias[0,:]-0.5\n",
    "        bias[1,:] = 2*np.pi*(bias[1,:]-0.5)\n",
    "        self.bias_0 = bias\n",
    "        self.bias = bias\n",
    "\n",
    "        # Set phase_0\n",
    "        self.phase_0 = np.pi * np.random.rand(self.N)-np.pi/2*np.ones(self.N)\n",
    "        \n",
    "        self.weights_0 = merge(self.WL, self.split_points, self.phase_0)\n",
    "        self.weights = self.weights_0\n",
    "        \n",
    "\n",
    "class SP_XY_SquareLattice_Network(SP_XY_Network):\n",
    "    def __init__(self, dimension, N_ev, dt, input_size, output_size):\n",
    "        self.architecture = 'Square Lattice'\n",
    "        \n",
    "        self.dimension = dimension\n",
    "        self.N = dimension[0]*dimension[1]\n",
    "        self.N_ev = N_ev\n",
    "        self.dt = dt\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.weights_0 = np.zeros([4] + dimension)\n",
    "\n",
    "        self.bias_0 = np.zeros([2] + dimension)\n",
    "        \n",
    "        self.input_index = np.arange(0, input_size)\n",
    "        self.variable_index = np.arange(input_size, self.N)\n",
    "        self.output_index = np.arange(self.N-output_size, self.N)\n",
    "        \n",
    "    def random_state_initiation(self):\n",
    "        weights_shape = self.weights_0.shape[1], self.weights_0.shape[2]\n",
    "        \n",
    "        W0 = np.random.randn(weights_shape[0]-1, weights_shape[1])\n",
    "        W1 = np.random.randn(weights_shape[0], weights_shape[1]-1)\n",
    "        \n",
    "        zero_row = np.zeros([1,weights_shape[1]])\n",
    "        zero_col = np.zeros([weights_shape[0],1])\n",
    "        \n",
    "        W_u = np.concatenate((W0, zero_row), axis=0)\n",
    "        W_d = np.concatenate((zero_row, W0), axis=0)\n",
    "        \n",
    "        W_l = np.concatenate((W1, zero_col), axis=1)\n",
    "        W_r = np.concatenate((zero_col, W1), axis=1)\n",
    "        \n",
    "        self.weights_0 = np.asarray([W_u, W_d, W_l, W_r])\n",
    "        self.bias_0[0,...] = np.random.randn(*self.dimension)\n",
    "        self.bias_0[1,...] = 2*np.pi*(np.random.rand(*self.dimension) - 0.5)\n",
    "        \n",
    "        \n",
    "\n",
    "#==============================================Matrix workshop=====================================================\n",
    "def merge(WL, split_points, phase):\n",
    "    N = phase.shape[0]\n",
    "    M = np.zeros([N,N])\n",
    "    \n",
    "    L = split_points.shape[0]\n",
    "    merge_points = jnp.zeros(L+2, dtype=jnp.int32)\n",
    "    merge_points = merge_points.at[1:L+1].set(split_points)\n",
    "    merge_points = merge_points.at[L+1].set(N)\n",
    "    merge_points = merge_points.at[0].set(0)\n",
    "    '''\n",
    "    merge_points = split_points.copy()\n",
    "    merge_points.append(N)\n",
    "    merge_points.insert(0, 0)\n",
    "    '''\n",
    "    \n",
    "    for k in range(0,L):\n",
    "        M[merge_points[k]:merge_points[k+1], merge_points[k+1]:merge_points[k+2]] = WL[k]\n",
    "    \n",
    "    M = M + np.transpose(M, [1,0])\n",
    "    \n",
    "    return M\n",
    "\n",
    "def split_M(W, split_points):\n",
    "    WL = []\n",
    "    N = W.shape[0]\n",
    "    \n",
    "    L = split_points.shape[0]\n",
    "    merge_points = jnp.zeros(L+2, dtype=jnp.int32)\n",
    "    merge_points = merge_points.at[1:L+1].set(split_points)\n",
    "    merge_points = merge_points.at[L+1].set(N)\n",
    "    merge_points = merge_points.at[0].set(0)\n",
    "    \n",
    "    '''\n",
    "    merge_points = split_points.copy()\n",
    "    merge_points.append(N)\n",
    "    merge_points.insert(0, 0)\n",
    "    '''\n",
    "    \n",
    "    for k in range(0,L):\n",
    "        WL.append(W[merge_points[k]:merge_points[k+1], merge_points[k+1]:merge_points[k+2]])\n",
    "    \n",
    "    return WL\n",
    "\n",
    "\n",
    "def flatten_weights(dimension, WL):\n",
    "    W_u, W_d, W_l, W_r = WL[0], WL[1], WL[2], WL[3]\n",
    "    n, m = dimension[0], dimension[1]\n",
    "    W_mat = np.zeros([n,m,n,m])\n",
    "    ind_n = np.arange(0,n)\n",
    "    ind_m = np.arange(0,m)\n",
    "    \n",
    "    for k in range(0, n-1):\n",
    "        for l in range(0, m):\n",
    "            W_mat[k,l,k+1,l] = W_u[k,l]\n",
    "            W_mat[k+1,l,k,l] = W_d[k+1,l]\n",
    "    \n",
    "    for k in range(0, n):\n",
    "        for l in range(0, m-1):\n",
    "            W_mat[k,l,k,l+1] = W_l[k,l]\n",
    "            W_mat[k,l+1,k,l] = W_r[k,l+1]\n",
    "    \n",
    "    W_mat = jnp.concatenate(W_mat)\n",
    "    W_mat = jnp.transpose(W_mat, [1,2,0])\n",
    "    W_mat = jnp.concatenate(W_mat)\n",
    "    W_mat = jnp.transpose(W_mat, [1,0])\n",
    "    \n",
    "    return W_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015da48e-2255-40d8-bb59-1cf732c3701b",
   "metadata": {
    "id": "015da48e-2255-40d8-bb59-1cf732c3701b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Functions for training the system with jax\n",
    "#---------------------------Energy Terms-------------------------\n",
    "from functools import partial\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "@jax.jit\n",
    "def internal_energy(W,phase):\n",
    "    # Calculate free term of internal energy for a set of phase\n",
    "    # !!Note: phase should be a 2-d tensor (N_sample (or others) x N_cell). For single phase, use [phase] as the input.\n",
    "        \n",
    "    dphase=cal_dphase(phase)\n",
    "    E_list= -0.5 * jnp.sum(W * jnp.cos(dphase), (1,2))\n",
    "        \n",
    "    return E_list\n",
    "\n",
    "@jax.jit   \n",
    "def bias_term(bias,phase):\n",
    "    # Calculate bias term of internal energy for a set of phase\n",
    "    # !!Note: phase should be a 2-d tensor (N_sample (or others) x N_cell). For single phase, use [phase] as the input. \n",
    "        \n",
    "    h = bias[0,:]\n",
    "    psi = bias[1,:]\n",
    "    N_data = jnp.shape(phase)[0]\n",
    "\n",
    "    aux_ones = jnp.ones(N_data)\n",
    "    psi_mat = jnp.tensordot(aux_ones,psi,0)\n",
    "    E_list = -jnp.sum( h*jnp.cos(phase-psi_mat), axis=1)\n",
    "    return E_list\n",
    "\n",
    "@jax.jit\n",
    "def cost_function(phase,target,output_index):\n",
    "    # Calculate the cost function for each sample\n",
    "    # !!Note: phase should be a 2-d tensor (N_sample (or others) x N_cell). For single phase, use [phase] as the input.\n",
    "        \n",
    "    output_phase = jnp.reshape(phase[:,output_index],jnp.shape(target))\n",
    "    \n",
    "    doutput = output_phase-target\n",
    "    cost_mat = jnp.ones(jnp.shape(doutput))-jnp.cos(doutput)\n",
    "    cost_list = jnp.mean(cost_mat,1)/2\n",
    "        \n",
    "    return cost_list\n",
    "\n",
    "@jax.jit\n",
    "def total_energy(W, bias, phase, target, output_index, beta):\n",
    "\n",
    "    return internal_energy(W,phase) + bias_term(bias,phase) + beta * cost_function(phase,target,output_index)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def qualitative_cost(phase, target, output_index, tol):\n",
    "    # Calculate the cost function for each sample\n",
    "    # !!Note: phase should be a 2-d tensor (N_sample (or others) x N_cell). For single phase, use [phase] as the input.\n",
    "        \n",
    "    output_phase = jnp.reshape(phase[:,output_index],jnp.shape(target))\n",
    "    \n",
    "    doutput = output_phase-target\n",
    "    cost_mat = jnp.ones(jnp.shape(doutput))-jnp.cos(doutput)\n",
    "    cost_list = jnp.sum( (cost_mat>tol)/2 )\n",
    "        \n",
    "    return cost_list\n",
    "\n",
    "#-------------------Run the system--------------------\n",
    "@jax.jit\n",
    "def cal_dphase(phase):\n",
    "    # Calculate dphase[i,j]=phase[i]-phase[j]\n",
    "    \n",
    "    N = jnp.shape(phase)[1]\n",
    "    aux_ones=jnp.ones(N)\n",
    "    phase_mat=jnp.tensordot(aux_ones,phase,0)\n",
    "    phase_i=jnp.transpose(phase_mat,(1,2,0))\n",
    "    phase_j=jnp.transpose(phase_i,(0,2,1))\n",
    "    dphase=phase_i-phase_j\n",
    "        \n",
    "    return dphase\n",
    "\n",
    "@jax.jit\n",
    "def total_force(t, con_phase, W, bias, target, beta, input_index, output_index):\n",
    "    \n",
    "    N = jnp.shape(W)[0]\n",
    "    N_data = int(jnp.shape(con_phase)[0]/N)\n",
    "    phase = jnp.reshape(con_phase,(N_data,N))\n",
    "\n",
    "    dphase = cal_dphase(phase)\n",
    "    F0 = jnp.sum(W*jnp.sin(dphase),2)\n",
    "\n",
    "    h=bias[0,:]\n",
    "    psi=bias[1,:]\n",
    "    N_data=jnp.shape(phase)[0]\n",
    "    psi=jnp.tensordot(jnp.ones(N_data),psi,0)\n",
    "    \n",
    "    #print(target)\n",
    "    #print(phase[:,output_index])\n",
    "\n",
    "    output_phase = jnp.reshape(phase[:,output_index],jnp.shape(target))\n",
    "\n",
    "    F1 = -h * jnp.sin(phase-psi)\n",
    "\n",
    "    F2 = jnp.zeros(np.shape(phase))\n",
    "    temp_F2 = -jnp.sin(output_phase-target)\n",
    "    F2 = F2.at[:,output_index].set( jnp.reshape(temp_F2, jnp.shape(output_phase[:,output_index])) )\n",
    "    \n",
    "    '''\n",
    "    F3 = jnp.zeros(np.shape(phase))\n",
    "    temp_F3 = -jnp.sin(0.5*(output_phase-target))\n",
    "    F3 = F3.at[:,output_index].set( jnp.reshape(temp_F3, jnp.shape(output_phase[:,output_index])) )\n",
    "    '''\n",
    "    \n",
    "    #F3 = F3.at[:,output_index].set( -jnp.sin(0.5*(output_phase-target)) )\n",
    "    \n",
    "    # Apply cross entropy loss functoin\n",
    "    \n",
    "    F3 = jnp.zeros(np.shape(phase))\n",
    "    M1 = -jnp.sin(output_phase-target)\n",
    "    M2 = (1.00)*jnp.ones(jnp.shape(output_phase)) + jnp.cos(output_phase-target)\n",
    "    F3 = F3.at[:,output_index].set( jnp.reshape(M1/M2, jnp.shape(output_phase[:,output_index])) )\n",
    "    \n",
    "\n",
    "    F = -F0 + F1 + 0*beta*F2 + beta*F3\n",
    "    F = F.at[:,input_index].set( jnp.zeros([N_data, len(input_index)]) )\n",
    "    \n",
    "        \n",
    "    return jnp.concatenate(F)\n",
    "\n",
    "@jax.jit\n",
    "def ode_total_force(con_phase, t, W, bias, target, beta, input_index, output_index):\n",
    "    return total_force(t, con_phase, W, bias, target, beta, input_index, output_index)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def run_network(phase_0, T, W, bias, target, beta, input_index, output_index):\n",
    "    # Set the initial conditions\n",
    "    N_data, N = jnp.shape(phase_0)\n",
    "    \n",
    "    con_phase_0 = jnp.concatenate(phase_0)\n",
    "    \n",
    "    \n",
    "    # Solve the equation with diffrax\n",
    "    # Set parameter for diffrax\n",
    "    rtol = 1e-8\n",
    "    atol = 1e-8\n",
    "    t_span = [0,T]\n",
    "    #saveat = np.linspace(*t_span, 10).tolist()\n",
    "    odefunc = lambda t, con_phase, args: total_force(t, con_phase, W, bias, target, beta, input_index, output_index)\n",
    "    eqs = diffrax.ODETerm(odefunc)\n",
    "    \n",
    "    # Use 4th Runge Kutta\n",
    "    #solver = diffrax.Tsit5()\n",
    "    \n",
    "    #Use 5th Kvaerno for stiff case\n",
    "    solver = diffrax.Kvaerno4()\n",
    "    \n",
    "    stepsize_controller = diffrax.PIDController(rtol=rtol, atol=atol)\n",
    "    #t = diffrax.SaveAt(ts=saveat)\n",
    "\n",
    "    # Solve the ODE\n",
    "    solution = diffrax.diffeqsolve(eqs, solver, t0=t_span[0], t1=t_span[1], dt0 = None, y0=con_phase_0,\n",
    "                               stepsize_controller=stepsize_controller, max_steps=1000000)\n",
    "    \n",
    "    L = len(solution.ts)\n",
    "    \n",
    "    phase = jnp.reshape(solution.ys[L-1,:], [N_data, N])\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    # Evolve with jaxode\n",
    "    \n",
    "    t_eval = jnp.array([0.,T])\n",
    "    solution = jaxode.odeint(ode_total_force, con_phase_0, t_eval, W, bias, target, beta, input_index, output_index, atol=1e-8, rtol=1e-8)\n",
    "    L = len(t_eval)\n",
    "    phase = jnp.reshape(solution[L-1,:], [N_data, N])\n",
    "    '''\n",
    "    \n",
    "    return phase\n",
    "\n",
    "\n",
    "#----------------------Calculate the gradient for the parameters-------------------------------\n",
    "@jax.jit\n",
    "def weights_gradient(equi_nudge, equi_free, beta):\n",
    "    # This is to calculate the contribution to weights gradient of free term in the internal energy\n",
    "    # The expression is: ( -cos(phi_i-phi_j)(\\beta!=0)+cos(phi_i-phi_j)(\\beta=0) )\n",
    "    nudge_dphase = cal_dphase(equi_nudge)\n",
    "    free_dphase = cal_dphase(equi_free)\n",
    "    gradient_list = (-jnp.cos(nudge_dphase)+jnp.cos(free_dphase))\n",
    "    #print(jnp.shape(gradient_list))\n",
    "    gradient = jnp.mean(gradient_list,axis=0)\n",
    "        \n",
    "    return gradient\n",
    "    \n",
    "\n",
    "@jax.jit\n",
    "def bias_gradient(equi_nudge, equi_free, bias, beta): \n",
    "    h = bias[0,:]\n",
    "    psi = bias[1,:]\n",
    "\n",
    "    h = jnp.tensordot(jnp.ones(jnp.shape(equi_free)[0]), h, 0)\n",
    "    psi = jnp.tensordot(jnp.ones(jnp.shape(equi_free)[0]), psi, 0)\n",
    "\n",
    "    g_h = jnp.cos(equi_free-psi) - jnp.cos(equi_nudge-psi)\n",
    "    g_psi = h*jnp.sin(equi_free-psi) - h*jnp.sin(equi_nudge-psi)\n",
    "\n",
    "    g_h = jnp.mean(g_h,axis=0)\n",
    "    g_psi = jnp.mean(g_psi,axis=0)\n",
    "\n",
    "    return jnp.asarray([g_h, g_psi])\n",
    "\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def paras_gradient(equi_nudge, equi_free, bias, beta): \n",
    "\n",
    "    return weights_gradient(equi_nudge, equi_free, beta) , bias_gradient(equi_nudge, equi_free, bias, beta)\n",
    "\n",
    "\n",
    "#---------------------------------Train the Network-------------------------------\n",
    "\n",
    "@jax.jit\n",
    "def weights_update(k, present_network):\n",
    "    # Initialize the system\n",
    "    phase_shape, W_0, bias_0, cost, training_data, training_target, training_paras, model_paras, ext_init_phase_0, random_flag = present_network\n",
    "    beta, study_rate = training_paras\n",
    "    N_ev, dt, input_index, output_index = model_paras\n",
    "    N_data = jnp.shape(training_data)[0]\n",
    "    N = jnp.shape(phase_shape)[1]\n",
    "    T = N_ev * dt\n",
    "    \n",
    "    W = W_0\n",
    "    bias = bias_0\n",
    "\n",
    "    input_tuple = input_index\n",
    "    output_tuple =  output_index\n",
    "\n",
    "    #initial phase\n",
    "    phase_0 = jnp.zeros([N_data, N]) + ext_init_phase_0 + random_flag*2*np.pi*(np.random.rand(N_data, N)-0.5)\n",
    "    phase_0 = jnp.asarray(phase_0)\n",
    "    phase_0 = phase_0.at[:,input_index].set(training_data)\n",
    "    \n",
    "    # Calculate the cost function\n",
    "    equi_zero = run_network(phase_0, T, W, bias, training_target, 0, input_index, output_index)\n",
    "    cost_list = cost_function(equi_zero, training_target, output_index)\n",
    "    cost = cost.at[k].set( jnp.sum(cost_list)/N_data )\n",
    "\n",
    "    # Update the weights\n",
    "    # Run the free and nudge phase for equilibrium propagation\n",
    "    # equi_free = run_network(phase_0, T, W, bias, training_target, -beta, input_index, output_index)\n",
    "    equi_nudge = run_network(equi_zero, T, W, bias, training_target, beta, input_index, output_index)\n",
    "        \n",
    "    # Calculate the gradient for the weights\n",
    "    gW, gh = paras_gradient(equi_nudge, equi_zero, bias, beta)\n",
    "\n",
    "    # Update the weights and bias\n",
    "    W = W_0 - study_rate/beta*gW\n",
    "    bias = bias_0 - study_rate/beta*gh\n",
    "\n",
    "    # Formulate the output\n",
    "\n",
    "\n",
    "    return phase_shape, W, bias, cost, training_data, training_target, training_paras, model_paras, ext_init_phase_0, random_flag\n",
    "\n",
    "@partial(jax.jit, static_argnames=['training_paras'])\n",
    "def jax_training(W_0, bias_0, training_data, training_target, training_paras, N_ev, dt, input_index, output_index, ext_init_phase_0=0, random_flag=False): \n",
    "    # Initialize the system\n",
    "    N_epoch, beta, study_rate = training_paras\n",
    "    #N, N_ev, dt, input_index, output_index = model_paras\n",
    "    N = jnp.shape(W_0)[0]\n",
    "    N_data = jnp.shape(training_data)[0]\n",
    "    T = N_ev * dt\n",
    "\n",
    "    cost = jnp.zeros(N_epoch)\n",
    "    phase_shape = jnp.zeros([N_data, N])\n",
    "\n",
    "    # Training with fori_loop\n",
    "    running_training_paras = (beta, study_rate)\n",
    "    running_model_paras = (N_ev, dt, input_index, output_index)\n",
    "    initial_network = (phase_shape, W_0, bias_0, cost, training_data, training_target, running_training_paras, running_model_paras, ext_init_phase_0, random_flag)\n",
    "    \n",
    "    #time the training\n",
    "    final_network = jax.lax.fori_loop(0, N_epoch, weights_update, initial_network)\n",
    "    \n",
    "    W = final_network[1]\n",
    "    bias = final_network[2]\n",
    "    cost = final_network[3]\n",
    "    \n",
    "\n",
    "    return cost, W, bias\n",
    "\n",
    "\n",
    "def train_network(W_0, bias_0, training_data, training_target, training_paras, model_paras, ext_init_phase_0=0, random_flag=False):\n",
    "    \n",
    "    # Initialize the system\n",
    "    N_epoch, beta, study_rate = training_paras\n",
    "    N, N_ev, dt, input_index, output_index = model_paras\n",
    "    N_data = jnp.shape(training_data)[0]\n",
    "    T = N_ev * dt\n",
    "    \n",
    "    input_tuple = tuple(input_index)\n",
    "    output_tuple = tuple(output_index)\n",
    "    \n",
    "    W = W_0\n",
    "    bias = bias_0\n",
    "\n",
    "    cost = jnp.zeros(N_epoch)\n",
    "    \n",
    "\n",
    "    # training\n",
    "    t1 = time.time()\n",
    "    for k in range(0,N_epoch):\n",
    "        phase_0 = jnp.zeros([N_data, N]) + ext_init_phase_0 + random_flag*2*np.pi*(np.random.rand(N_data, N)-0.5)\n",
    "        phase_0 = jnp.asarray(phase_0)\n",
    "        phase_0 = phase_0.at[:,input_index].set(training_data)\n",
    "        #print(phase_0)\n",
    "\n",
    "        #print(W.shape, phase_0.shape, bias.shape)\n",
    "\n",
    "        # Calculate the cost function\n",
    "        equi_zero = run_network(phase_0, T, W, bias, training_target, 0, input_index, output_index)\n",
    "        cost_list = cost_function(equi_zero, training_target, output_index)\n",
    "        cost = cost.at[k].set( jnp.sum(cost_list)/N_data )\n",
    "\n",
    "        # Run the free and nudge phase for equilibrium propagation\n",
    "        # equi_free = run_network(phase_0, T, W, bias, training_target, -beta, input_index, output_index)\n",
    "        equi_nudge = run_network(phase_0, T, W, bias, training_target, beta, input_index, output_index)\n",
    "        \n",
    "        #print(equi_zero, '\\n\\n', equi_free, '\\n\\n', equi_nudge, '\\n\\n')\n",
    "        \n",
    "        #print(\"equi_zero= \\n\", equi_zero, \"\\n equi_free= \\n\", equi_free, \"\\n equi_nudge= \\n\", equi_nudge)\n",
    "        \n",
    "        # Calculate the gradient for the weights\n",
    "        gW, gh = paras_gradient(equi_nudge, equi_zero, bias, beta)\n",
    "        \n",
    "        #print(gW,'\\n\\n', gh)\n",
    "        \n",
    "        # Update the weights and bias\n",
    "        W = W - study_rate*gW/beta\n",
    "        bias = bias - study_rate*gh/beta\n",
    "\n",
    "    t2 = time.time()\n",
    "    \n",
    "    '''\n",
    "    for k in range(0,N_epoch):\n",
    "        phase_0 = jnp.zeros([N_sample, N])\n",
    "        phase_0 = phase_0.at[:,input_index].set(training_data)\n",
    "\n",
    "        # Calculate the cost function\n",
    "        equi_zero = run_network(W, bias, phase_0, training_target, 0, T, input_tuple, output_tuple)\n",
    "        cost_list = total_energy(W, bias, equi_zero, training_target, output_index)\n",
    "        cost = cost.at[k].set( jnp.sum(cost_list)/N_sample )\n",
    "\n",
    "        # Run the free and nudge phase for equilibrium propagation\n",
    "        equi_free = run_network(W, bias, phase_0, training_target, -beta, T, input_tuple, output_tuple)\n",
    "        equi_nudge = run_network(W, bias, phase_0, training_target, beta, T, input_tuple, output_tuple)\n",
    "        \n",
    "        # Calculate the gradient for the weights\n",
    "        gW, gh = paras_gradient(equi_nudge, equi_free, bias, beta)\n",
    "\n",
    "        # Update the weights and bias\n",
    "        W = W - study_rate*gW\n",
    "        bias = bias - study_rate*gh\n",
    "    '''\n",
    "    \n",
    "    t3 = time.time()\n",
    "\n",
    "    return cost, W, bias\n",
    "\n",
    "#--------------------------Consecutive Training------------------------\n",
    "'''\n",
    "Training the net work with consecutive scheme: start from the equilibrium we get from the last epoch.\n",
    "'''\n",
    "\n",
    "@jax.jit\n",
    "def consecutive_weights_update(k, present_network):\n",
    "    # Initialize the system\n",
    "    phase_shape, W_0, bias_0, cost, training_data, training_target, training_paras, model_paras, ext_init_phase_0, random_flag = present_network\n",
    "    beta, study_rate = training_paras\n",
    "    N_ev, dt, input_index, output_index = model_paras\n",
    "    N_data= jnp.shape(training_data)[0]\n",
    "    N = jnp.shape(phase_shape)[1]\n",
    "    T = N_ev * dt\n",
    "    \n",
    "    W = W_0\n",
    "    bias = bias_0\n",
    "\n",
    "    input_tuple = input_index\n",
    "    output_tuple =  output_index\n",
    "\n",
    "    #initial phase\n",
    "    phase_0 = jnp.zeros([N_data, N]) + ext_init_phase_0 + random_flag*2*np.pi*(np.random.rand(N_data, N)-0.5)\n",
    "    phase_0 = jnp.asarray(phase_0)\n",
    "    phase_0 = phase_0.at[:,input_index].set(training_data)\n",
    "    \n",
    "    # Calculate the cost function\n",
    "    equi_zero = run_network(phase_0, T, W, bias, training_target, 0, input_index, output_index)\n",
    "    cost_list = cost_function(equi_zero, training_target, output_index)\n",
    "    cost = cost.at[k].set( jnp.sum(cost_list)/N_data )\n",
    "\n",
    "    # Update the weights\n",
    "    # Run the free and nudge phase for equilibrium propagation\n",
    "    # equi_free = run_network(phase_0, T, W, bias, training_target, -beta, input_index, output_index)\n",
    "    equi_nudge = run_network(equi_zero, T, W, bias, training_target, beta, input_index, output_index)\n",
    "        \n",
    "    # Calculate the gradient for the weights\n",
    "    gW, gh = paras_gradient(equi_nudge, equi_zero, bias, beta)\n",
    "\n",
    "    # Update the weights and bias\n",
    "    W = W_0 - study_rate/beta*gW\n",
    "    bias = bias_0 - study_rate/beta*gh\n",
    "\n",
    "    # Formulate the output\n",
    "\n",
    "\n",
    "    return phase_shape, W, bias, cost, training_data, training_target, training_paras, model_paras, equi_zero, False\n",
    "\n",
    "@partial(jax.jit, static_argnames=['training_paras'])\n",
    "def consecutive_jax_training(W_0, bias_0, training_data, training_target, training_paras, N_ev, dt, input_index, output_index, ext_init_phase_0=0, random_flag=False): \n",
    "    # Initialize the system\n",
    "    N_epoch, beta, study_rate = training_paras\n",
    "    #N, N_ev, dt, input_index, output_index = model_paras\n",
    "    N = jnp.shape(W_0)[0]\n",
    "    N_sample = jnp.shape(training_data)[0]\n",
    "    T = N_ev * dt\n",
    "\n",
    "    cost = jnp.zeros(N_epoch)\n",
    "    phase_shape = jnp.zeros([N_sample, N])\n",
    "\n",
    "    # Training with fori_loop\n",
    "    running_training_paras = (beta, study_rate)\n",
    "    running_model_paras = (N_ev, dt, input_index, output_index)\n",
    "    initial_network = (phase_shape, W_0, bias_0, cost, training_data, training_target, running_training_paras, running_model_paras, ext_init_phase_0, random_flag)\n",
    "    \n",
    "    #time the training\n",
    "    final_network = jax.lax.fori_loop(0, N_epoch, consecutive_weights_update, initial_network)\n",
    "    \n",
    "    W = final_network[1]\n",
    "    bias = final_network[2]\n",
    "    cost = final_network[3]\n",
    "    \n",
    "\n",
    "    return cost, W, bias\n",
    "\n",
    "\n",
    "#--------------------------Do multiple training in single function------------------------\n",
    "\n",
    "@jax.jit\n",
    "def loop_jax_training(k, task_paras):\n",
    "    # Here W_0 and bias_0 are lists of weights and bias that are generated outside the function\n",
    "    cost_list, cost, W_0, bias_0, training_data, training_target, training_paras, model_paras = task_paras\n",
    "    # Initialize the system\n",
    "    N_epoch, beta, study_rate = training_paras\n",
    "    N, N_ev, dt, input_index, output_index = model_paras\n",
    "    N_sample = jnp.shape(training_data)[0]\n",
    "    T = N_ev * dt\n",
    "    \n",
    "    N_cell = np.shape(W_0)[1]\n",
    "    phase_shape = jnp.zeros([N_sample, N_cell])\n",
    "\n",
    "    # Prepare parameters for training with fori_loop\n",
    "    running_training_paras = (beta, study_rate)\n",
    "    running_model_paras = (N_ev, dt, input_index, output_index)\n",
    "    initial_network = (phase_shape, W_0[k,:,:], bias_0[k,:,:], cost, training_data, training_target, running_training_paras, running_model_paras, 0, False)\n",
    "\n",
    "    #time the training\n",
    "    final_network = jax.lax.fori_loop(0, N_epoch, weights_update, initial_network)\n",
    "    \n",
    "    W = final_network[1]\n",
    "    bias = final_network[2]\n",
    "    new_cost = final_network[3]\n",
    "    \n",
    "    # Formulate the output\n",
    "    W_trained = W_0.at[k,:,:].set(W)\n",
    "    bias_trained = bias_0.at[k,:,:].set(bias)\n",
    "    cost_list = cost_list.at[k,:].set(new_cost)\n",
    "    \n",
    "    return cost_list, cost, W_trained, bias_trained, training_data, training_target, training_paras, model_paras\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnames=['training_paras'])\n",
    "def multiple_jax_training(N_run, cost_list_0, cost_0, W_0, bias_0, training_data, training_target, training_paras, model_paras):\n",
    "    task_paras = cost_list_0, cost_0[0], W_0, bias_0, training_data, training_target, training_paras, model_paras\n",
    "    \n",
    "    # time the training\n",
    "    trained_networks = jax.lax.fori_loop(0, N_run, loop_jax_training, task_paras)\n",
    "    \n",
    "    W_list = trained_networks[2]\n",
    "    bias_list = trained_networks[3]\n",
    "    cost_list = trained_networks[0]\n",
    "    \n",
    "    return cost_list\n",
    "\n",
    "#@partial(jax.jit, static_argnames=['training_paras', 'training_data', 'training_target'])\n",
    "def hv_jax_training(W_0, bias_0, training_data, training_target, training_paras, N_ev, dt, input_index, output_index, ext_init_phase_0=0, random_flag=False):\n",
    "    # Train many networks together in parallelism\n",
    "    \n",
    "    multiple_run_network = jax.vmap(run_network, (0,None,0,0,None,None,None,None))\n",
    "    multiple_paras_gradient = jax.vmap(paras_gradient, (0,0,0,None))\n",
    "    multiple_cost_function = jax.vmap(cost_function, (0,None,None))\n",
    "    \n",
    "    @jax.jit\n",
    "    def hv_update(k,present_network):\n",
    "        \n",
    "        W_0, bias_0, cost, training_data, training_target, training_paras, model_paras, ext_init_phase_0, random_flag = present_network\n",
    "        beta, study_rate = training_paras\n",
    "        N_ev, dt, input_index, output_index = model_paras\n",
    "        N_data = jnp.shape(training_data)[0]\n",
    "        N_run = jnp.shape(W_0)[0]\n",
    "        N = jnp.shape(W_0)[1]\n",
    "        T = N_ev * dt\n",
    "\n",
    "        #initial phase\n",
    "        phase_0 = jnp.zeros([N_data, N]) + ext_init_phase_0 + random_flag*2*np.pi*(np.random.rand(N_data, N)-0.5)\n",
    "        phase_0 = jnp.asarray(phase_0)\n",
    "        phase_0 = phase_0.at[:,input_index].set(training_data)\n",
    "        phase_0 = jnp.tensordot(jnp.ones(N_run), phase_0, 0)\n",
    "\n",
    "        # Calculate the cost function\n",
    "        equi_zero = multiple_run_network(phase_0, T, W_0[k], bias_0[k], training_target, 0, input_index, output_index)\n",
    "        cost_list = multiple_cost_function(equi_zero, training_target, output_index)\n",
    "        cost = cost.at[:,k].set( jnp.mean(cost_list, axis=1) )\n",
    "\n",
    "        # Update the weights\n",
    "        # Run the free and nudge phase for equilibrium propagation\n",
    "        # equi_free = run_network(phase_0, T, W, bias, training_target, -beta, input_index, output_index)\n",
    "        equi_nudge = multiple_run_network(equi_zero, T, W_0, bias_0, training_target, beta, input_index, output_index)\n",
    "\n",
    "        # Calculate the gradient for the weights\n",
    "        gW, gh = multiple_paras_gradient(equi_nudge, equi_zero, bias_0, beta)\n",
    "\n",
    "        # Update the weights and bias\n",
    "        W = W_0 - study_rate/beta*gW\n",
    "        bias = bias_0 - study_rate/beta*gh\n",
    "\n",
    "        return W, bias, cost, training_data, training_target, training_paras, model_paras, ext_init_phase_0, random_flag\n",
    "    \n",
    "    N_epoch, beta, study_rate = training_paras\n",
    "    N_run = jnp.shape(W_0)[0]\n",
    "    \n",
    "    cost_list_0 = jnp.zeros([N_run, N_epoch])\n",
    "    \n",
    "    running_training_paras = (beta, study_rate)\n",
    "    running_model_paras = (N_ev, dt, input_index, output_index)\n",
    "    \n",
    "    initial_networks = W_0, bias_0, cost_list_0, training_data, training_target, running_training_paras, running_model_paras, ext_init_phase_0, random_flag\n",
    "    \n",
    "    trained_networks = jax.lax.fori_loop(0, N_epoch, hv_update, initial_networks)\n",
    "    W, bias, cost = trained_networks[0], trained_networks[1], trained_networks[2]\n",
    "    \n",
    "    return cost, W, bias\n",
    "    \n",
    "vmul_jax_training = jax.vmap(jax_training, (0,0,None,None,(None,None,None),None,None,None,None,None,None))\n",
    "vmul_consecutive_jax_training = jax.vmap(consecutive_jax_training, (0,0,None,None,(None,None,None),None,None,None,None,None,None))\n",
    "\n",
    "\n",
    "#=================CPU training===================\n",
    "# Use scipy\n",
    "#------------------calculate equilibriums-------------------\n",
    "def sp_cal_dphase(phase):\n",
    "    # Calculate dphase[i,j]=phase[i]-phase[j]\n",
    "    \n",
    "    N = np.shape(phase)[1]\n",
    "    aux_ones=np.ones(N)\n",
    "    phase_mat=np.tensordot(aux_ones,phase,0)\n",
    "    phase_i=np.transpose(phase_mat,(1,2,0))\n",
    "    phase_j=np.transpose(phase_i,(0,2,1))\n",
    "    dphase=phase_i-phase_j\n",
    "        \n",
    "    return dphase\n",
    "\n",
    "def sp_total_force(t, con_phase, W, bias, target, beta, input_index, output_index):\n",
    "    \n",
    "    N = np.shape(W)[0]\n",
    "    Nh = int(np.shape(con_phase)[0]/N)\n",
    "    phase = np.reshape(con_phase,(Nh,N))\n",
    "\n",
    "    dphase = sp_cal_dphase(phase)\n",
    "    F0 = np.sum(W*np.sin(dphase),2)\n",
    "\n",
    "    h=bias[0,:]\n",
    "    psi=bias[1,:]\n",
    "    N_data=np.shape(phase)[0]\n",
    "    psi=np.tensordot(np.ones(N_data),psi,0)\n",
    "    \n",
    "    #print(target)\n",
    "    #print(phase[:,output_index])\n",
    "\n",
    "    output_phase = np.reshape(phase[:,output_index],np.shape(target))\n",
    "\n",
    "    F1 = -h * np.sin(phase-psi)\n",
    "\n",
    "    F2 = np.zeros(np.shape(phase))\n",
    "    temp_F2 = -np.sin(output_phase-target)\n",
    "    F2[:,output_index] = temp_F2\n",
    "    \n",
    "    '''\n",
    "    F3 = jnp.zeros(np.shape(phase))\n",
    "    temp_F3 = -jnp.sin(0.5*(output_phase-target))\n",
    "    F3 = F3.at[:,output_index].set( jnp.reshape(temp_F3, jnp.shape(output_phase[:,output_index])) )\n",
    "    '''\n",
    "    \n",
    "    #F3 = F3.at[:,output_index].set( -jnp.sin(0.5*(output_phase-target)) )\n",
    "    \n",
    "    # Apply cross entropy loss functoin\n",
    "    \n",
    "    F3 = np.zeros(np.shape(phase))\n",
    "    M1 = -np.sin(output_phase-target)\n",
    "    M2 = 1.0*np.ones(np.shape(output_phase)) + np.cos(output_phase-target)\n",
    "    F3[:,output_index] = M1/M2\n",
    "    \n",
    "\n",
    "    F = -F0 + F1 + 0*beta*F2 + beta*F3\n",
    "    F[:,input_index] = np.zeros([Nh, len(input_index)])\n",
    "    \n",
    "        \n",
    "    return np.concatenate(F)\n",
    "\n",
    "def sp_ode_total_force(con_phase, t, W, bias, target, beta, input_index, output_index):\n",
    "    return sp_total_force(t, con_phase, W, bias, target, beta, input_index, output_index)\n",
    "\n",
    "\n",
    "def sp_run_network(phase_0, T, W, bias, target, beta, input_index, output_index):\n",
    "    # Set the initial conditions\n",
    "    N_data, N = np.shape(phase_0)\n",
    "    \n",
    "    con_phase_0 = np.concatenate(phase_0)\n",
    "    \n",
    "    # Evolve with scipy\n",
    "    \n",
    "    t_span = np.array([0.,T])\n",
    "    \n",
    "    solution = scipy.integrate.solve_ivp(sp_total_force, t_span, con_phase_0, method='LSODA', args=[W, bias, target, beta, input_index, output_index], rtol = 1.4e-8, atol = 1.4e-8)\n",
    "    \n",
    "    L = len(solution.t)\n",
    "    con_phase = solution.y[:,L-1]\n",
    "    phase = np.reshape(con_phase, [N_data, N])\n",
    "\n",
    "    return phase\n",
    "\n",
    "\n",
    "#------------------------train the parameters-----------------------\n",
    "\n",
    "\n",
    "def sp_weights_gradient(equi_nudge, equi_free, beta):\n",
    "    # This is to calculate the contribution to weights gradient of free term in the internal energy\n",
    "    # The expression is: ( -cos(phi_i-phi_j)(\\beta!=0)+cos(phi_i-phi_j)(\\beta=0) )\n",
    "    N_data = np.shape(equi_free)[0]\n",
    "    nudge_dphase = sp_cal_dphase(equi_nudge)\n",
    "    free_dphase = sp_cal_dphase(equi_free)\n",
    "    gradient_list = (-np.cos(nudge_dphase)+np.cos(free_dphase))\n",
    "    #print(jnp.shape(gradient_list))\n",
    "    gradient = np.mean(gradient_list,axis=0)\n",
    "        \n",
    "    return gradient\n",
    "\n",
    "def sp_bias_gradient(equi_nudge, equi_free, bias, beta): \n",
    "        \n",
    "    N_sample = np.shape(equi_free)[0]\n",
    "    gradient = 0\n",
    "    h = bias[0,:]\n",
    "    psi = bias[1,:]\n",
    "\n",
    "    h = np.tensordot(np.ones(np.shape(equi_free)[0]), h, 0)\n",
    "    psi = np.tensordot(np.ones(np.shape(equi_free)[0]), psi, 0)\n",
    "\n",
    "    g_h = np.cos(equi_free-psi) - np.cos(equi_nudge-psi)\n",
    "    g_psi = h*np.sin(equi_free-psi) - h*np.sin(equi_nudge-psi)\n",
    "\n",
    "    g_h = np.mean(g_h,axis=0)\n",
    "    g_psi = np.mean(g_psi,axis=0)\n",
    "\n",
    "    return np.asarray([g_h, g_psi])\n",
    "\n",
    "\n",
    "def sp_paras_gradient(equi_nudge, equi_free, bias, beta): \n",
    "\n",
    "    return sp_weights_gradient(equi_nudge, equi_free, beta) , sp_bias_gradient(equi_nudge, equi_free, bias, beta)\n",
    "\n",
    "\n",
    "def sp_train_network(W_0, bias_0, training_data, training_target, training_paras, model_paras, ext_init_phase_0=0, random_flag=False):\n",
    "    \n",
    "    # Initialize the system\n",
    "    N_epoch, beta, study_rate = training_paras\n",
    "    N, N_ev, dt, input_index, output_index = model_paras\n",
    "    N_data = np.shape(training_data)[0]\n",
    "    T = N_ev * dt\n",
    "    \n",
    "    W = W_0\n",
    "    bias = bias_0\n",
    "\n",
    "    cost = np.zeros(N_epoch)\n",
    "    \n",
    "\n",
    "    # training\n",
    "    for k in range(0,N_epoch):\n",
    "        phase_0 = np.zeros([N_data, N]) + ext_init_phase_0 + random_flag*2*np.pi*(np.random.rand(N_data, N)-0.5)\n",
    "        phase_0[:,input_index] = training_data\n",
    "        #print(phase_0)\n",
    "\n",
    "        #print(W.shape, phase_0.shape, bias.shape)\n",
    "\n",
    "        # Calculate the cost function\n",
    "        equi_zero = sp_run_network(phase_0, T, W, bias, training_target, 0, input_index, output_index)\n",
    "        cost_list = cost_function(equi_zero, training_target, output_index)\n",
    "        cost[k] = np.sum(cost_list)/N_data\n",
    "\n",
    "        # Run the free and nudge phase for equilibrium propagation\n",
    "        equi_free = sp_run_network(phase_0, T, W, bias, training_target, -beta, input_index, output_index)\n",
    "        equi_nudge = sp_run_network(phase_0, T, W, bias, training_target, beta, input_index, output_index)\n",
    "        \n",
    "        #print(equi_zero, '\\n\\n', equi_free, '\\n\\n', equi_nudge, '\\n\\n')\n",
    "        \n",
    "        #print(\"equi_zero= \\n\", equi_zero, \"\\n equi_free= \\n\", equi_free, \"\\n equi_nudge= \\n\", equi_nudge)\n",
    "        \n",
    "        # Calculate the gradient for the weights\n",
    "        gW, gh = sp_paras_gradient(equi_nudge, equi_zero, bias, beta)\n",
    "        \n",
    "        #print(gW,'\\n\\n', gh)\n",
    "        \n",
    "        # Update the weights and bias\n",
    "        W = W - study_rate*gW/2/beta\n",
    "        bias = bias - study_rate*gh/2/beta\n",
    "\n",
    "    return cost, W, bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5609b186",
   "metadata": {
    "id": "5609b186",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the network with optimization methods in jaxopt\n",
    "\n",
    "@jax.jit\n",
    "def opt_total_energy(variable_phase, W, bias, input_data, target, input_index, variable_index, output_index, beta):\n",
    "    \n",
    "    N = jnp.shape(input_index)[0]+jnp.shape(variable_index)[0]\n",
    "    \n",
    "    #Set the phase to calculate the energy\n",
    "    phase = jnp.zeros(N)\n",
    "    phase = phase.at[input_index].set(input_data)\n",
    "\n",
    "    phase = phase.at[variable_index].set(variable_phase)\n",
    "    \n",
    "    #Calculate the internal energy\n",
    "    aux_ones = jnp.ones(N)\n",
    "    phase_mat = jnp.tensordot(aux_ones, phase, 0)\n",
    "    dphase = phase_mat - jnp.transpose(phase_mat, [1,0])\n",
    "    E_in = -0.5 * jnp.sum(W * jnp.cos(dphase))\n",
    "    \n",
    "    #Calculate the energy from the bias terms\n",
    "    h = bias[0,:]\n",
    "    psi = bias[1,:]\n",
    "    E_bias = -jnp.sum(h * jnp.cos(phase-psi))\n",
    "    \n",
    "    #Calculate the energy from the cost function\n",
    "    output_phase = phase[output_index]\n",
    "    E_cost = -jnp.sum(jnp.log(1 + jnp.cos(output_phase - target)))\n",
    "\n",
    "    return E_in + E_bias + beta * E_cost\n",
    "\n",
    "@jax.jit\n",
    "def opt_total_force(variable_phase, W, bias, input_data, target, input_index, variable_index, output_index, beta):\n",
    "    # This calculate the gradient of the energy (-F_total)\n",
    "    phase = jnp.concatenate((input_data, variable_phase))\n",
    "    phase_mat = jnp.asarray([phase])\n",
    "    dphase = -phase_mat + jnp.transpose(phase_mat,[1,0])\n",
    "    \n",
    "    output_phase = phase[output_index]\n",
    "    doutput = output_phase-target\n",
    "    \n",
    "    h=bias[0,:]\n",
    "    psi=bias[1,:]\n",
    "    N_cell = jnp.shape(phase)[0]\n",
    "    N_temp = N_cell - jnp.shape(output_index)[0]\n",
    "    \n",
    "    F0 = jnp.sum(W*jnp.sin(dphase),axis=1)\n",
    "    \n",
    "    F1 = -h * jnp.sin(phase-psi)\n",
    "    \n",
    "    \n",
    "    F3 = jnp.zeros(np.shape(phase))\n",
    "    M1 = -jnp.sin(output_phase-target)\n",
    "    M2 = (1.00)*jnp.ones(jnp.shape(output_phase)) + jnp.cos(output_phase-target)\n",
    "\n",
    "    #temp_F3 = -jnp.sin(0.5*(output_phase-target))\n",
    "    F3 = F3.at[output_index].set(M1/M2)\n",
    "    \n",
    "    \n",
    "    #F3 = F3.at[:,output_index].set( -jnp.sin(0.5*(output_phase-target)) )\n",
    "    \n",
    "    # Apply cross entropy loss function\n",
    "\n",
    "    F = -F0 + F1 + beta*F3\n",
    "    \n",
    "    F = F[variable_index]\n",
    "    \n",
    "    return F\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def opt_energy_with_grad(variable_phase, args):\n",
    "    W, bias, input_data, target, input_index, variable_index, output_index, beta = args\n",
    "    E = opt_total_energy(variable_phase, W, bias, input_data, target, input_index, variable_index, output_index, beta)\n",
    "    F = opt_total_force(variable_phase, W, bias, input_data, target, input_index, variable_index, output_index, beta)\n",
    "\n",
    "    return E, -F\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def single_opt_run_network(phase_0, W, bias, target, beta, input_index, variable_index, output_index):\n",
    "    #solver = jaxopt.LBFGS(opt_energy_with_grad, value_and_grad=True, maxiter=10000, tol=1e-8)\n",
    "    solver = jaxopt.GradientDescent(opt_energy_with_grad, value_and_grad=True, maxiter=10000, tol=1e-8)\n",
    "    input_data = phase_0[input_index]\n",
    "    variable_phase_0 = phase_0[variable_index]\n",
    "\n",
    "    args = W, bias, input_data, target, input_index, variable_index, output_index, beta\n",
    "\n",
    "    res = solver.run(variable_phase_0, args)\n",
    "\n",
    "    variable_phase = res.params\n",
    "    phase = jnp.concatenate((input_data, variable_phase))\n",
    "\n",
    "    return phase\n",
    "\n",
    "v_opt_run_network = jax.vmap(single_opt_run_network, (0,None,None,0,None,None,None,None))\n",
    "\n",
    "@jax.jit\n",
    "def opt_run_network_inloop(k, args):\n",
    "\n",
    "    phase, phase_0, W, bias, target, beta, input_index, variable_index, output_index = args\n",
    "\n",
    "    #solver = jaxopt.LBFGS(opt_energy_with_grad, value_and_grad=True, maxiter=10000, tol=1e-8)\n",
    "    solver = jaxopt.GradientDescent(opt_energy_with_grad, value_and_grad=True, maxiter=10000, tol=1e-8)\n",
    "    input_data = phase_0[k,input_index]\n",
    "    variable_phase_0 = phase_0[k,variable_index]\n",
    "\n",
    "    init_args = W, bias, input_data, target[k,:], input_index, variable_index, output_index, beta\n",
    "\n",
    "    res = solver.run(variable_phase_0, init_args)\n",
    "\n",
    "    variable_phase = res.params\n",
    "    phase = phase.at[k,:].set(jnp.concatenate((input_data, variable_phase)))\n",
    "\n",
    "    return phase, phase_0, W, bias, target, beta, input_index, variable_index, output_index\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def mul_opt_run_network(phase_0, W, bias, target, beta, input_index, variable_index, output_index):\n",
    "    phase = jnp.zeros(phase_0.shape)\n",
    "    N_data, N = phase_0.shape\n",
    "    args_0 = phase, phase_0, W, bias, target, beta, input_index, variable_index, output_index\n",
    "    result = jax.lax.fori_loop(0, N_data,opt_run_network_inloop, args_0)\n",
    "\n",
    "    phase = result[0]\n",
    "\n",
    "    return phase\n",
    "\n",
    "\n",
    "#==================Eequivalence verification=================\n",
    "# Verify the equivalence between opt and ode\n",
    "\n",
    "def dE_dparas(equi, bias):\n",
    "    # This is to calculate the contribution to weights gradient of free term in the internal energy\n",
    "    # The expression is: ( -cos(phi_i-phi_j)(\\beta!=0)+cos(phi_i-phi_j)(\\beta=0) )\n",
    "    equi_mat = jnp.asarray([equi])\n",
    "    free_dphase = equi_mat - jnp.transpose(equi_mat)\n",
    "    g_W = -jnp.cos(free_dphase)\n",
    "\n",
    "    #Calculate derivative over bias\n",
    "\n",
    "    h = bias[0,:]\n",
    "    psi = bias[1,:]\n",
    "\n",
    "    #h = jnp.tensordot(jnp.ones(jnp.shape(equi)[0]), h, 0)\n",
    "    #psi = jnp.tensordot(jnp.ones(jnp.shape(equi)[0]), psi, 0)\n",
    "\n",
    "    #print(equi.shape, psi.shape, h.shape)\n",
    "    g_h = -jnp.cos(equi-psi)\n",
    "    g_psi = -h*jnp.sin(equi-psi)\n",
    "        \n",
    "    return g_W, g_h, g_psi\n",
    "\n",
    "mul_dE_dparas = jax.vmap(dE_dparas, (0,None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42bc2edd",
   "metadata": {
    "id": "42bc2edd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def qualitative_cost(phase, target, output_index, tol):\n",
    "    # Calculate the cost function for each sample\n",
    "    # !!Note: phase should be a 2-d tensor (N_sample (or others) x N_cell). For single phase, use [phase] as the input.\n",
    "        \n",
    "    output_phase = jnp.reshape(phase[:,output_index],jnp.shape(target))\n",
    "    \n",
    "    doutput = output_phase-target\n",
    "    cost_mat = jnp.ones(jnp.shape(doutput))-jnp.cos(doutput)\n",
    "    cost_list = jnp.sum( (cost_mat>tol)/2 )\n",
    "        \n",
    "    return cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6209a601",
   "metadata": {
    "id": "6209a601",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Running and training XY network with layer structure\n",
    "#=======================================Running without layer structure=============================================\n",
    "@jax.jit\n",
    "def single_force(t, phase, W, bias, target, input_index, output_index, beta):\n",
    "    # This calculate the gradient of the energy (-F_total)\n",
    "    phase_mat = jnp.asarray([phase])\n",
    "    dphase = -phase_mat + jnp.transpose(phase_mat,[1,0])\n",
    "    \n",
    "    output_phase = phase[output_index]\n",
    "    \n",
    "    h=bias[0,:]\n",
    "    psi=bias[1,:]\n",
    "    N_cell = jnp.shape(phase)[0]\n",
    "    N_temp = N_cell - jnp.shape(output_index)[0]\n",
    "    \n",
    "    F0 = jnp.sum(W*jnp.sin(dphase),axis=1)\n",
    "    \n",
    "    F1 = -h * jnp.sin(phase-psi)\n",
    "    \n",
    "    \n",
    "    F3 = jnp.zeros(np.shape(phase))\n",
    "    M1 = -jnp.sin(output_phase-target)\n",
    "    M2 = (1.00)*jnp.ones(jnp.shape(output_phase)) + jnp.cos(output_phase-target)\n",
    "    F3 = F3.at[output_index].set(M1/M2)\n",
    "    \n",
    "    #temp_F3 = -jnp.sin(0.5*(output_phase-target))\n",
    "    #F3 = F3.at[output_index].set( -jnp.sin(0.5*(output_phase-target)) )\n",
    "    \n",
    "    # Apply cross entropy loss functoin\n",
    "\n",
    "    F = -F0 + F1 + beta*F3\n",
    "    \n",
    "    F = F.at[input_index].set(0)\n",
    "    \n",
    "    return F\n",
    "\n",
    "@jax.jit\n",
    "def single_run_network(phase_0, T, W, bias, target, beta, input_index, output_index):\n",
    "    # Solve the equation with diffrax\n",
    "    # Set parameter for diffrax\n",
    "    rtol = 1e-8\n",
    "    atol = 1e-8\n",
    "    t_span = [0,T]\n",
    "    #saveat = np.linspace(*t_span, 10).tolist()\n",
    "    odefunc = lambda t, phase, args: single_force(t, phase, W, bias, target, input_index, output_index, beta)\n",
    "    eqs = diffrax.ODETerm(odefunc)\n",
    "    \n",
    "    # Use 4th Runge Kutta\n",
    "    solver = diffrax.Tsit5()\n",
    "    \n",
    "    #Use 5th Kvaerno for stiff case\n",
    "    #solver = diffrax.Kvaerno4()\n",
    "    \n",
    "    stepsize_controller = diffrax.PIDController(rtol=rtol, atol=atol)\n",
    "    #t = diffrax.SaveAt(ts=saveat)\n",
    "\n",
    "    # Solve the ODE\n",
    "    solution = diffrax.diffeqsolve(eqs, solver, t0=t_span[0], t1=t_span[1], dt0 = None, y0=phase_0,\n",
    "                               stepsize_controller=stepsize_controller, max_steps=10000000)\n",
    "    \n",
    "    L = len(solution.ts)\n",
    "    \n",
    "    phase = solution.ys[L-1,:]\n",
    "\n",
    "    return phase\n",
    "\n",
    "@jax.jit\n",
    "def mul_run_network(phase_0, T, W, bias, target, beta, input_index, output_index):\n",
    "    odefunc = lambda phase_0, target: single_run_network(phase_0, T, W, bias, target, beta, input_index, output_index)\n",
    "    phase = jax.tree_map(odefunc, list(phase_0), list(target))\n",
    "    return jnp.asarray(phase)\n",
    "\n",
    "v_run_network = jax.vmap(single_run_network, (0,None,None,None,0,None,None,None))\n",
    "\n",
    "\n",
    "#=================================Calculate the energy and force with layered structure=================================\n",
    "@jax.jit\n",
    "def backward_force(phase, W, phase_next):\n",
    "    mphase = phase[None,:]\n",
    "    mphase_next = phase_next[None,:]\n",
    "    return jnp.sum(W * jnp.sin(jnp.transpose(mphase, [1,0]) - mphase_next), axis=1)\n",
    "\n",
    "@jax.jit\n",
    "def forward_force(phase, W, phase_last):\n",
    "    mphase = phase[None,:]\n",
    "    mphase_last = phase_last[None,:]\n",
    "    return jnp.sum(W * jnp.sin(mphase - jnp.transpose(mphase_last, [1,0])), axis=0)\n",
    "\n",
    "@jax.jit\n",
    "def add(x,y):\n",
    "    return x+y\n",
    "\n",
    "@jax.jit\n",
    "def layered_free_energy(phase1, W, phase2):\n",
    "    #This calculate the energy of free energy\n",
    "    '''\n",
    "        W: W^{n,n+1}, coupling between the n-th layer and n+1-th layer. n = 0,1,2...L, L+1 the number of layers in the network. \n",
    "        phase: phi^n\n",
    "        next_phase : phi^{n+1}\n",
    "    '''\n",
    "    \n",
    "    E = -jnp.sum( W * jnp.cos(jnp.transpose(phase1[None,:]) - phase2[None,:]) )\n",
    "    return E\n",
    "\n",
    "@jax.jit\n",
    "def layered_energy(phase, WL, bias, target, structure_shape, beta):\n",
    "    \n",
    "    # Calculate the free energy layer by layer\n",
    "    # Split and translate the phase according to layer structure\n",
    "    split_points = jax.tree_map(jnp.size, structure_shape)\n",
    "    phase_list = jnp.split(phase, split_points)\n",
    "    \n",
    "    phase1_list = phase_list.copy()\n",
    "    phase2_list = phase_list.copy()\n",
    "    \n",
    "    del phase1_list[-1]\n",
    "    del phase2_list[0]\n",
    "    \n",
    "    E0 = jnp.sum( jnp.asarray(jax.tree_map(layered_free_energy, phase1_list, WL, phase2_list)) )\n",
    "    \n",
    "    #Calculate the energy from the bias terms\n",
    "    h = bias[0,:]\n",
    "    psi = bias[1,:]\n",
    "    E_bias = -jnp.sum(h * jnp.cos(phase-psi))\n",
    "    \n",
    "    #Calculate the energy from the cost function\n",
    "    output_phase = phase_list[-1]\n",
    "    E_cost = -jnp.sum(jnp.log(1 + jnp.cos(output_phase - target)))\n",
    "    \n",
    "    #Sum all the terms and get the total energy\n",
    "    E = E0 + E_bias + beta * E_cost\n",
    "    \n",
    "    return E\n",
    "    \n",
    "\n",
    "@jax.jit\n",
    "def layered_force(t, phase, WL, bias, target, structure_shape, beta):\n",
    "    split_points = jax.tree_map(jnp.size, structure_shape)\n",
    "    phase_list = jnp.split(phase, split_points)\n",
    "    L = len(split_points)\n",
    "    phase_next_list = phase_list.copy()\n",
    "    phase_next_list.append(phase_list[len(phase_list)-1])\n",
    "    del phase_next_list[0]\n",
    "    \n",
    "    phase_last_list = phase_list.copy()\n",
    "    phase_last_list.insert(0, phase_list[0])\n",
    "    del phase_last_list[L+1]\n",
    "    \n",
    "    WL_back = WL.copy()\n",
    "    WL_back.append(jnp.zeros([phase_list[L].shape[0], phase_list[L].shape[0]]))\n",
    "    WL_forward = WL.copy()\n",
    "    WL_forward.insert(0, jnp.zeros([phase_list[0].shape[0], phase_list[0].shape[0]]))\n",
    "    \n",
    "    # Get the backward and forward force\n",
    "    BF = jax.tree_map(backward_force, phase_list, WL_back, phase_next_list)\n",
    "    FF = jax.tree_map(forward_force, phase_list, WL_forward, phase_last_list)\n",
    "    \n",
    "    FL0 = jax.tree_map(add, BF, FF)\n",
    "    FL0[0] = FL0[0]*0\n",
    "    \n",
    "    # Calculate bias force\n",
    "    \n",
    "    h=bias[0,:]\n",
    "    psi=bias[1,:]\n",
    "    F1 = -h * jnp.sin(phase-psi)\n",
    "    F1 = F1.at[0:split_points[0]].set(0)\n",
    "    \n",
    "    # Calculate the force from cost function\n",
    "    \n",
    "    output_phase = phase_list[len(phase_list)-1]\n",
    "    M1 = -jnp.sin(output_phase - target)\n",
    "    M2 = (1.00)*jnp.ones(jnp.shape(output_phase)) + jnp.cos(output_phase-target)\n",
    "    #F3 = -jnp.sin(0.5*(output_phase-target))\n",
    "    F3 = M1/M2\n",
    "    \n",
    "    FL0[len(FL0)-1] = FL0[len(FL0)-1] - beta*F3\n",
    "    F = -jnp.concatenate(FL0) + F1\n",
    "    \n",
    "    #Merge the forces together and concatenate\n",
    "    \n",
    "    \n",
    "    \n",
    "    #return phase_list, phase_last_list, phase_last_list, WL_forward, WL_back, BF, FF\n",
    "    return F\n",
    "    \n",
    "\n",
    "#=======================================Run network with solving ODE======================================\n",
    "@jax.jit\n",
    "def single_layer_run_network(phase_0, T, WL, bias, target, structure_shape, beta):\n",
    "    #run network with layer structure for single inputs\n",
    "    # Solve the equation with diffrax\n",
    "    # Set parameter for diffrax\n",
    "    rtol = 1e-8\n",
    "    atol = 1e-8\n",
    "    t_span = [0,T]\n",
    "    #saveat = np.linspace(*t_span, 10).tolist()\n",
    "    odefunc = lambda t, phase, args: layered_force(t, phase, WL, bias, target, structure_shape, beta)\n",
    "    eqs = diffrax.ODETerm(odefunc)\n",
    "    \n",
    "    # Use 4th Runge Kutta\n",
    "    solver = diffrax.Tsit5()\n",
    "    \n",
    "    #Use 5th Kvaerno for stiff case\n",
    "    #solver = diffrax.Kvaerno4()\n",
    "    \n",
    "    stepsize_controller = diffrax.PIDController(rtol=rtol, atol=atol)\n",
    "    #t = diffrax.SaveAt(ts=saveat)\n",
    "\n",
    "    # Solve the ODE\n",
    "    solution = diffrax.diffeqsolve(eqs, solver, t0=t_span[0], t1=t_span[1], dt0 = None, y0=phase_0,\n",
    "                               stepsize_controller=stepsize_controller, max_steps=10000000)\n",
    "    \n",
    "    L = len(solution.ts)\n",
    "    \n",
    "    phase = solution.ys[L-1,:]\n",
    "\n",
    "    return phase\n",
    "\n",
    "@jax.jit\n",
    "def ode_run_layered_network(phase_0, T, WL, bias, target, structure_shape, beta):\n",
    "    odefunc = lambda phase_0, target: single_layer_run_network(phase_0, T, WL, bias, target, structure_shape, beta)\n",
    "    phase = jax.tree_map(odefunc, list(phase_0), list(target))\n",
    "    return jnp.asarray(phase)\n",
    "\n",
    "@jax.jit\n",
    "def v_run_layered_network(phase_0, T, WL, bias, target, structure_shape, beta):\n",
    "    odefunc = lambda phase_0, target: single_layer_run_network(phase_0, T, WL, bias, target, structure_shape, beta)\n",
    "    phase = jax.vmap(odefunc, (0,0))(phase_0, target)\n",
    "    return phase\n",
    "\n",
    "\n",
    "#==========================================Running with optimization methods==========================================\n",
    "\n",
    "@jax.jit\n",
    "def opt_layered_energy(variable_phase, input_data, WL, bias, target, structure_shape, beta):\n",
    "    phase = jnp.concatenate((input_data, variable_phase), axis=0)\n",
    "    return layered_energy(phase, WL, bias, target, structure_shape, beta)\n",
    "\n",
    "@jax.jit\n",
    "def opt_layered_grad(variable_phase, input_data, WL, bias, target, structure_shape, beta):\n",
    "    variable_index = jnp.arange(structure_shape[0].shape[0], bias.shape[1])\n",
    "    phase = jnp.concatenate((input_data, variable_phase), axis=0)\n",
    "    grad_E = -layered_force(0, phase, WL, bias, target, structure_shape, beta)[variable_index]\n",
    "    \n",
    "    return grad_E\n",
    "\n",
    "@jax.jit\n",
    "def opt_layered_energy_with_grad(variable_phase, input_data, WL, bias, target, structure_shape, beta):\n",
    "    E = opt_layered_energy(variable_phase, input_data, WL, bias, target, structure_shape, beta)\n",
    "    grad_E = opt_layered_grad(variable_phase, input_data, WL, bias, target, structure_shape, beta)\n",
    "    \n",
    "    return E, grad_E\n",
    "\n",
    "@jax.jit\n",
    "def opt_single_layer_run_network(phase_0, WL, bias, target, structure_shape, beta):\n",
    "    # Run network for single set of input data\n",
    "    \n",
    "    input_index = jnp.arange(0, structure_shape[0].shape[0])\n",
    "    variable_index = jnp.arange(structure_shape[0].shape[0], bias.shape[1])\n",
    "    \n",
    "    input_data = phase_0[input_index]\n",
    "    variable_phase_0 = phase_0[variable_index]\n",
    "    \n",
    "    optfunc = lambda variable_phase: opt_layered_energy_with_grad(variable_phase, input_data, WL, bias, target, structure_shape, beta)\n",
    "    \n",
    "    solver = jaxopt.LBFGS(optfunc, value_and_grad=True, maxiter=10000, tol=1e-6)\n",
    "    #solver = jaxopt.GradientDescent(optfunc, value_and_grad=True, maxiter=10000, tol=1e-6)\n",
    "\n",
    "    #args = input_data, WL, bias, target, structure_shape, beta\n",
    "\n",
    "    res = solver.run(variable_phase_0)\n",
    "\n",
    "    variable_phase = res.params\n",
    "    phase = jnp.concatenate((input_data, variable_phase))\n",
    "\n",
    "    return phase\n",
    "\n",
    "@jax.jit\n",
    "def opt_run_layered_network(phase_0, WL, bias, target, structure_shape, beta):\n",
    "    runfunc = lambda phase_0, target: opt_single_layer_run_network(phase_0, WL, bias, target, structure_shape, beta)\n",
    "    phase = jax.tree_map(runfunc, list(phase_0), list(target))\n",
    "    return jnp.asarray(phase)\n",
    "\n",
    "@jax.jit\n",
    "def v_opt_run_layered_network(phase_0, WL, bias, target, structure_shape, beta):\n",
    "    runfunc = lambda phase_0, target: opt_single_layer_run_network(phase_0, WL, bias, target, structure_shape, beta)\n",
    "    phase = jax.vmap(runfunc, (0,0))(phase_0, target)\n",
    "    return phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "825ae807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#====================================Run the network with lattice structure=================================\n",
    "#--------------------------------------Evolve the system with solving ODE-----------------------------------\n",
    "# moving phase\n",
    "@jax.jit\n",
    "def move_phase(phase):\n",
    "    phase_shape = phase.shape\n",
    "    sub_row = jnp.zeros([1, phase_shape[1]])\n",
    "    sub_col = jnp.zeros([phase_shape[0], 1])\n",
    "    \n",
    "    #phase_u[i,j] = phase[i+1, j]\n",
    "    phase_u = jnp.delete(phase, 0, axis=0)\n",
    "    #phase_u = jnp.concatenate((phase_u, sub_row), axis=0)\n",
    "    phase_u = jnp.concatenate((phase_u, phase[-1,:][None,:]), axis=0)\n",
    "    \n",
    "    #phase_d[i,j] = phase[i-1, j]\n",
    "    phase_d = jnp.delete(phase, phase_shape[0]-1, axis=0)\n",
    "    #phase_d = jnp.concatenate((sub_row, phase_d), axis=0)\n",
    "    phase_d = jnp.concatenate((phase[0,:][None,:], phase_d), axis=0)\n",
    "    \n",
    "    #phase_l[i,j] = phase[i, j+1]\n",
    "    phase_l = jnp.delete(phase, 0, axis=1)\n",
    "    #phase_l = jnp.concatenate((phase_l, sub_col), axis=1)\n",
    "    phase_l = jnp.concatenate((phase_l, phase[:,-1][:,None]), axis=1)\n",
    "    \n",
    "    #phase_r[i,j] = phase[i, j-1]\n",
    "    phase_r = jnp.delete(phase, phase_shape[1]-1, axis=1)\n",
    "    #phase_r = jnp.concatenate((sub_col, phase_r), axis=1)\n",
    "    phase_r = jnp.concatenate((phase[:,0][:,None], phase_r), axis=1)\n",
    "    \n",
    "    return jnp.asarray([phase_u, phase_d, phase_l, phase_r])\n",
    "\n",
    "@jax.jit\n",
    "def SquareLattice_total_energy(flatten_phase, W, bias, target, lattice_form, input_index, output_index, beta):\n",
    "    dimension = lattice_form.shape\n",
    "    phase = jnp.reshape(flatten_phase, dimension)\n",
    "    moved_phase = move_phase(phase)\n",
    "    E0 = -0.5 * jnp.sum(W * jnp.cos(phase - moved_phase))\n",
    "    \n",
    "    h = bias[0,...]\n",
    "    psi = bias[1,...]\n",
    "    \n",
    "    E1 = -jnp.sum(h*jnp.cos(phase - psi))\n",
    "    \n",
    "    phase_out = phase[-1, output_index]\n",
    "    E2 = -jnp.sum(jnp.log(1+jnp.cos(phase_out - target)))\n",
    "    \n",
    "    return E0 + E1 + beta*E2\n",
    "\n",
    "@jax.jit\n",
    "def SquareLattice_total_force(t, flatten_phase, W, bias, target, lattice_form, input_index, output_index, beta):\n",
    "    dimension = lattice_form.shape\n",
    "    phase = jnp.reshape(flatten_phase, dimension)\n",
    "    moved_phase = move_phase(phase)\n",
    "    F0 = -jnp.sum(W * jnp.sin(phase - moved_phase), axis=0)\n",
    "    \n",
    "    h = bias[0,...]\n",
    "    psi = bias[1,...]\n",
    "    F1 = -h*jnp.sin(phase - psi)\n",
    "    \n",
    "    row_output_index = output_index - (dimension[0]-1)*dimension[1]\n",
    "    \n",
    "    phase_out = phase[-1, row_output_index]\n",
    "    F2 = -jnp.sin(phase_out - target)/(1+jnp.cos(phase_out - target))\n",
    "    \n",
    "    F = F1 + F0\n",
    "    \n",
    "    F_out = F[-1, row_output_index]\n",
    "    F_out = F_out + F2*beta\n",
    "    \n",
    "    F = F.at[0,input_index].set(0)\n",
    "    F = F.at[-1,row_output_index].set(F_out)\n",
    "    \n",
    "    return jnp.concatenate(F)\n",
    "\n",
    "@jax.jit\n",
    "def single_lattice_run_network(phase_0, T, W, bias, target, lattice_form, input_index, output_index, beta):\n",
    "    #run network with layer structure for single inputs\n",
    "    # Solve the equation with diffrax\n",
    "\n",
    "    # Transform a lattice configuration into a sequence\n",
    "    flatten_phase_0 = jnp.concatenate(phase_0)\n",
    "    \n",
    "    # Set parameter for diffrax\n",
    "    rtol = 1e-8\n",
    "    atol = 1e-8\n",
    "    t_span = [0,T]\n",
    "    #saveat = np.linspace(*t_span, 10).tolist()\n",
    "    odefunc = lambda t, flatten_phase_0, args: SquareLattice_total_force(t, flatten_phase_0, W, bias, target, lattice_form, input_index, output_index, beta)\n",
    "    eqs = diffrax.ODETerm(odefunc)\n",
    "    \n",
    "    # Use 4th Runge Kutta\n",
    "    solver = diffrax.Tsit5()\n",
    "    \n",
    "    #Use 5th Kvaerno for stiff case\n",
    "    #solver = diffrax.Kvaerno4()\n",
    "    \n",
    "    stepsize_controller = diffrax.PIDController(rtol=rtol, atol=atol)\n",
    "    #t = diffrax.SaveAt(ts=saveat)\n",
    "    \n",
    "    # Solve the ODE\n",
    "    solution = diffrax.diffeqsolve(eqs, solver, t0=t_span[0], t1=t_span[1], dt0 = None, y0=flatten_phase_0,\n",
    "                               stepsize_controller=stepsize_controller, max_steps=10000000)\n",
    "    \n",
    "    L = len(solution.ts)\n",
    "    \n",
    "    phase = solution.ys[L-1,:].reshape(phase_0.shape)\n",
    "\n",
    "    return phase\n",
    "\n",
    "v_run_lattice_network = jax.vmap(single_lattice_run_network, (0,None,None,None,0,None,None,None,None))\n",
    "\n",
    "#--------------------------------------Evolve the system via optimization methods-----------------------------------------\n",
    "@jax.jit\n",
    "def opt_SquareLattice_total_energy(variable_phase, input_data, W, bias, target, lattice_form, input_index, output_index, beta):\n",
    "    flatten_phase = jnp.concatenate((input_data, variable_phase), axis=0)\n",
    "    E = SquareLattice_total_energy(flatten_phase, W, bias, target, lattice_form, input_index, output_index, beta)\n",
    "    return E\n",
    "\n",
    "@jax.jit\n",
    "def opt_SquareLattice_total_force(variable_phase, input_data, W, bias, target, lattice_form, input_index, output_index, beta):\n",
    "    flatten_phase = jnp.concatenate((input_data, variable_phase), axis=0)\n",
    "    F = SquareLattice_total_force(0, flatten_phase, W, bias, target, lattice_form, input_index, output_index, beta)\n",
    "    return F\n",
    "\n",
    "@jax.jit\n",
    "def opt_SquareLattice_energy_with_grad(variable_phase, input_data, W, bias, target, lattice_form, input_index, variable_index, output_index, beta):\n",
    "    flatten_phase = jnp.concatenate((input_data, variable_phase), axis=0)\n",
    "    E = SquareLattice_total_energy(flatten_phase, W, bias, target, lattice_form, input_index, output_index, beta)\n",
    "    F = SquareLattice_total_force(0, flatten_phase, W, bias, target, lattice_form, input_index, output_index, beta)\n",
    "    return E, -F[variable_index]\n",
    "\n",
    "@jax.jit\n",
    "def opt_single_SquareLattice_run_network(phase_0, W, bias, target, lattice_form, input_index, variable_index, output_index, beta):\n",
    "    # Run network for single set of input data\n",
    "    \n",
    "    flatten_phase_0 = jnp.concatenate(phase_0)\n",
    "    \n",
    "    input_data = flatten_phase_0[input_index]\n",
    "    variable_phase_0 = flatten_phase_0[variable_index]\n",
    "    \n",
    "    optfunc = lambda variable_phase: opt_SquareLattice_energy_with_grad(variable_phase, input_data, W, bias, target, lattice_form, input_index, variable_index, output_index, beta)\n",
    "    \n",
    "    solver = jaxopt.LBFGS(optfunc, value_and_grad=True, maxiter=10000, tol=1e-6)\n",
    "    #solver = jaxopt.GradientDescent(optfunc, value_and_grad=True, maxiter=10000, tol=1e-6)\n",
    "\n",
    "    #args = input_data, WL, bias, target, structure_shape, beta\n",
    "\n",
    "    res = solver.run(variable_phase_0)\n",
    "\n",
    "    variable_phase = res.params\n",
    "    flatten_phase = jnp.concatenate((input_data, variable_phase))\n",
    "\n",
    "    return jnp.reshape(flatten_phase, phase_0.shape)\n",
    "\n",
    "v_opt_run_SquareLattice_network = jax.vmap(opt_single_SquareLattice_run_network, (0,None,None,0,None,None,None,None,None))\n",
    "\n",
    "#-----------------------------------Calculate the gradient over parameters with EP-----------------------------------------\n",
    "\n",
    "@jax.jit\n",
    "def single_SquareLattice_paras_gradient(equi_nudge, equi_zero, bias, beta):\n",
    "    #Here equi_nudge and equi_zero are all configuration for a single phase\n",
    "    # Calculate gradient over weights\n",
    "    moved_equi_zero = move_phase(equi_zero)\n",
    "    dp_zero = equi_zero - moved_equi_zero\n",
    "    \n",
    "    moved_equi_nudge = move_phase(equi_nudge)\n",
    "    dp_nudge = equi_nudge - moved_equi_nudge\n",
    "    \n",
    "    gW = -jnp.cos(dp_nudge) + jnp.cos(dp_zero)\n",
    "    \n",
    "    # Calculate the gradient over bias\n",
    "    h = bias[0,...]\n",
    "    psi = bias[1,...]\n",
    "    \n",
    "    g_h = jnp.cos(equi_zero-psi) - jnp.cos(equi_nudge-psi)\n",
    "    g_psi = h*jnp.sin(equi_zero-psi) - h*jnp.sin(equi_nudge-psi)\n",
    "    \n",
    "    gh = jnp.asarray([g_h, g_psi])\n",
    "    \n",
    "    return gW/beta, gh/beta\n",
    "\n",
    "\n",
    "def SquareLattice_EP_param_gradient(W_0, bias_0, phase_0, training_target, training_paras, model_paras):\n",
    "    \n",
    "    beta, study_rate = training_paras\n",
    "    N_ev, dt, lattice_form, input_index, variable_index, output_index = model_paras\n",
    "    \n",
    "    N = bias_0.shape[1]\n",
    "    T = N_ev * dt\n",
    "    \n",
    "    batch_size = phase_0.shape[0]\n",
    "    batch_training_target = jnp.tensordot(jnp.ones(batch_size), training_target, 0)\n",
    "    \n",
    "    #equi_zero = v_opt_run_SquareLattice_network(jnp.concatenate(phase_0), W_0, bias_0, jnp.concatenate(batch_training_target), lattice_form, input_index, variable_index, output_index, 0)\n",
    "    #equi_nudge = v_opt_run_SquareLattice_network(equi_zero, W_0, bias_0, jnp.concatenate(batch_training_target), lattice_form, input_index, variable_index, output_index, beta)\n",
    "\n",
    "    equi_zero = v_run_lattice_network(jnp.concatenate(phase_0), T, W_0, bias_0, jnp.concatenate(batch_training_target), lattice_form, input_index, output_index, 0)\n",
    "    equi_nudge = v_run_lattice_network(equi_zero, T, W_0, bias_0, jnp.concatenate(batch_training_target), lattice_form, input_index, output_index, beta)\n",
    "\n",
    "    gWL, ghL = jax.vmap(single_SquareLattice_paras_gradient, in_axes=(0,0,None,None), out_axes=(0,0))(equi_nudge, equi_zero, bias_0, beta)\n",
    "    \n",
    "    gW = jnp.mean(gWL, axis=0)\n",
    "    gh = jnp.mean(ghL, axis=0)\n",
    "    \n",
    "    flatten_equi_zero = jax.vmap(jnp.concatenate)(equi_zero)\n",
    "    \n",
    "    cost_list = cost_function(flatten_equi_zero, jnp.concatenate(batch_training_target), output_index)\n",
    "    cost = jnp.mean(cost_list)\n",
    "    \n",
    "    q_cost_list = qualitative_cost(flatten_equi_zero, jnp.concatenate(batch_training_target), output_index, 0.1)\n",
    "    q_cost = jnp.mean(q_cost_list)\n",
    "    \n",
    "    return gW, gh, cost, q_cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbcf2537",
   "metadata": {
    "id": "fbcf2537",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#===================Step by step update===============\n",
    "#--------------------------------initialize the state------------------------------\n",
    "def init_phase(N, input_index, input_data, batch_size):\n",
    "    N_data = input_data.shape[0]\n",
    "    phase_0 = np.random.rand(np.max([batch_size,1]), N_data, N) * (batch_size > 0)\n",
    "    phase_0[:,:,input_index] = input_data\n",
    "    \n",
    "    return jnp.asarray(phase_0)\n",
    "\n",
    "@jax.jit\n",
    "def jax_init_phase(phase_form, input_index, input_data, batch_form, seed, from_zero=False):\n",
    "    N_data, N = phase_form.shape\n",
    "    batch_size = batch_form.shape[0]\n",
    "    \n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    \n",
    "    BS = jnp.max(jnp.asarray([1, batch_size]))\n",
    "    phase_0 = jax.random.uniform(key, shape=(batch_size, N_data, N), dtype=jnp.float64, minval=-jnp.pi, maxval=jnp.pi) * (1 - (from_zero==True))\n",
    "    #phase_0 = np.random.rand(np.max([batch_size,1]), N_data, N) * (batch_size > 0)\n",
    "    phase_0 = phase_0.at[:,:,input_index].set(input_data)\n",
    "    \n",
    "    return jnp.asarray(phase_0)\n",
    "\n",
    "@jax.jit\n",
    "def lattice_jax_init_phase(phase_form, input_index, input_data, batch_form, seed, from_zero=False):\n",
    "    N_data, *dim = phase_form.shape\n",
    "    batch_size = batch_form.shape[0]\n",
    "    \n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    \n",
    "    phase_0 = jax.random.uniform(key, shape=(batch_size, N_data, *dim), dtype=jnp.float64, minval=-jnp.pi, maxval=jnp.pi) * (1 - (from_zero==True))\n",
    "    #phase_0 = np.random.rand(np.max([batch_size,1]), N_data, N) * (batch_size > 0)\n",
    "    phase_0 = phase_0.at[...,0,input_index].set(input_data)\n",
    "    \n",
    "    return jnp.asarray(phase_0)\n",
    "\n",
    "#------------------------------Calculate gradient with EP---------------------------\n",
    "@jax.jit\n",
    "def EP_param_gradient(W_0, bias_0, phase_0, training_target, training_paras, model_paras):\n",
    "    # Initialize the system\n",
    "    #batch_size = batch_form.shape[0]\n",
    "    beta, study_rate = training_paras\n",
    "    N_ev, dt, input_index, variable_index, output_index = model_paras\n",
    "    N_data = jnp.shape(training_target)[0]\n",
    "    N = jnp.shape(W_0)[1]\n",
    "    T = N_ev * dt\n",
    "    \n",
    "    #initial phase\n",
    "    batch_size = phase_0.shape[0]\n",
    "    batch_training_target = jnp.tensordot(jnp.ones(batch_size), training_target, 0)\n",
    "    \n",
    "    '''\n",
    "    equi_zero = v_opt_run_network(jnp.concatenate(phase_0), W_0, bias_0, jnp.concatenate(batch_training_target), 0, input_index, variable_index, output_index)\n",
    "    if jnp.isnan(jnp.sum(equi_zero)):\n",
    "        equi_zero = v_run_network(jnp.concatenate(phase_0), T, W_0, bias_0, jnp.concatenate(batch_training_target), 0, input_index, output_index)\n",
    "        \n",
    "    equi_nudge = v_opt_run_network(equi_zero, W_0, bias_0, jnp.concatenate(batch_training_target), beta, input_index, variable_index, output_index)\n",
    "    if jnp.isnan(jnp.sum(equi_nudge)):\n",
    "        equi_nudge = v_run_network(equi_zero, T, W_0, bias_0, jnp.concatenate(batch_training_target), beta, input_index, output_index)\n",
    "    '''\n",
    "    equi_zero = v_run_network(jnp.concatenate(phase_0), T, W_0, bias_0, jnp.concatenate(batch_training_target), 0, input_index, output_index)\n",
    "    equi_nudge = v_run_network(equi_zero, T, W_0, bias_0, jnp.concatenate(batch_training_target), beta, input_index, output_index)\n",
    "    \n",
    "    cost_list = cost_function(equi_zero, jnp.concatenate(batch_training_target), output_index)\n",
    "    cost = jnp.mean(cost_list)\n",
    "    \n",
    "    q_cost_list = qualitative_cost(equi_zero, jnp.concatenate(batch_training_target), output_index, 0.1)\n",
    "    q_cost = jnp.mean(q_cost_list)\n",
    "    \n",
    "    gW, gh = paras_gradient(equi_nudge, equi_zero, bias_0, beta)\n",
    "    \n",
    "\n",
    "    # Formulate the output\n",
    "\n",
    "\n",
    "    return gW/beta, gh/beta, cost, q_cost\n",
    "\n",
    "#---------------------------------Calculate parameter gradient with EP with layer structure-------------------------------\n",
    "@jax.jit\n",
    "def weights_deriv_in_layer(phase1, phase2):\n",
    "    gW_loc = -jnp.cos(phase2[:,None,:] - jnp.transpose(phase1[:,None,:], axes=(0,2,1)))\n",
    "    \n",
    "    return jnp.mean(gW_loc, axis=0)\n",
    "\n",
    "@jax.jit\n",
    "def weights_gradient_in_layer(phase, structure_shape):\n",
    "    split_points = jax.tree_map(jnp.size, structure_shape)\n",
    "    phase_list = jnp.split(phase, split_points, axis=1)\n",
    "    \n",
    "    phase1_list = phase_list.copy()\n",
    "    phase2_list = phase_list.copy()\n",
    "    \n",
    "    del phase1_list[-1]\n",
    "    del phase2_list[0]\n",
    "    \n",
    "    return jax.tree_map(weights_deriv_in_layer, phase1_list, phase2_list)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def layer_paras_gradient(equi_nudge, equi_zero, bias, structure_shape, beta):\n",
    "    \n",
    "    #Calculate gradient over bias\n",
    "    h = bias[0,:]\n",
    "    psi = bias[1,:]\n",
    "\n",
    "    h = jnp.tensordot(jnp.ones(jnp.shape(equi_zero)[0]), h, 0)\n",
    "    psi = jnp.tensordot(jnp.ones(jnp.shape(equi_zero)[0]), psi, 0)\n",
    "\n",
    "    g_h = jnp.cos(equi_zero-psi) - jnp.cos(equi_nudge-psi)\n",
    "    g_psi = h*jnp.sin(equi_zero-psi) - h*jnp.sin(equi_nudge-psi)\n",
    "\n",
    "    g_h = jnp.mean(g_h,axis=0)\n",
    "    g_psi = jnp.mean(g_psi,axis=0)\n",
    "\n",
    "    gh = jnp.asarray([g_h, g_psi])\n",
    "    \n",
    "    #Calculate gradient over coupling\n",
    "    dEdW_zero = weights_gradient_in_layer(equi_zero, structure_shape)\n",
    "    dEdW_nudge = weights_gradient_in_layer(equi_nudge, structure_shape)\n",
    "    \n",
    "    gW = jax.tree_map(jnp.subtract, dEdW_nudge, dEdW_zero)\n",
    "    \n",
    "    return jax.tree_map(jnp.divide, gW, list(beta*jnp.ones(len(gW)))), gh/beta\n",
    "        \n",
    "\n",
    "#@jax.jit\n",
    "def layered_EP_param_gradient(WL_0, bias_0, phase_0, training_target, training_paras, model_paras):\n",
    "    # Initialize the system\n",
    "    beta, study_rate = training_paras\n",
    "    N_ev, dt, structure_list, split_points, structure_shape = model_paras\n",
    "    \n",
    "    N = bias_0.shape[1]\n",
    "    T = N_ev * dt\n",
    "\n",
    "    input_index = jnp.arange(0, structure_shape[0].shape[0])\n",
    "    output_index = jnp.arange(structure_shape[-1].shape[0], N)\n",
    "    \n",
    "    batch_size = phase_0.shape[0]\n",
    "    batch_training_target = jnp.tensordot(jnp.ones(batch_size), training_target, 0)\n",
    "    \n",
    "    '''\n",
    "    equi_zero = v_opt_run_layered_network(jnp.concatenate(phase_0), WL_0, bias_0, jnp.concatenate(batch_training_target), structure_shape, 0)\n",
    "    if jnp.isnan(jnp.sum(equi_zero)):\n",
    "        equi_zero = v_run_layered_network(jnp.concatenate(phase_0), T, WL_0, bias_0, jnp.concatenate(batch_training_target), structure_shape, 0)\n",
    "    \n",
    "    equi_nudge = v_opt_run_layered_network(equi_zero, WL_0, bias_0, jnp.concatenate(batch_training_target), structure_shape, beta)\n",
    "    if jnp.isnan(jnp.sum(equi_nudge)):\n",
    "        equi_nudge = v_run_layered_network(equi_zero, T, WL_0, bias_0, jnp.concatenate(batch_training_target), structure_shape, beta)\n",
    "\n",
    "    # Calculate the loss\n",
    "    cost_list = cost_function(equi_zero, batch_training_target, output_index)\n",
    "    cost = jnp.mean(cost_list)\n",
    "\n",
    "    q_cost_list = qualitative_cost(equi_zero, batch_training_target, output_index, tol=0.1)\n",
    "    q_cost = jnp.mean(q_cost_list)\n",
    "\n",
    "    '''\n",
    "    zero_run = lambda phase_0: v_run_layered_network(phase_0, T, WL_0, bias_0, training_target, structure_shape, 0)\n",
    "    equi_zero = jax.vmap(zero_run,(0))(phase_0)\n",
    "    \n",
    "    nudge_run = lambda phase_0: v_run_layered_network(phase_0, T, WL_0, bias_0, training_target, structure_shape, beta)\n",
    "    equi_nudge = jax.vmap(nudge_run, (0))(equi_zero)\n",
    "    \n",
    "    cost_list = jax.vmap(cost_function, (0, None, None))(equi_zero, training_target, output_index)\n",
    "    cost = jnp.mean(cost_list)\n",
    "\n",
    "    q_cost_list = jax.vmap(qualitative_cost, (0, None, None, None))(equi_zero, training_target, output_index, 0.1)\n",
    "    q_cost = jnp.mean(q_cost_list)\n",
    "    \n",
    "    equi_zero = jnp.concatenate(equi_zero, axis=0)\n",
    "    equi_nudge = jnp.concatenate(equi_nudge, axis=0)\n",
    "    \n",
    "\n",
    "    gW, gh = layer_paras_gradient(equi_nudge, equi_zero, bias_0, structure_shape, beta)\n",
    "    \n",
    "    return gW, gh, cost, q_cost\n",
    "\n",
    "\n",
    "#---------------------------------Calculate parameter gradient with EP with lattice structure-------------------------------\n",
    "\n",
    "    \n",
    "#================================Optimization Updates========================\n",
    "@jax.jit\n",
    "def gradient_descent_update(paras, g_paras, study_rate_0, itr_time, study_rate_f=0.001, decay=0):\n",
    "    eta = jnp.max(jnp.asarray([study_rate_0 - decay*itr_time, study_rate_f]))\n",
    "    return paras - eta * g_paras\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def Adam_update(paras, g_paras, study_rate_0, itr_time, s, r, r1=0.9, r2=0.999, delta=1e-8, study_rate_f=0.001, decay=0):\n",
    "    '''\n",
    "        This implement update stem with adam. s is the momentum, r realizes adaptive stepsize\n",
    "    '''\n",
    "    # Get the study rate, epsilon in Adam\n",
    "    eta = jnp.max(jnp.asarray([study_rate_0 - decay*itr_time, study_rate_f]))\n",
    "    \n",
    "    new_t = itr_time + 1\n",
    "    new_s = r1 * s + (1 - r1) * g_paras\n",
    "    new_r = r2 * r + (1 - r2) * (g_paras * g_paras)\n",
    "    \n",
    "    s_hat = new_s/(1 - r1**new_t)\n",
    "    r_hat = new_r/(1 - r2**new_t)\n",
    "    \n",
    "    new_paras = paras - eta * s_hat / (delta + jnp.sqrt(r_hat))\n",
    "    \n",
    "    return new_paras, new_s, new_r\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c3fa1e",
   "metadata": {},
   "source": [
    "$Test the network with XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e010118",
   "metadata": {},
   "source": [
    "Calculate the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3408082d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_US_model(model, N_epoch, batch_size, study_rate, training_data, training_target):\n",
    "    #test all-to-all connected network\n",
    "    from_zero = False\n",
    "    if batch_size == 0:\n",
    "        batch_size = 1\n",
    "        from_zero = True\n",
    "\n",
    "    N_data = training_data.shape[0]\n",
    "    batch_form = jnp.zeros(batch_size)\n",
    "    phase_form = jnp.zeros([N_data, model.N])\n",
    "\n",
    "    training_paras = model.beta, study_rate\n",
    "    model_paras = model.N_ev, model.dt, model.input_index, model.variable_index, model.output_index\n",
    "\n",
    "    phase_0 = init_phase(model.N, model.input_index, training_data, batch_size)\n",
    "    W_0 = model.weights_0\n",
    "    bias_0 = model.bias_0\n",
    "\n",
    "    WL = np.zeros([N_epoch+1, model.N, model.N])\n",
    "    biasL = np.zeros([N_epoch+1, 2, model.N])\n",
    "    costL = np.zeros(N_epoch)\n",
    "\n",
    "    W = W_0\n",
    "    bias = bias_0\n",
    "\n",
    "    WL[0,...] = W_0\n",
    "    biasL[0,...] = bias_0\n",
    "\n",
    "    #prepare for Adam\n",
    "    s_W = 0*W\n",
    "    r_W = 0*W\n",
    "    s_h = 0*bias\n",
    "    r_h = 0*bias\n",
    "    \n",
    "    for k in range(0, N_epoch):\n",
    "        phase_0 = jax_init_phase(phase_form, model.input_index, training_data, batch_form, k, from_zero)\n",
    "        #phase_0 = init_phase(UA_model.N, UA_model.input_index, training_data, batch_size)\n",
    "        gW, gh, cost, q_cost = EP_param_gradient(W, bias, phase_0, training_target, training_paras, model_paras)\n",
    "        \n",
    "        W = gradient_descent_update(W, gW, study_rate, k)\n",
    "        bias = gradient_descent_update(bias, gh, study_rate, k)\n",
    "        \n",
    "        #W, s_W, r_W = Adam_update(W, gW, study_rate, k, s_W, r_W)\n",
    "        #bias, s_h, r_h = Adam_update(bias, gh, study_rate, k, s_h, r_h)\n",
    "        \n",
    "        costL[k] = cost\n",
    "    \n",
    "    return WL, biasL, costL\n",
    "\n",
    "\n",
    "def train_layered_model(model, N_epoch, batch_size, study_rate, training_data, training_target):\n",
    "    #test layered network with XOR\n",
    "\n",
    "    from_zero = False\n",
    "    if batch_size == 0:\n",
    "        batch_size = 1\n",
    "        from_zero = True\n",
    "\n",
    "    batch_form = jnp.zeros(batch_size)\n",
    "\n",
    "    training_paras = model.beta, study_rate\n",
    "    model_paras = model.N_ev, model.dt, model.structure_list, model.split_points, model.structure_shape\n",
    "\n",
    "    N_data = training_data.shape[0]\n",
    "    phase_form = jnp.zeros([N_data, model.N])\n",
    "    WL_0 = model.WL\n",
    "    bias_0 = model.bias_0\n",
    "\n",
    "    WLL_layer = []\n",
    "    biasL_layer = np.zeros([N_epoch+1, 2, model.N])\n",
    "    costL_layer = np.zeros(N_epoch)\n",
    "\n",
    "    WL = WL_0\n",
    "    bias = bias_0\n",
    "\n",
    "    WLL_layer = [WL_0]\n",
    "    biasL_layer[0,...] = bias_0\n",
    "\n",
    "    #prepare for Adam\n",
    "    WL_shape = jax.tree_map(jnp.shape, WL_0)\n",
    "\n",
    "    s_W = []\n",
    "    for shape in WL_shape:\n",
    "        s_W.append(jnp.zeros(shape))\n",
    "\n",
    "    r_W = s_W.copy()\n",
    "\n",
    "    s_h = jnp.zeros(bias_0.shape)\n",
    "    r_h = s_h\n",
    "    \n",
    "    depth = len(WL)\n",
    "    study_rate_list = [study_rate]\n",
    "    gWL = np.zeros([N_epoch, depth])\n",
    "    ngWL = np.zeros([N_epoch, depth])\n",
    "    \n",
    "    for k in range(1, depth-1):\n",
    "        study_rate_list.append(study_rate_list[-1]*1)\n",
    "        \n",
    "    study_rate_list.append(study_rate_list[-1] * 0.1)\n",
    "\n",
    "    for k in range(0, N_epoch):\n",
    "        phase_0 = jax_init_phase(phase_form, model.input_index, training_data, batch_form, k, from_zero)\n",
    "        gW, gh, cost, q_cost = layered_EP_param_gradient(WL, bias, phase_0, training_target, training_paras, model_paras)\n",
    "        \n",
    "        abs_gW = jax.tree_util.tree_map(jnp.linalg.norm, gW)\n",
    "        ngW = jax.tree_util.tree_map(jnp.divide, abs_gW, jax.tree_util.tree_map(jnp.linalg.norm, WL))\n",
    "        \n",
    "        ugW = jax.tree_util.tree_map(jnp.divide, gW, jax.tree_util.tree_map(jnp.linalg.norm, WL))\n",
    "        #ugW = jax.tree_util.tree_map(jnp.multiply, ugW, jax.tree_util.tree_map(jnp.sqrt, jax.tree_util.tree_map(jnp.size, WL) ))\n",
    "        \n",
    "        \n",
    "        #update_func = lambda paras, g_paras, study_rate_list: gradient_descent_update(paras, g_paras, study_rate_list, k)\n",
    "        #WL = jax.tree_util.tree_map(update_func, WL, gW, study_rate_list)\n",
    "        \n",
    "        '''\n",
    "        bias_list = jnp.split(bias, layer_model.split_points, axis=1)\n",
    "        gh_list = jnp.split(gh, layer_model.split_points, axis=1)\n",
    "        bias0 = bias_list[0]\n",
    "        del bias_list[0]\n",
    "        del gh_list[0]\n",
    "        ugh_list = jax.tree_util.tree_map(jnp.divide, gh_list, jax.tree_util.tree_map(jnp.linalg.norm, bias_list))\n",
    "        \n",
    "        bias_list = jax.tree_util.tree_map(update_func, bias_list, gh_list, study_rate_list)\n",
    "        bias_list.insert(0,bias0)\n",
    "        bias = jnp.concatenate(bias_list, axis=1)\n",
    "        '''\n",
    "        #bias = gradient_descent_update(bias, gh, study_rate, k)\n",
    "\n",
    "        '''\n",
    "        ugW = jax.tree_util.tree_map(jnp.divide, gW, jax.tree_util.tree_map(jnp.linalg.norm, WL))\n",
    "        bias_list = jnp.split(bias, layer_model.split_points, axis=1)\n",
    "        gh_list = jnp.split(gh, layer_model.split_points, axis=1)\n",
    "        bias0 = bias_list[0]\n",
    "        del bias_list[0]\n",
    "        del gh_list[0]\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        update_func = lambda paras, g_paras, s, r: Adam_update(paras, g_paras, study_rate, k, s, r)\n",
    "        bias, s_h, r_h = update_func(bias, gh, s_h, r_h)\n",
    "        res = jax.tree_map(update_func, WL, gW, s_W, r_W)\n",
    "        WL, s_W, r_W = tuple(zip(*res))\n",
    "        WL, s_W, r_W = list(WL), list(s_W), list(r_W)\n",
    "        \n",
    "        \n",
    "        WLL_layer.append(WL)\n",
    "        biasL_layer[k+1,...] = bias\n",
    "        costL_layer[k] = cost\n",
    "        gWL[k,:] = jnp.asarray(abs_gW)\n",
    "        ngWL[k,:] = jnp.asarray(ngW)\n",
    "         \n",
    "    return WLL_layer, biasL_layer, costL_layer\n",
    "\n",
    "def train_squarelattice_model(model, N_epoch, batch_size, study_rate, training_data, training_target):\n",
    "    #test Square lattice network with XOR\n",
    "    from_zero = False\n",
    "    if batch_size == 0:\n",
    "        batch_size = 1\n",
    "        from_zero = True\n",
    "\n",
    "    batch_form = jnp.zeros(batch_size)\n",
    "\n",
    "    lattice_form = jnp.zeros(model.dimension)\n",
    "\n",
    "    training_paras = beta, study_rate\n",
    "    model_paras = N_ev, dt, lattice_form, model.input_index, model.variable_index, model.output_index\n",
    "\n",
    "    N_data = training_data.shape[0]\n",
    "    phase_form = jnp.zeros([N_data, *model.dimension])\n",
    "\n",
    "    W_0 = model.weights_0\n",
    "    bias_0 = model.bias_0\n",
    "\n",
    "    WL_lattice = []\n",
    "    biasL_lattice = []\n",
    "    costL_lattice = np.zeros(N_epoch)\n",
    "\n",
    "    W = W_0\n",
    "    bias = bias_0\n",
    "\n",
    "    WL_lattice = [W_0]\n",
    "    biasL_lattice.append(bias_0)\n",
    "\n",
    "    #prepare for Adam\n",
    "    #prepare for Adam\n",
    "    s_W = 0*W\n",
    "    r_W = 0*W\n",
    "    s_h = 0*bias\n",
    "    r_h = 0*bias\n",
    "\n",
    "    for k in range(0, N_epoch):\n",
    "        phase_0 = lattice_jax_init_phase(phase_form, model.input_index, training_data, batch_form, k**2, from_zero)\n",
    "        gW, gh, cost, q_cost = SquareLattice_EP_param_gradient(W, bias, phase_0, training_target, training_paras, model_paras)\n",
    "        \n",
    "        W = gradient_descent_update(W, gW, study_rate/100, k)\n",
    "        bias = gradient_descent_update(bias, gh, study_rate/100, k)\n",
    "        \n",
    "        #W, s_W, r_W = Adam_update(W, gW, study_rate, k, s_W, r_W)\n",
    "        #bias, s_h, r_h = Adam_update(bias, gh, study_rate, k, s_h, r_h)\n",
    "        \n",
    "        \n",
    "        WL_lattice.append(W)\n",
    "        biasL_lattice.append(bias)\n",
    "        costL_lattice[k] = cost\n",
    "\n",
    "    return WL_lattice, biasL_lattice, costL_lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ca3bc2",
   "metadata": {},
   "source": [
    "#Start doing experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5583dc6a-ac69-4cd6-bfcf-a01f9596847e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n"
     ]
    }
   ],
   "source": [
    "# Load data from scikit-learning\n",
    "import sklearn\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = datasets.load_digits(return_X_y=True)\n",
    "print(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63894a3b-c546-4b50-990b-ce074081639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite the data to fit the data\n",
    "X_data_scale = jnp.max(X) \n",
    "y_data_scale = jnp.max(y)\n",
    "all_training_data = jnp.pi * (X - X_data_scale/2)/(X_data_scale)\n",
    "all_target = jnp.pi * (y - y_data_scale/2)/(y_data_scale)\n",
    "all_target = all_target[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "393b2bf6-70b4-4ae7-b6e5-80aa9fc1581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_target = np.zeros([1797, 10])\n",
    "for k in range(0,1797):\n",
    "    all_target[k,y[k]] = 1\n",
    "\n",
    "all_target = jnp.asarray( jnp.pi * (all_target - 0.5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9344a5d-9348-449b-87b9-80560d334950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test distinguish 3 digits\n",
    "# prepare data: sorting the scikit_data accodring to digit\n",
    "\n",
    "sorted_X = []\n",
    "sorted_y = []\n",
    "sorted_ind = []\n",
    "for k in range(0,10):\n",
    "    sorted_X.append([])\n",
    "    sorted_y.append([])\n",
    "    sorted_ind.append([])\n",
    "\n",
    "for k in range(0,1797):\n",
    "    digit = y[k]\n",
    "    sorted_X[digit].append(X[k])\n",
    "    sorted_y[digit].append(y[k])\n",
    "    sorted_ind[digit].append(k)\n",
    "    \n",
    "# pick 2 digits to distinguish\n",
    "digits = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# prepare dataset for training\n",
    "\n",
    "n_digit = len(digits)\n",
    "\n",
    "selected_training_data = []\n",
    "selected_training_target = []\n",
    "\n",
    "for k in range(0,n_digit):\n",
    "    selected_training_data.append(all_training_data[sorted_ind[digits[k]], :])\n",
    "    selected_training_target.append(all_target[sorted_ind[digits[k]], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c86c27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the network\n",
    "N_ev = 1000\n",
    "dt = 0.1\n",
    "\n",
    "study_rate = 0.01\n",
    "beta = 0.1\n",
    "\n",
    "#Define the network with layer stryctyre\n",
    "Nh = 300\n",
    "structure_list = jnp.asarray([64,Nh,10])\n",
    "N = jnp.sum(structure_list)\n",
    "layer_model = SP_XY_Layer_Network(N, N_ev, dt, structure_list)\n",
    "layer_model.get_beta(beta)\n",
    "layer_model.random_state_initiation()\n",
    "\n",
    "input_index = jnp.arange(0, structure_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "87f4f3b8-8118-48b9-961f-29c07d8ac690",
   "metadata": {},
   "outputs": [],
   "source": [
    "WLL = np.load('WLLh{0}.npy'.format(Nh), allow_pickle=True)\n",
    "biasL = np.load('biasLh{0}.npy'.format(Nh), allow_pickle=True)\n",
    "costL = np.load('costLh{0}.npy'.format(Nh), allow_pickle=True)\n",
    "training_success_list = np.load('training_success_listh{0}.npy'.format(Nh), allow_pickle=True)\n",
    "success_list = np.load('success_listh{0}.npy'.format(Nh), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9552bdb8-8937-4074-8d3f-9ad7c246b30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_epoch = costL.shape[0]\n",
    "test_W_ind = np.arange(0,N_epoch+1, 5)\n",
    "#print(test_W_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f270858-c59a-4a07-9f21-29119f5e75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind = []\n",
    "test_dataL = []\n",
    "test_targetL = []\n",
    "\n",
    "train_set_size = 100\n",
    "test_batch_size = 70\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "for l in range(0,n_digit):\n",
    "    t_ind = np.arange(train_set_size,train_set_size+test_batch_size)\n",
    "    test_dataL.append(selected_training_data[l][t_ind, :])\n",
    "    test_targetL.append(selected_training_target[l][t_ind, :])\n",
    "\n",
    "test_data = jnp.concatenate(test_dataL, axis=0)\n",
    "test_target = jnp.concatenate(test_targetL, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e4d9749-72a1-4cae-9a9d-4cbb949e5751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0th set of parameters is tested. Time consumption: 8.9419 s. Success=0.113\n",
      "The 5th set of parameters is tested. Time consumption: 7.2429 s. Success=0.309\n",
      "The 10th set of parameters is tested. Time consumption: 6.9348 s. Success=0.450\n",
      "The 15th set of parameters is tested. Time consumption: 7.0278 s. Success=0.619\n",
      "The 20th set of parameters is tested. Time consumption: 6.9788 s. Success=0.696\n",
      "The 25th set of parameters is tested. Time consumption: 7.3385 s. Success=0.734\n",
      "The 30th set of parameters is tested. Time consumption: 6.9555 s. Success=0.780\n",
      "The 35th set of parameters is tested. Time consumption: 6.9080 s. Success=0.791\n",
      "The 40th set of parameters is tested. Time consumption: 6.9740 s. Success=0.814\n",
      "The 45th set of parameters is tested. Time consumption: 7.0623 s. Success=0.809\n",
      "The 50th set of parameters is tested. Time consumption: 6.8460 s. Success=0.836\n",
      "The 55th set of parameters is tested. Time consumption: 6.8459 s. Success=0.843\n",
      "The 60th set of parameters is tested. Time consumption: 6.9417 s. Success=0.833\n",
      "The 65th set of parameters is tested. Time consumption: 6.8457 s. Success=0.856\n",
      "The 70th set of parameters is tested. Time consumption: 6.8456 s. Success=0.864\n",
      "The 75th set of parameters is tested. Time consumption: 6.7976 s. Success=0.850\n",
      "The 80th set of parameters is tested. Time consumption: 7.0383 s. Success=0.856\n",
      "The 85th set of parameters is tested. Time consumption: 6.7977 s. Success=0.854\n",
      "The 90th set of parameters is tested. Time consumption: 6.7731 s. Success=0.879\n",
      "The 95th set of parameters is tested. Time consumption: 6.7497 s. Success=0.866\n",
      "The 100th set of parameters is tested. Time consumption: 6.7736 s. Success=0.884\n",
      "The 105th set of parameters is tested. Time consumption: 6.7740 s. Success=0.877\n",
      "The 110th set of parameters is tested. Time consumption: 6.8942 s. Success=0.879\n",
      "The 115th set of parameters is tested. Time consumption: 6.7501 s. Success=0.879\n",
      "The 120th set of parameters is tested. Time consumption: 6.8945 s. Success=0.884\n",
      "The 125th set of parameters is tested. Time consumption: 6.6536 s. Success=0.896\n",
      "The 130th set of parameters is tested. Time consumption: 6.9906 s. Success=0.883\n",
      "The 135th set of parameters is tested. Time consumption: 6.8214 s. Success=0.894\n",
      "The 140th set of parameters is tested. Time consumption: 6.9905 s. Success=0.880\n",
      "The 145th set of parameters is tested. Time consumption: 6.8943 s. Success=0.891\n",
      "The 150th set of parameters is tested. Time consumption: 6.8709 s. Success=0.889\n",
      "The 155th set of parameters is tested. Time consumption: 6.7987 s. Success=0.909\n",
      "The 160th set of parameters is tested. Time consumption: 6.8717 s. Success=0.904\n",
      "The 165th set of parameters is tested. Time consumption: 6.7020 s. Success=0.901\n",
      "The 170th set of parameters is tested. Time consumption: 6.8460 s. Success=0.896\n",
      "The 175th set of parameters is tested. Time consumption: 6.9188 s. Success=0.903\n",
      "The 180th set of parameters is tested. Time consumption: 7.0145 s. Success=0.904\n",
      "The 185th set of parameters is tested. Time consumption: 6.8702 s. Success=0.910\n",
      "The 190th set of parameters is tested. Time consumption: 6.8220 s. Success=0.906\n",
      "The 195th set of parameters is tested. Time consumption: 6.9184 s. Success=0.899\n",
      "The 200th set of parameters is tested. Time consumption: 6.9186 s. Success=0.897\n",
      "The 205th set of parameters is tested. Time consumption: 6.8468 s. Success=0.900\n",
      "The 210th set of parameters is tested. Time consumption: 6.7981 s. Success=0.911\n",
      "The 215th set of parameters is tested. Time consumption: 7.1107 s. Success=0.906\n",
      "The 220th set of parameters is tested. Time consumption: 6.9662 s. Success=0.913\n",
      "The 225th set of parameters is tested. Time consumption: 6.7259 s. Success=0.916\n",
      "The 230th set of parameters is tested. Time consumption: 6.9667 s. Success=0.914\n",
      "The 235th set of parameters is tested. Time consumption: 6.9665 s. Success=0.916\n",
      "The 240th set of parameters is tested. Time consumption: 6.8455 s. Success=0.913\n",
      "The 245th set of parameters is tested. Time consumption: 7.2316 s. Success=0.910\n",
      "The 250th set of parameters is tested. Time consumption: 7.1116 s. Success=0.911\n",
      "The 255th set of parameters is tested. Time consumption: 7.2322 s. Success=0.917\n",
      "The 260th set of parameters is tested. Time consumption: 6.8716 s. Success=0.911\n",
      "The 265th set of parameters is tested. Time consumption: 6.8225 s. Success=0.917\n",
      "The 270th set of parameters is tested. Time consumption: 6.8950 s. Success=0.921\n",
      "The 275th set of parameters is tested. Time consumption: 6.9905 s. Success=0.924\n",
      "The 280th set of parameters is tested. Time consumption: 6.9421 s. Success=0.919\n",
      "The 285th set of parameters is tested. Time consumption: 6.9914 s. Success=0.916\n",
      "The 290th set of parameters is tested. Time consumption: 7.0395 s. Success=0.926\n",
      "The 295th set of parameters is tested. Time consumption: 7.1106 s. Success=0.907\n",
      "The 300th set of parameters is tested. Time consumption: 6.8936 s. Success=0.890\n",
      "The 305th set of parameters is tested. Time consumption: 7.3519 s. Success=0.919\n",
      "The 310th set of parameters is tested. Time consumption: 7.0628 s. Success=0.919\n",
      "The 315th set of parameters is tested. Time consumption: 7.1833 s. Success=0.914\n",
      "The 320th set of parameters is tested. Time consumption: 7.0875 s. Success=0.914\n",
      "The 325th set of parameters is tested. Time consumption: 7.0394 s. Success=0.909\n",
      "The 330th set of parameters is tested. Time consumption: 7.2083 s. Success=0.924\n",
      "The 335th set of parameters is tested. Time consumption: 7.0875 s. Success=0.903\n",
      "The 340th set of parameters is tested. Time consumption: 7.2552 s. Success=0.914\n",
      "The 345th set of parameters is tested. Time consumption: 7.0634 s. Success=0.909\n",
      "The 350th set of parameters is tested. Time consumption: 7.1831 s. Success=0.903\n",
      "The 355th set of parameters is tested. Time consumption: 7.2315 s. Success=0.910\n",
      "The 360th set of parameters is tested. Time consumption: 7.0632 s. Success=0.916\n",
      "The 365th set of parameters is tested. Time consumption: 7.2077 s. Success=0.917\n",
      "The 370th set of parameters is tested. Time consumption: 7.2558 s. Success=0.917\n",
      "The 375th set of parameters is tested. Time consumption: 7.0629 s. Success=0.923\n",
      "The 380th set of parameters is tested. Time consumption: 7.3036 s. Success=0.914\n",
      "The 385th set of parameters is tested. Time consumption: 7.3516 s. Success=0.910\n",
      "The 390th set of parameters is tested. Time consumption: 7.1353 s. Success=0.916\n",
      "The 395th set of parameters is tested. Time consumption: 7.2798 s. Success=0.911\n",
      "The 400th set of parameters is tested. Time consumption: 7.5929 s. Success=0.913\n",
      "The 405th set of parameters is tested. Time consumption: 7.3278 s. Success=0.909\n",
      "The 410th set of parameters is tested. Time consumption: 7.1353 s. Success=0.906\n",
      "The 415th set of parameters is tested. Time consumption: 7.2081 s. Success=0.906\n",
      "The 420th set of parameters is tested. Time consumption: 7.2318 s. Success=0.903\n",
      "The 425th set of parameters is tested. Time consumption: 7.3274 s. Success=0.910\n",
      "The 430th set of parameters is tested. Time consumption: 7.4961 s. Success=0.906\n",
      "The 435th set of parameters is tested. Time consumption: 7.1112 s. Success=0.913\n",
      "The 440th set of parameters is tested. Time consumption: 7.1833 s. Success=0.929\n",
      "The 445th set of parameters is tested. Time consumption: 7.4723 s. Success=0.910\n",
      "The 450th set of parameters is tested. Time consumption: 7.3033 s. Success=0.907\n",
      "The 455th set of parameters is tested. Time consumption: 7.2318 s. Success=0.920\n",
      "The 460th set of parameters is tested. Time consumption: 7.2073 s. Success=0.923\n",
      "The 465th set of parameters is tested. Time consumption: 7.5921 s. Success=0.921\n",
      "The 470th set of parameters is tested. Time consumption: 7.4716 s. Success=0.904\n",
      "The 475th set of parameters is tested. Time consumption: 7.3510 s. Success=0.917\n",
      "The 480th set of parameters is tested. Time consumption: 7.4233 s. Success=0.914\n",
      "The 485th set of parameters is tested. Time consumption: 7.2079 s. Success=0.917\n",
      "The 490th set of parameters is tested. Time consumption: 7.5446 s. Success=0.916\n",
      "The 495th set of parameters is tested. Time consumption: 7.4719 s. Success=0.917\n",
      "The 500th set of parameters is tested. Time consumption: 7.3999 s. Success=0.909\n",
      "The 505th set of parameters is tested. Time consumption: 7.3756 s. Success=0.916\n",
      "The 510th set of parameters is tested. Time consumption: 7.2071 s. Success=0.921\n",
      "The 515th set of parameters is tested. Time consumption: 7.6402 s. Success=0.910\n",
      "The 520th set of parameters is tested. Time consumption: 7.3755 s. Success=0.913\n",
      "The 525th set of parameters is tested. Time consumption: 7.5691 s. Success=0.920\n",
      "The 530th set of parameters is tested. Time consumption: 7.8113 s. Success=0.911\n",
      "The 535th set of parameters is tested. Time consumption: 7.6172 s. Success=0.920\n",
      "The 540th set of parameters is tested. Time consumption: 7.6172 s. Success=0.921\n",
      "The 545th set of parameters is tested. Time consumption: 7.9296 s. Success=0.907\n",
      "The 550th set of parameters is tested. Time consumption: 7.5441 s. Success=0.914\n",
      "The 555th set of parameters is tested. Time consumption: 7.4002 s. Success=0.907\n",
      "The 560th set of parameters is tested. Time consumption: 8.0020 s. Success=0.911\n",
      "The 565th set of parameters is tested. Time consumption: 7.4962 s. Success=0.924\n",
      "The 570th set of parameters is tested. Time consumption: 7.6640 s. Success=0.913\n",
      "The 575th set of parameters is tested. Time consumption: 7.6655 s. Success=0.887\n",
      "The 580th set of parameters is tested. Time consumption: 7.4487 s. Success=0.911\n",
      "The 585th set of parameters is tested. Time consumption: 7.5449 s. Success=0.906\n",
      "The 590th set of parameters is tested. Time consumption: 7.5936 s. Success=0.913\n",
      "The 595th set of parameters is tested. Time consumption: 7.5924 s. Success=0.897\n",
      "The 600th set of parameters is tested. Time consumption: 7.6409 s. Success=0.919\n",
      "The 605th set of parameters is tested. Time consumption: 7.4961 s. Success=0.914\n",
      "The 610th set of parameters is tested. Time consumption: 7.6884 s. Success=0.913\n",
      "The 615th set of parameters is tested. Time consumption: 7.5442 s. Success=0.924\n",
      "The 620th set of parameters is tested. Time consumption: 7.5438 s. Success=0.923\n",
      "The 625th set of parameters is tested. Time consumption: 7.5930 s. Success=0.921\n",
      "The 630th set of parameters is tested. Time consumption: 7.8342 s. Success=0.911\n",
      "The 635th set of parameters is tested. Time consumption: 7.7608 s. Success=0.913\n",
      "The 640th set of parameters is tested. Time consumption: 7.8104 s. Success=0.909\n",
      "The 645th set of parameters is tested. Time consumption: 7.8817 s. Success=0.899\n",
      "The 650th set of parameters is tested. Time consumption: 7.7367 s. Success=0.917\n",
      "The 655th set of parameters is tested. Time consumption: 7.8574 s. Success=0.916\n",
      "The 660th set of parameters is tested. Time consumption: 7.9543 s. Success=0.910\n",
      "The 665th set of parameters is tested. Time consumption: 7.6643 s. Success=0.913\n",
      "The 670th set of parameters is tested. Time consumption: 7.8342 s. Success=0.923\n",
      "The 675th set of parameters is tested. Time consumption: 7.6891 s. Success=0.903\n",
      "The 680th set of parameters is tested. Time consumption: 8.0255 s. Success=0.917\n",
      "The 685th set of parameters is tested. Time consumption: 7.8088 s. Success=0.914\n",
      "The 690th set of parameters is tested. Time consumption: 7.6412 s. Success=0.920\n",
      "The 695th set of parameters is tested. Time consumption: 7.7846 s. Success=0.910\n",
      "The 700th set of parameters is tested. Time consumption: 7.6403 s. Success=0.921\n",
      "The 705th set of parameters is tested. Time consumption: 7.7612 s. Success=0.916\n",
      "The 710th set of parameters is tested. Time consumption: 7.7369 s. Success=0.920\n",
      "The 715th set of parameters is tested. Time consumption: 7.9308 s. Success=0.919\n",
      "The 720th set of parameters is tested. Time consumption: 8.2910 s. Success=0.923\n",
      "The 725th set of parameters is tested. Time consumption: 7.5925 s. Success=0.906\n",
      "The 730th set of parameters is tested. Time consumption: 7.8095 s. Success=0.901\n",
      "The 735th set of parameters is tested. Time consumption: 7.8099 s. Success=0.904\n",
      "The 740th set of parameters is tested. Time consumption: 7.7854 s. Success=0.926\n",
      "The 745th set of parameters is tested. Time consumption: 7.7369 s. Success=0.924\n",
      "The 750th set of parameters is tested. Time consumption: 7.8339 s. Success=0.921\n",
      "The 755th set of parameters is tested. Time consumption: 8.0984 s. Success=0.919\n",
      "The 760th set of parameters is tested. Time consumption: 7.7612 s. Success=0.924\n",
      "The 765th set of parameters is tested. Time consumption: 7.9059 s. Success=0.903\n",
      "The 770th set of parameters is tested. Time consumption: 7.7854 s. Success=0.913\n",
      "The 775th set of parameters is tested. Time consumption: 7.8573 s. Success=0.919\n",
      "The 780th set of parameters is tested. Time consumption: 7.8094 s. Success=0.910\n",
      "The 785th set of parameters is tested. Time consumption: 8.0520 s. Success=0.919\n",
      "The 790th set of parameters is tested. Time consumption: 7.8820 s. Success=0.917\n",
      "The 795th set of parameters is tested. Time consumption: 7.7850 s. Success=0.914\n",
      "The 800th set of parameters is tested. Time consumption: 8.0502 s. Success=0.906\n",
      "The 805th set of parameters is tested. Time consumption: 8.0748 s. Success=0.911\n",
      "The 810th set of parameters is tested. Time consumption: 7.9062 s. Success=0.920\n",
      "The 815th set of parameters is tested. Time consumption: 8.0028 s. Success=0.917\n",
      "The 820th set of parameters is tested. Time consumption: 7.9780 s. Success=0.906\n",
      "The 825th set of parameters is tested. Time consumption: 7.8815 s. Success=0.919\n",
      "The 830th set of parameters is tested. Time consumption: 8.0743 s. Success=0.897\n",
      "The 835th set of parameters is tested. Time consumption: 8.0028 s. Success=0.923\n",
      "The 840th set of parameters is tested. Time consumption: 8.3399 s. Success=0.926\n",
      "The 845th set of parameters is tested. Time consumption: 8.2205 s. Success=0.906\n",
      "The 850th set of parameters is tested. Time consumption: 8.0269 s. Success=0.910\n",
      "The 855th set of parameters is tested. Time consumption: 8.2663 s. Success=0.907\n",
      "The 860th set of parameters is tested. Time consumption: 7.8087 s. Success=0.911\n",
      "The 865th set of parameters is tested. Time consumption: 8.0507 s. Success=0.917\n",
      "The 870th set of parameters is tested. Time consumption: 8.1457 s. Success=0.914\n",
      "The 875th set of parameters is tested. Time consumption: 8.1945 s. Success=0.914\n",
      "The 880th set of parameters is tested. Time consumption: 8.1701 s. Success=0.894\n",
      "The 885th set of parameters is tested. Time consumption: 8.1711 s. Success=0.920\n",
      "The 890th set of parameters is tested. Time consumption: 7.7850 s. Success=0.911\n",
      "The 895th set of parameters is tested. Time consumption: 8.0750 s. Success=0.919\n",
      "The 900th set of parameters is tested. Time consumption: 8.0993 s. Success=0.924\n",
      "The 905th set of parameters is tested. Time consumption: 8.3629 s. Success=0.917\n",
      "The 910th set of parameters is tested. Time consumption: 8.2202 s. Success=0.920\n",
      "The 915th set of parameters is tested. Time consumption: 8.2914 s. Success=0.913\n",
      "The 920th set of parameters is tested. Time consumption: 8.1468 s. Success=0.911\n",
      "The 925th set of parameters is tested. Time consumption: 8.3395 s. Success=0.916\n",
      "The 930th set of parameters is tested. Time consumption: 8.3393 s. Success=0.901\n",
      "The 935th set of parameters is tested. Time consumption: 8.2904 s. Success=0.896\n",
      "The 940th set of parameters is tested. Time consumption: 7.9774 s. Success=0.919\n",
      "The 945th set of parameters is tested. Time consumption: 8.3149 s. Success=0.909\n",
      "The 950th set of parameters is tested. Time consumption: 8.1951 s. Success=0.923\n",
      "The 955th set of parameters is tested. Time consumption: 8.5560 s. Success=0.917\n",
      "The 960th set of parameters is tested. Time consumption: 8.3391 s. Success=0.926\n",
      "The 965th set of parameters is tested. Time consumption: 8.3143 s. Success=0.923\n",
      "The 970th set of parameters is tested. Time consumption: 8.3153 s. Success=0.926\n",
      "The 975th set of parameters is tested. Time consumption: 8.3392 s. Success=0.921\n",
      "The 980th set of parameters is tested. Time consumption: 8.4353 s. Success=0.914\n",
      "The 985th set of parameters is tested. Time consumption: 8.3149 s. Success=0.900\n",
      "The 990th set of parameters is tested. Time consumption: 8.6534 s. Success=0.907\n",
      "The 995th set of parameters is tested. Time consumption: 8.2671 s. Success=0.916\n",
      "The 1000th set of parameters is tested. Time consumption: 8.4357 s. Success=0.913\n",
      "The 1005th set of parameters is tested. Time consumption: 8.2430 s. Success=0.919\n",
      "The 1010th set of parameters is tested. Time consumption: 8.3392 s. Success=0.919\n",
      "The 1015th set of parameters is tested. Time consumption: 8.2185 s. Success=0.911\n",
      "The 1020th set of parameters is tested. Time consumption: 8.3146 s. Success=0.913\n",
      "The 1025th set of parameters is tested. Time consumption: 8.4345 s. Success=0.919\n",
      "The 1030th set of parameters is tested. Time consumption: 8.4833 s. Success=0.909\n",
      "The 1035th set of parameters is tested. Time consumption: 8.2668 s. Success=0.937\n",
      "The 1040th set of parameters is tested. Time consumption: 8.7731 s. Success=0.927\n",
      "The 1045th set of parameters is tested. Time consumption: 8.3153 s. Success=0.913\n",
      "The 1050th set of parameters is tested. Time consumption: 8.4116 s. Success=0.914\n",
      "The 1055th set of parameters is tested. Time consumption: 8.5799 s. Success=0.923\n",
      "The 1060th set of parameters is tested. Time consumption: 8.2672 s. Success=0.920\n",
      "The 1065th set of parameters is tested. Time consumption: 8.4117 s. Success=0.917\n",
      "The 1070th set of parameters is tested. Time consumption: 8.6286 s. Success=0.921\n",
      "The 1075th set of parameters is tested. Time consumption: 8.4362 s. Success=0.911\n",
      "The 1080th set of parameters is tested. Time consumption: 8.5076 s. Success=0.920\n",
      "The 1085th set of parameters is tested. Time consumption: 8.4352 s. Success=0.921\n",
      "The 1090th set of parameters is tested. Time consumption: 8.2671 s. Success=0.917\n",
      "The 1095th set of parameters is tested. Time consumption: 8.5801 s. Success=0.920\n",
      "The 1100th set of parameters is tested. Time consumption: 8.6280 s. Success=0.916\n",
      "The 1105th set of parameters is tested. Time consumption: 8.8453 s. Success=0.917\n",
      "The 1110th set of parameters is tested. Time consumption: 8.5312 s. Success=0.917\n",
      "The 1115th set of parameters is tested. Time consumption: 8.7249 s. Success=0.924\n",
      "The 1120th set of parameters is tested. Time consumption: 8.8689 s. Success=0.934\n",
      "The 1125th set of parameters is tested. Time consumption: 8.6280 s. Success=0.914\n",
      "The 1130th set of parameters is tested. Time consumption: 8.4116 s. Success=0.914\n",
      "The 1135th set of parameters is tested. Time consumption: 8.6042 s. Success=0.919\n",
      "The 1140th set of parameters is tested. Time consumption: 8.7969 s. Success=0.913\n",
      "The 1145th set of parameters is tested. Time consumption: 8.5318 s. Success=0.930\n",
      "The 1150th set of parameters is tested. Time consumption: 8.4352 s. Success=0.920\n",
      "The 1155th set of parameters is tested. Time consumption: 8.4115 s. Success=0.917\n",
      "The 1160th set of parameters is tested. Time consumption: 8.7246 s. Success=0.917\n",
      "The 1165th set of parameters is tested. Time consumption: 8.5556 s. Success=0.929\n",
      "The 1170th set of parameters is tested. Time consumption: 8.5554 s. Success=0.926\n",
      "The 1175th set of parameters is tested. Time consumption: 8.7719 s. Success=0.920\n",
      "The 1180th set of parameters is tested. Time consumption: 8.6996 s. Success=0.929\n",
      "The 1185th set of parameters is tested. Time consumption: 8.7003 s. Success=0.930\n",
      "The 1190th set of parameters is tested. Time consumption: 8.5807 s. Success=0.929\n",
      "The 1195th set of parameters is tested. Time consumption: 8.7479 s. Success=0.919\n",
      "The 1200th set of parameters is tested. Time consumption: 8.8205 s. Success=0.924\n",
      "The 1205th set of parameters is tested. Time consumption: 8.4835 s. Success=0.901\n",
      "The 1210th set of parameters is tested. Time consumption: 8.9894 s. Success=0.916\n",
      "The 1215th set of parameters is tested. Time consumption: 9.1583 s. Success=0.920\n",
      "The 1220th set of parameters is tested. Time consumption: 8.7732 s. Success=0.913\n",
      "The 1225th set of parameters is tested. Time consumption: 8.6767 s. Success=0.899\n",
      "The 1230th set of parameters is tested. Time consumption: 9.0133 s. Success=0.920\n",
      "The 1235th set of parameters is tested. Time consumption: 8.5324 s. Success=0.921\n",
      "The 1240th set of parameters is tested. Time consumption: 8.4833 s. Success=0.914\n",
      "The 1245th set of parameters is tested. Time consumption: 9.0615 s. Success=0.916\n",
      "The 1250th set of parameters is tested. Time consumption: 9.3496 s. Success=0.917\n",
      "The 1255th set of parameters is tested. Time consumption: 8.7482 s. Success=0.914\n",
      "The 1260th set of parameters is tested. Time consumption: 9.1334 s. Success=0.907\n",
      "The 1265th set of parameters is tested. Time consumption: 8.7254 s. Success=0.921\n",
      "The 1270th set of parameters is tested. Time consumption: 8.9892 s. Success=0.924\n",
      "The 1275th set of parameters is tested. Time consumption: 8.6777 s. Success=0.921\n",
      "The 1280th set of parameters is tested. Time consumption: 9.1596 s. Success=0.921\n",
      "The 1285th set of parameters is tested. Time consumption: 9.0632 s. Success=0.900\n",
      "The 1290th set of parameters is tested. Time consumption: 8.9414 s. Success=0.923\n",
      "The 1295th set of parameters is tested. Time consumption: 8.9174 s. Success=0.917\n",
      "The 1300th set of parameters is tested. Time consumption: 8.6040 s. Success=0.911\n",
      "The 1305th set of parameters is tested. Time consumption: 8.6037 s. Success=0.917\n",
      "The 1310th set of parameters is tested. Time consumption: 9.0128 s. Success=0.926\n",
      "The 1315th set of parameters is tested. Time consumption: 8.8701 s. Success=0.921\n",
      "The 1320th set of parameters is tested. Time consumption: 8.6760 s. Success=0.910\n",
      "The 1325th set of parameters is tested. Time consumption: 8.8446 s. Success=0.923\n",
      "The 1330th set of parameters is tested. Time consumption: 8.7484 s. Success=0.924\n",
      "The 1335th set of parameters is tested. Time consumption: 8.7487 s. Success=0.917\n",
      "The 1340th set of parameters is tested. Time consumption: 8.7004 s. Success=0.913\n",
      "The 1345th set of parameters is tested. Time consumption: 8.9653 s. Success=0.924\n",
      "The 1350th set of parameters is tested. Time consumption: 8.9166 s. Success=0.924\n",
      "The 1355th set of parameters is tested. Time consumption: 9.3496 s. Success=0.923\n",
      "The 1360th set of parameters is tested. Time consumption: 8.7010 s. Success=0.920\n",
      "The 1365th set of parameters is tested. Time consumption: 8.9898 s. Success=0.907\n",
      "The 1370th set of parameters is tested. Time consumption: 8.7482 s. Success=0.909\n",
      "The 1375th set of parameters is tested. Time consumption: 8.8682 s. Success=0.923\n",
      "The 1380th set of parameters is tested. Time consumption: 9.0135 s. Success=0.911\n",
      "The 1385th set of parameters is tested. Time consumption: 8.7722 s. Success=0.913\n",
      "The 1390th set of parameters is tested. Time consumption: 8.9172 s. Success=0.919\n",
      "The 1395th set of parameters is tested. Time consumption: 9.1096 s. Success=0.917\n",
      "The 1400th set of parameters is tested. Time consumption: 8.9401 s. Success=0.920\n",
      "The 1405th set of parameters is tested. Time consumption: 8.8438 s. Success=0.913\n",
      "The 1410th set of parameters is tested. Time consumption: 9.1577 s. Success=0.923\n",
      "The 1415th set of parameters is tested. Time consumption: 9.2772 s. Success=0.937\n",
      "The 1420th set of parameters is tested. Time consumption: 9.2047 s. Success=0.920\n",
      "The 1425th set of parameters is tested. Time consumption: 9.2291 s. Success=0.920\n",
      "The 1430th set of parameters is tested. Time consumption: 9.0375 s. Success=0.931\n",
      "The 1435th set of parameters is tested. Time consumption: 9.0364 s. Success=0.887\n",
      "The 1440th set of parameters is tested. Time consumption: 9.2530 s. Success=0.933\n",
      "The 1445th set of parameters is tested. Time consumption: 8.9160 s. Success=0.926\n",
      "The 1450th set of parameters is tested. Time consumption: 8.8923 s. Success=0.921\n",
      "The 1455th set of parameters is tested. Time consumption: 9.1330 s. Success=0.917\n",
      "The 1460th set of parameters is tested. Time consumption: 9.5192 s. Success=0.909\n",
      "The 1465th set of parameters is tested. Time consumption: 9.6623 s. Success=0.919\n",
      "The 1470th set of parameters is tested. Time consumption: 9.1811 s. Success=0.924\n",
      "The 1475th set of parameters is tested. Time consumption: 8.7480 s. Success=0.921\n",
      "The 1480th set of parameters is tested. Time consumption: 9.1573 s. Success=0.910\n",
      "The 1485th set of parameters is tested. Time consumption: 9.4224 s. Success=0.917\n",
      "The 1490th set of parameters is tested. Time consumption: 9.0611 s. Success=0.906\n",
      "The 1495th set of parameters is tested. Time consumption: 9.0847 s. Success=0.923\n",
      "The 1500th set of parameters is tested. Time consumption: 9.4936 s. Success=0.923\n",
      "The 1505th set of parameters is tested. Time consumption: 9.0859 s. Success=0.924\n",
      "The 1510th set of parameters is tested. Time consumption: 9.6630 s. Success=0.924\n",
      "The 1515th set of parameters is tested. Time consumption: 9.2294 s. Success=0.921\n",
      "The 1520th set of parameters is tested. Time consumption: 8.8200 s. Success=0.916\n",
      "The 1525th set of parameters is tested. Time consumption: 9.0135 s. Success=0.919\n",
      "The 1530th set of parameters is tested. Time consumption: 9.5903 s. Success=0.914\n",
      "The 1535th set of parameters is tested. Time consumption: 9.3731 s. Success=0.913\n",
      "The 1540th set of parameters is tested. Time consumption: 9.0610 s. Success=0.914\n",
      "The 1545th set of parameters is tested. Time consumption: 9.4464 s. Success=0.909\n",
      "The 1550th set of parameters is tested. Time consumption: 9.5919 s. Success=0.924\n",
      "The 1555th set of parameters is tested. Time consumption: 9.4711 s. Success=0.923\n",
      "The 1560th set of parameters is tested. Time consumption: 9.2064 s. Success=0.911\n",
      "The 1565th set of parameters is tested. Time consumption: 9.2769 s. Success=0.920\n",
      "The 1570th set of parameters is tested. Time consumption: 9.2533 s. Success=0.917\n",
      "The 1575th set of parameters is tested. Time consumption: 9.0848 s. Success=0.937\n",
      "The 1580th set of parameters is tested. Time consumption: 9.1329 s. Success=0.919\n",
      "The 1585th set of parameters is tested. Time consumption: 9.0841 s. Success=0.920\n",
      "The 1590th set of parameters is tested. Time consumption: 9.5416 s. Success=0.929\n",
      "The 1595th set of parameters is tested. Time consumption: 9.3015 s. Success=0.923\n",
      "The 1600th set of parameters is tested. Time consumption: 9.4943 s. Success=0.924\n",
      "The 1605th set of parameters is tested. Time consumption: 9.4230 s. Success=0.923\n",
      "The 1610th set of parameters is tested. Time consumption: 9.4482 s. Success=0.910\n",
      "The 1615th set of parameters is tested. Time consumption: 9.1104 s. Success=0.906\n",
      "The 1620th set of parameters is tested. Time consumption: 9.3266 s. Success=0.913\n",
      "The 1625th set of parameters is tested. Time consumption: 9.2534 s. Success=0.924\n",
      "The 1630th set of parameters is tested. Time consumption: 9.3975 s. Success=0.926\n",
      "The 1635th set of parameters is tested. Time consumption: 9.2298 s. Success=0.920\n",
      "The 1640th set of parameters is tested. Time consumption: 9.3982 s. Success=0.933\n",
      "The 1645th set of parameters is tested. Time consumption: 9.4944 s. Success=0.911\n",
      "The 1650th set of parameters is tested. Time consumption: 9.3752 s. Success=0.917\n",
      "The 1655th set of parameters is tested. Time consumption: 9.2289 s. Success=0.926\n",
      "The 1660th set of parameters is tested. Time consumption: 9.2531 s. Success=0.924\n",
      "The 1665th set of parameters is tested. Time consumption: 9.7591 s. Success=0.916\n",
      "The 1670th set of parameters is tested. Time consumption: 9.4213 s. Success=0.921\n",
      "The 1675th set of parameters is tested. Time consumption: 9.6144 s. Success=0.914\n",
      "The 1680th set of parameters is tested. Time consumption: 9.9280 s. Success=0.923\n",
      "The 1685th set of parameters is tested. Time consumption: 9.3256 s. Success=0.916\n",
      "The 1690th set of parameters is tested. Time consumption: 9.5188 s. Success=0.933\n",
      "The 1695th set of parameters is tested. Time consumption: 9.6865 s. Success=0.926\n",
      "The 1700th set of parameters is tested. Time consumption: 9.4468 s. Success=0.921\n",
      "The 1705th set of parameters is tested. Time consumption: 9.6643 s. Success=0.913\n",
      "The 1710th set of parameters is tested. Time consumption: 9.7354 s. Success=0.924\n",
      "The 1715th set of parameters is tested. Time consumption: 10.2168 s. Success=0.923\n",
      "The 1720th set of parameters is tested. Time consumption: 9.5666 s. Success=0.931\n",
      "The 1725th set of parameters is tested. Time consumption: 9.9997 s. Success=0.923\n",
      "The 1730th set of parameters is tested. Time consumption: 9.5657 s. Success=0.926\n",
      "The 1735th set of parameters is tested. Time consumption: 9.5184 s. Success=0.933\n",
      "The 1740th set of parameters is tested. Time consumption: 9.7109 s. Success=0.919\n",
      "The 1745th set of parameters is tested. Time consumption: 9.4715 s. Success=0.911\n",
      "The 1750th set of parameters is tested. Time consumption: 9.3515 s. Success=0.923\n",
      "The 1755th set of parameters is tested. Time consumption: 9.4471 s. Success=0.926\n",
      "The 1760th set of parameters is tested. Time consumption: 9.6396 s. Success=0.930\n",
      "The 1765th set of parameters is tested. Time consumption: 9.6633 s. Success=0.920\n",
      "The 1770th set of parameters is tested. Time consumption: 9.9532 s. Success=0.907\n",
      "The 1775th set of parameters is tested. Time consumption: 9.7123 s. Success=0.921\n",
      "The 1780th set of parameters is tested. Time consumption: 9.8327 s. Success=0.913\n",
      "The 1785th set of parameters is tested. Time consumption: 9.6625 s. Success=0.916\n",
      "The 1790th set of parameters is tested. Time consumption: 9.6867 s. Success=0.923\n",
      "The 1795th set of parameters is tested. Time consumption: 9.3987 s. Success=0.933\n",
      "The 1800th set of parameters is tested. Time consumption: 9.4225 s. Success=0.914\n",
      "The 1805th set of parameters is tested. Time consumption: 9.7826 s. Success=0.904\n",
      "The 1810th set of parameters is tested. Time consumption: 9.6880 s. Success=0.924\n",
      "The 1815th set of parameters is tested. Time consumption: 9.5681 s. Success=0.926\n",
      "The 1820th set of parameters is tested. Time consumption: 9.9036 s. Success=0.926\n",
      "The 1825th set of parameters is tested. Time consumption: 9.7127 s. Success=0.917\n",
      "The 1830th set of parameters is tested. Time consumption: 9.9054 s. Success=0.933\n",
      "The 1835th set of parameters is tested. Time consumption: 9.9297 s. Success=0.921\n",
      "The 1840th set of parameters is tested. Time consumption: 9.3257 s. Success=0.920\n",
      "The 1845th set of parameters is tested. Time consumption: 9.8314 s. Success=0.916\n",
      "The 1850th set of parameters is tested. Time consumption: 10.0960 s. Success=0.921\n",
      "The 1855th set of parameters is tested. Time consumption: 9.5899 s. Success=0.917\n",
      "The 1860th set of parameters is tested. Time consumption: 9.5910 s. Success=0.921\n",
      "The 1865th set of parameters is tested. Time consumption: 10.2171 s. Success=0.927\n",
      "The 1870th set of parameters is tested. Time consumption: 10.3382 s. Success=0.924\n",
      "The 1875th set of parameters is tested. Time consumption: 9.7599 s. Success=0.934\n",
      "The 1880th set of parameters is tested. Time consumption: 9.4459 s. Success=0.926\n",
      "The 1885th set of parameters is tested. Time consumption: 10.0236 s. Success=0.933\n",
      "The 1890th set of parameters is tested. Time consumption: 9.7605 s. Success=0.919\n",
      "The 1895th set of parameters is tested. Time consumption: 9.9522 s. Success=0.917\n",
      "The 1900th set of parameters is tested. Time consumption: 10.1688 s. Success=0.923\n",
      "The 1905th set of parameters is tested. Time consumption: 10.3864 s. Success=0.909\n",
      "The 1910th set of parameters is tested. Time consumption: 9.8308 s. Success=0.919\n",
      "The 1915th set of parameters is tested. Time consumption: 10.2176 s. Success=0.916\n",
      "The 1920th set of parameters is tested. Time consumption: 10.1210 s. Success=0.927\n",
      "The 1925th set of parameters is tested. Time consumption: 9.7097 s. Success=0.927\n",
      "The 1930th set of parameters is tested. Time consumption: 9.6630 s. Success=0.929\n",
      "The 1935th set of parameters is tested. Time consumption: 9.9759 s. Success=0.917\n",
      "The 1940th set of parameters is tested. Time consumption: 10.4090 s. Success=0.924\n",
      "The 1945th set of parameters is tested. Time consumption: 9.7822 s. Success=0.921\n",
      "The 1950th set of parameters is tested. Time consumption: 9.9277 s. Success=0.923\n",
      "The 1955th set of parameters is tested. Time consumption: 10.1209 s. Success=0.929\n",
      "The 1960th set of parameters is tested. Time consumption: 10.1923 s. Success=0.933\n",
      "The 1965th set of parameters is tested. Time consumption: 9.9755 s. Success=0.924\n",
      "The 1970th set of parameters is tested. Time consumption: 10.0950 s. Success=0.929\n",
      "The 1975th set of parameters is tested. Time consumption: 9.9770 s. Success=0.920\n",
      "The 1980th set of parameters is tested. Time consumption: 10.0482 s. Success=0.929\n",
      "The 1985th set of parameters is tested. Time consumption: 9.7342 s. Success=0.927\n",
      "The 1990th set of parameters is tested. Time consumption: 10.2887 s. Success=0.913\n",
      "The 1995th set of parameters is tested. Time consumption: 10.1929 s. Success=0.911\n",
      "The 2000th set of parameters is tested. Time consumption: 9.7345 s. Success=0.929\n",
      "3356.5535571575165\n"
     ]
    }
   ],
   "source": [
    "#testing error\n",
    "\n",
    "success_list = []\n",
    "\n",
    "test_phase_0_list = []\n",
    "test_phase_1_list = []\n",
    "\n",
    "T0 = time.time()\n",
    "\n",
    "test_ind = []\n",
    "test_dataL = []\n",
    "test_targetL = []\n",
    "\n",
    "for l in range(0,n_digit):\n",
    "    t_ind = np.arange(train_set_size,train_set_size+test_batch_size)\n",
    "    test_dataL.append(selected_training_data[l][t_ind, :])\n",
    "    test_targetL.append(selected_training_target[l][t_ind, :])\n",
    "\n",
    "test_data = jnp.concatenate(test_dataL, axis=0)\n",
    "test_target = jnp.concatenate(test_targetL, axis=0)\n",
    "\n",
    "for k in test_W_ind:\n",
    "    test_ind = []\n",
    "    test_dataL = []\n",
    "    test_targetL = []\n",
    "\n",
    "    phase_0 = 2*np.pi*(np.random.rand(test_data.shape[0], N) - 0.5) * (batch_size>0)\n",
    "    phase_0[:, input_index] = test_data\n",
    "    phase_0 = jnp.asarray(phase_0)\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    phase1 = v_run_layered_network(phase_0, 100, list(WLL[k]), biasL[k], test_target, layer_model.structure_shape, 0)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    test_phase_0_list.append(phase_0)\n",
    "    test_phase_1_list.append(phase1)\n",
    "    \n",
    "    output = jnp.argmax(jnp.sin(phase1[:,layer_model.output_index]), axis=1)\n",
    "    target_output = jnp.argmax(jnp.sin(test_target), axis=1)\n",
    "    success = jnp.sum(output == target_output)/len(output)\n",
    "    success_list.append(success)\n",
    "    \n",
    "    print(\"The {0}th set of parameters is tested. Time consumption: {1:.4f} s. Success={2:.3f}\".format(k, t1-t0, success))\n",
    "    \n",
    "\n",
    "np.save('test_phase0h{0}'.format(Nh), np.asarray(test_phase_0_list))\n",
    "np.save('test_phase1h{0}'.format(Nh), np.asarray(test_phase_1_list))\n",
    "    \n",
    "T1 = time.time()\n",
    "print(T1-T0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e6f8da86-caa5-4127-91c4-30f7a755f7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0th set of parameters is tested. Time consumption: 6.4811 s. Success=0.111\n",
      "The 5th set of parameters is tested. Time consumption: 7.1701 s. Success=0.299\n",
      "The 10th set of parameters is tested. Time consumption: 6.9308 s. Success=0.474\n",
      "The 15th set of parameters is tested. Time consumption: 6.9312 s. Success=0.654\n",
      "The 20th set of parameters is tested. Time consumption: 6.7404 s. Success=0.739\n",
      "The 25th set of parameters is tested. Time consumption: 7.0270 s. Success=0.791\n",
      "The 30th set of parameters is tested. Time consumption: 6.8362 s. Success=0.810\n",
      "The 35th set of parameters is tested. Time consumption: 6.8603 s. Success=0.846\n",
      "The 40th set of parameters is tested. Time consumption: 6.8119 s. Success=0.863\n",
      "The 45th set of parameters is tested. Time consumption: 6.7247 s. Success=0.877\n",
      "The 50th set of parameters is tested. Time consumption: 6.8690 s. Success=0.870\n",
      "The 55th set of parameters is tested. Time consumption: 6.9901 s. Success=0.901\n",
      "The 60th set of parameters is tested. Time consumption: 7.0615 s. Success=0.909\n",
      "The 65th set of parameters is tested. Time consumption: 6.7483 s. Success=0.899\n",
      "The 70th set of parameters is tested. Time consumption: 6.8694 s. Success=0.906\n",
      "The 75th set of parameters is tested. Time consumption: 6.9893 s. Success=0.913\n",
      "The 80th set of parameters is tested. Time consumption: 6.7969 s. Success=0.934\n",
      "The 85th set of parameters is tested. Time consumption: 7.0134 s. Success=0.920\n",
      "The 90th set of parameters is tested. Time consumption: 6.8449 s. Success=0.943\n",
      "The 95th set of parameters is tested. Time consumption: 6.9654 s. Success=0.940\n",
      "The 100th set of parameters is tested. Time consumption: 6.8689 s. Success=0.954\n",
      "The 105th set of parameters is tested. Time consumption: 6.9891 s. Success=0.940\n",
      "The 110th set of parameters is tested. Time consumption: 6.8201 s. Success=0.966\n",
      "The 115th set of parameters is tested. Time consumption: 6.7963 s. Success=0.976\n",
      "The 120th set of parameters is tested. Time consumption: 6.8695 s. Success=0.947\n",
      "The 125th set of parameters is tested. Time consumption: 6.9659 s. Success=0.967\n",
      "The 130th set of parameters is tested. Time consumption: 6.9408 s. Success=0.964\n",
      "The 135th set of parameters is tested. Time consumption: 6.9409 s. Success=0.964\n",
      "The 140th set of parameters is tested. Time consumption: 6.7963 s. Success=0.960\n",
      "The 145th set of parameters is tested. Time consumption: 6.9891 s. Success=0.977\n",
      "The 150th set of parameters is tested. Time consumption: 6.9408 s. Success=0.977\n",
      "The 155th set of parameters is tested. Time consumption: 6.8931 s. Success=0.967\n",
      "The 160th set of parameters is tested. Time consumption: 6.8689 s. Success=0.966\n",
      "The 165th set of parameters is tested. Time consumption: 6.9410 s. Success=0.970\n",
      "The 170th set of parameters is tested. Time consumption: 6.9890 s. Success=0.973\n",
      "The 175th set of parameters is tested. Time consumption: 6.8449 s. Success=0.970\n",
      "The 180th set of parameters is tested. Time consumption: 7.1104 s. Success=0.977\n",
      "The 185th set of parameters is tested. Time consumption: 6.8694 s. Success=0.960\n",
      "The 190th set of parameters is tested. Time consumption: 6.8449 s. Success=0.977\n",
      "The 195th set of parameters is tested. Time consumption: 6.9174 s. Success=0.977\n",
      "The 200th set of parameters is tested. Time consumption: 6.9411 s. Success=0.971\n",
      "The 205th set of parameters is tested. Time consumption: 7.2064 s. Success=0.977\n",
      "The 210th set of parameters is tested. Time consumption: 6.8454 s. Success=0.976\n",
      "The 215th set of parameters is tested. Time consumption: 6.7973 s. Success=0.970\n",
      "The 220th set of parameters is tested. Time consumption: 6.9898 s. Success=0.969\n",
      "The 225th set of parameters is tested. Time consumption: 7.2308 s. Success=0.973\n",
      "The 230th set of parameters is tested. Time consumption: 6.8690 s. Success=0.986\n",
      "The 235th set of parameters is tested. Time consumption: 7.0851 s. Success=0.987\n",
      "The 240th set of parameters is tested. Time consumption: 7.0371 s. Success=0.974\n",
      "The 245th set of parameters is tested. Time consumption: 7.0127 s. Success=0.980\n",
      "The 250th set of parameters is tested. Time consumption: 7.2057 s. Success=0.970\n",
      "The 255th set of parameters is tested. Time consumption: 7.0376 s. Success=0.976\n",
      "The 260th set of parameters is tested. Time consumption: 6.9650 s. Success=0.973\n",
      "The 265th set of parameters is tested. Time consumption: 7.0856 s. Success=0.986\n",
      "The 270th set of parameters is tested. Time consumption: 6.9647 s. Success=0.987\n",
      "The 275th set of parameters is tested. Time consumption: 7.0857 s. Success=0.979\n",
      "The 280th set of parameters is tested. Time consumption: 6.9890 s. Success=0.984\n",
      "The 285th set of parameters is tested. Time consumption: 7.1824 s. Success=0.986\n",
      "The 290th set of parameters is tested. Time consumption: 7.1106 s. Success=0.979\n",
      "The 295th set of parameters is tested. Time consumption: 7.1577 s. Success=0.983\n",
      "The 300th set of parameters is tested. Time consumption: 7.2294 s. Success=0.964\n",
      "The 305th set of parameters is tested. Time consumption: 6.9420 s. Success=0.981\n",
      "The 310th set of parameters is tested. Time consumption: 7.2791 s. Success=0.990\n",
      "The 315th set of parameters is tested. Time consumption: 7.1106 s. Success=0.983\n",
      "The 320th set of parameters is tested. Time consumption: 7.1818 s. Success=0.990\n",
      "The 325th set of parameters is tested. Time consumption: 7.1095 s. Success=0.973\n",
      "The 330th set of parameters is tested. Time consumption: 7.1572 s. Success=0.977\n",
      "The 335th set of parameters is tested. Time consumption: 7.1574 s. Success=0.979\n",
      "The 340th set of parameters is tested. Time consumption: 7.3500 s. Success=0.977\n",
      "The 345th set of parameters is tested. Time consumption: 7.3514 s. Success=0.986\n",
      "The 350th set of parameters is tested. Time consumption: 7.3272 s. Success=0.966\n",
      "The 355th set of parameters is tested. Time consumption: 7.0855 s. Success=0.987\n",
      "The 360th set of parameters is tested. Time consumption: 7.3259 s. Success=0.970\n",
      "The 365th set of parameters is tested. Time consumption: 7.2058 s. Success=0.990\n",
      "The 370th set of parameters is tested. Time consumption: 7.0374 s. Success=0.990\n",
      "The 375th set of parameters is tested. Time consumption: 7.3501 s. Success=0.984\n",
      "The 380th set of parameters is tested. Time consumption: 7.3513 s. Success=0.987\n",
      "The 385th set of parameters is tested. Time consumption: 7.2785 s. Success=0.981\n",
      "The 390th set of parameters is tested. Time consumption: 7.3264 s. Success=0.981\n",
      "The 395th set of parameters is tested. Time consumption: 7.1577 s. Success=0.990\n",
      "The 400th set of parameters is tested. Time consumption: 7.3979 s. Success=0.984\n",
      "The 405th set of parameters is tested. Time consumption: 7.0608 s. Success=0.974\n",
      "The 410th set of parameters is tested. Time consumption: 7.1332 s. Success=0.989\n",
      "The 415th set of parameters is tested. Time consumption: 7.4224 s. Success=0.981\n",
      "The 420th set of parameters is tested. Time consumption: 7.3019 s. Success=0.991\n",
      "The 425th set of parameters is tested. Time consumption: 7.1100 s. Success=0.980\n",
      "The 430th set of parameters is tested. Time consumption: 7.4229 s. Success=0.984\n",
      "The 435th set of parameters is tested. Time consumption: 7.1575 s. Success=0.977\n",
      "The 440th set of parameters is tested. Time consumption: 7.5671 s. Success=0.991\n",
      "The 445th set of parameters is tested. Time consumption: 7.3984 s. Success=0.980\n",
      "The 450th set of parameters is tested. Time consumption: 7.6150 s. Success=0.983\n",
      "The 455th set of parameters is tested. Time consumption: 7.3990 s. Success=0.983\n",
      "The 460th set of parameters is tested. Time consumption: 7.3022 s. Success=0.981\n",
      "The 465th set of parameters is tested. Time consumption: 7.3503 s. Success=0.989\n",
      "The 470th set of parameters is tested. Time consumption: 7.2784 s. Success=0.979\n",
      "The 475th set of parameters is tested. Time consumption: 7.3499 s. Success=0.976\n",
      "The 480th set of parameters is tested. Time consumption: 7.4471 s. Success=0.980\n",
      "The 485th set of parameters is tested. Time consumption: 7.3025 s. Success=0.983\n",
      "The 490th set of parameters is tested. Time consumption: 7.4705 s. Success=0.979\n",
      "The 495th set of parameters is tested. Time consumption: 7.3981 s. Success=0.994\n",
      "The 500th set of parameters is tested. Time consumption: 7.6869 s. Success=0.970\n",
      "The 505th set of parameters is tested. Time consumption: 7.2297 s. Success=0.991\n",
      "The 510th set of parameters is tested. Time consumption: 7.6393 s. Success=0.983\n",
      "The 515th set of parameters is tested. Time consumption: 7.5186 s. Success=0.987\n",
      "The 520th set of parameters is tested. Time consumption: 7.4467 s. Success=0.989\n",
      "The 525th set of parameters is tested. Time consumption: 7.5675 s. Success=0.986\n",
      "The 530th set of parameters is tested. Time consumption: 7.5916 s. Success=0.980\n",
      "The 535th set of parameters is tested. Time consumption: 7.8073 s. Success=0.979\n",
      "The 540th set of parameters is tested. Time consumption: 7.6872 s. Success=0.981\n",
      "The 545th set of parameters is tested. Time consumption: 7.5903 s. Success=0.981\n",
      "The 550th set of parameters is tested. Time consumption: 7.8555 s. Success=0.989\n",
      "The 555th set of parameters is tested. Time consumption: 7.7360 s. Success=0.977\n",
      "The 560th set of parameters is tested. Time consumption: 7.4940 s. Success=0.986\n",
      "The 565th set of parameters is tested. Time consumption: 7.6151 s. Success=0.983\n",
      "The 570th set of parameters is tested. Time consumption: 7.7841 s. Success=0.987\n",
      "The 575th set of parameters is tested. Time consumption: 7.6148 s. Success=0.976\n",
      "The 580th set of parameters is tested. Time consumption: 7.4961 s. Success=0.976\n",
      "The 585th set of parameters is tested. Time consumption: 8.1463 s. Success=0.991\n",
      "The 590th set of parameters is tested. Time consumption: 7.7850 s. Success=0.971\n",
      "The 595th set of parameters is tested. Time consumption: 7.5197 s. Success=0.984\n",
      "The 600th set of parameters is tested. Time consumption: 7.5192 s. Success=0.977\n",
      "The 605th set of parameters is tested. Time consumption: 7.6391 s. Success=0.986\n",
      "The 610th set of parameters is tested. Time consumption: 7.9050 s. Success=0.989\n",
      "The 615th set of parameters is tested. Time consumption: 7.8333 s. Success=0.991\n",
      "The 620th set of parameters is tested. Time consumption: 7.6399 s. Success=0.989\n",
      "The 625th set of parameters is tested. Time consumption: 7.7359 s. Success=0.987\n",
      "The 630th set of parameters is tested. Time consumption: 7.3984 s. Success=0.980\n",
      "The 635th set of parameters is tested. Time consumption: 7.5423 s. Success=0.981\n",
      "The 640th set of parameters is tested. Time consumption: 7.7835 s. Success=0.984\n",
      "The 645th set of parameters is tested. Time consumption: 7.6632 s. Success=0.981\n",
      "The 650th set of parameters is tested. Time consumption: 7.8563 s. Success=0.987\n",
      "The 655th set of parameters is tested. Time consumption: 7.6650 s. Success=0.987\n",
      "The 660th set of parameters is tested. Time consumption: 8.0245 s. Success=0.990\n",
      "The 665th set of parameters is tested. Time consumption: 7.7352 s. Success=0.986\n",
      "The 670th set of parameters is tested. Time consumption: 7.8092 s. Success=0.989\n",
      "The 675th set of parameters is tested. Time consumption: 7.8812 s. Success=0.990\n",
      "The 680th set of parameters is tested. Time consumption: 7.7838 s. Success=0.986\n",
      "The 685th set of parameters is tested. Time consumption: 7.6163 s. Success=0.989\n",
      "The 690th set of parameters is tested. Time consumption: 7.6631 s. Success=0.986\n",
      "The 695th set of parameters is tested. Time consumption: 7.7842 s. Success=0.986\n",
      "The 700th set of parameters is tested. Time consumption: 7.8080 s. Success=0.989\n",
      "The 705th set of parameters is tested. Time consumption: 7.8070 s. Success=0.990\n",
      "The 710th set of parameters is tested. Time consumption: 7.9038 s. Success=0.991\n",
      "The 715th set of parameters is tested. Time consumption: 8.2655 s. Success=0.981\n",
      "The 720th set of parameters is tested. Time consumption: 8.1688 s. Success=0.979\n",
      "The 725th set of parameters is tested. Time consumption: 8.2168 s. Success=0.984\n",
      "The 730th set of parameters is tested. Time consumption: 7.7845 s. Success=0.979\n",
      "The 735th set of parameters is tested. Time consumption: 7.9050 s. Success=0.976\n",
      "The 740th set of parameters is tested. Time consumption: 8.0727 s. Success=0.989\n",
      "The 745th set of parameters is tested. Time consumption: 7.9045 s. Success=0.993\n",
      "The 750th set of parameters is tested. Time consumption: 8.2175 s. Success=0.980\n",
      "The 755th set of parameters is tested. Time consumption: 7.9285 s. Success=0.983\n",
      "The 760th set of parameters is tested. Time consumption: 8.1936 s. Success=0.984\n",
      "The 765th set of parameters is tested. Time consumption: 7.5672 s. Success=0.990\n",
      "The 770th set of parameters is tested. Time consumption: 7.8075 s. Success=0.981\n",
      "The 775th set of parameters is tested. Time consumption: 8.1208 s. Success=0.987\n",
      "The 780th set of parameters is tested. Time consumption: 7.9043 s. Success=0.990\n",
      "The 785th set of parameters is tested. Time consumption: 8.2172 s. Success=0.987\n",
      "The 790th set of parameters is tested. Time consumption: 7.9766 s. Success=0.991\n",
      "The 795th set of parameters is tested. Time consumption: 7.9279 s. Success=0.983\n",
      "The 800th set of parameters is tested. Time consumption: 8.0004 s. Success=0.993\n",
      "The 805th set of parameters is tested. Time consumption: 8.0486 s. Success=0.989\n",
      "The 810th set of parameters is tested. Time consumption: 7.8803 s. Success=0.990\n",
      "The 815th set of parameters is tested. Time consumption: 8.2176 s. Success=0.986\n",
      "The 820th set of parameters is tested. Time consumption: 7.8801 s. Success=0.984\n",
      "The 825th set of parameters is tested. Time consumption: 8.1690 s. Success=0.983\n",
      "The 830th set of parameters is tested. Time consumption: 8.2900 s. Success=0.977\n",
      "The 835th set of parameters is tested. Time consumption: 8.6990 s. Success=0.996\n",
      "The 840th set of parameters is tested. Time consumption: 8.0243 s. Success=0.989\n",
      "The 845th set of parameters is tested. Time consumption: 8.4334 s. Success=0.979\n",
      "The 850th set of parameters is tested. Time consumption: 8.1438 s. Success=0.987\n",
      "The 855th set of parameters is tested. Time consumption: 8.5543 s. Success=0.981\n",
      "The 860th set of parameters is tested. Time consumption: 7.9299 s. Success=0.990\n",
      "The 865th set of parameters is tested. Time consumption: 8.4117 s. Success=0.994\n",
      "The 870th set of parameters is tested. Time consumption: 8.1467 s. Success=0.986\n",
      "The 875th set of parameters is tested. Time consumption: 8.1945 s. Success=0.994\n",
      "The 880th set of parameters is tested. Time consumption: 8.5304 s. Success=0.979\n",
      "The 885th set of parameters is tested. Time consumption: 8.2657 s. Success=0.980\n",
      "The 890th set of parameters is tested. Time consumption: 8.0243 s. Success=0.977\n",
      "The 895th set of parameters is tested. Time consumption: 8.4336 s. Success=0.983\n",
      "The 900th set of parameters is tested. Time consumption: 8.2643 s. Success=0.990\n",
      "The 905th set of parameters is tested. Time consumption: 8.0975 s. Success=0.990\n",
      "The 910th set of parameters is tested. Time consumption: 8.6027 s. Success=0.986\n",
      "The 915th set of parameters is tested. Time consumption: 8.3615 s. Success=0.987\n",
      "The 920th set of parameters is tested. Time consumption: 8.5050 s. Success=0.984\n",
      "The 925th set of parameters is tested. Time consumption: 8.3854 s. Success=0.987\n",
      "The 930th set of parameters is tested. Time consumption: 8.3135 s. Success=0.983\n",
      "The 935th set of parameters is tested. Time consumption: 8.1686 s. Success=0.983\n",
      "The 940th set of parameters is tested. Time consumption: 8.6276 s. Success=0.991\n",
      "The 945th set of parameters is tested. Time consumption: 8.2893 s. Success=0.980\n",
      "The 950th set of parameters is tested. Time consumption: 8.4097 s. Success=0.996\n",
      "The 955th set of parameters is tested. Time consumption: 8.5060 s. Success=0.991\n",
      "The 960th set of parameters is tested. Time consumption: 8.5055 s. Success=0.987\n",
      "The 965th set of parameters is tested. Time consumption: 8.5053 s. Success=0.989\n",
      "The 970th set of parameters is tested. Time consumption: 8.1445 s. Success=0.993\n",
      "The 975th set of parameters is tested. Time consumption: 8.3370 s. Success=0.990\n",
      "The 980th set of parameters is tested. Time consumption: 8.4827 s. Success=0.986\n",
      "The 985th set of parameters is tested. Time consumption: 8.7492 s. Success=0.983\n",
      "The 990th set of parameters is tested. Time consumption: 8.7729 s. Success=0.986\n",
      "The 995th set of parameters is tested. Time consumption: 8.3618 s. Success=0.993\n",
      "The 1000th set of parameters is tested. Time consumption: 8.5057 s. Success=0.990\n",
      "The 1005th set of parameters is tested. Time consumption: 8.6744 s. Success=0.993\n",
      "The 1010th set of parameters is tested. Time consumption: 8.7963 s. Success=0.983\n",
      "The 1015th set of parameters is tested. Time consumption: 8.5553 s. Success=0.989\n",
      "The 1020th set of parameters is tested. Time consumption: 8.6273 s. Success=0.989\n",
      "The 1025th set of parameters is tested. Time consumption: 8.8203 s. Success=0.987\n",
      "The 1030th set of parameters is tested. Time consumption: 8.3384 s. Success=0.991\n",
      "The 1035th set of parameters is tested. Time consumption: 8.5544 s. Success=0.993\n",
      "The 1040th set of parameters is tested. Time consumption: 8.4818 s. Success=0.984\n",
      "The 1045th set of parameters is tested. Time consumption: 8.5539 s. Success=0.993\n",
      "The 1050th set of parameters is tested. Time consumption: 8.6984 s. Success=0.993\n",
      "The 1055th set of parameters is tested. Time consumption: 8.4579 s. Success=0.991\n",
      "The 1060th set of parameters is tested. Time consumption: 8.4817 s. Success=0.987\n",
      "The 1065th set of parameters is tested. Time consumption: 8.8197 s. Success=0.986\n",
      "The 1070th set of parameters is tested. Time consumption: 8.4820 s. Success=0.981\n",
      "The 1075th set of parameters is tested. Time consumption: 8.7958 s. Success=0.981\n",
      "The 1080th set of parameters is tested. Time consumption: 8.4336 s. Success=0.993\n",
      "The 1085th set of parameters is tested. Time consumption: 8.6741 s. Success=0.987\n",
      "The 1090th set of parameters is tested. Time consumption: 8.6268 s. Success=0.983\n",
      "The 1095th set of parameters is tested. Time consumption: 8.5787 s. Success=0.990\n",
      "The 1100th set of parameters is tested. Time consumption: 8.4820 s. Success=0.996\n",
      "The 1105th set of parameters is tested. Time consumption: 9.1814 s. Success=0.987\n",
      "The 1110th set of parameters is tested. Time consumption: 8.7462 s. Success=0.991\n",
      "The 1115th set of parameters is tested. Time consumption: 8.7713 s. Success=0.987\n",
      "The 1120th set of parameters is tested. Time consumption: 8.8922 s. Success=0.991\n",
      "The 1125th set of parameters is tested. Time consumption: 8.4572 s. Success=0.979\n",
      "The 1130th set of parameters is tested. Time consumption: 8.8920 s. Success=0.990\n",
      "The 1135th set of parameters is tested. Time consumption: 8.6261 s. Success=0.987\n",
      "The 1140th set of parameters is tested. Time consumption: 9.1085 s. Success=0.991\n",
      "The 1145th set of parameters is tested. Time consumption: 8.8189 s. Success=0.993\n",
      "The 1150th set of parameters is tested. Time consumption: 8.8663 s. Success=0.997\n",
      "The 1155th set of parameters is tested. Time consumption: 8.8423 s. Success=0.989\n",
      "The 1160th set of parameters is tested. Time consumption: 8.7226 s. Success=0.996\n",
      "The 1165th set of parameters is tested. Time consumption: 8.5779 s. Success=0.980\n",
      "The 1170th set of parameters is tested. Time consumption: 8.9149 s. Success=0.983\n",
      "The 1175th set of parameters is tested. Time consumption: 8.7463 s. Success=0.993\n",
      "The 1180th set of parameters is tested. Time consumption: 9.0829 s. Success=0.991\n",
      "The 1185th set of parameters is tested. Time consumption: 8.6744 s. Success=0.993\n",
      "The 1190th set of parameters is tested. Time consumption: 9.0353 s. Success=0.986\n",
      "The 1195th set of parameters is tested. Time consumption: 9.2772 s. Success=0.983\n",
      "The 1200th set of parameters is tested. Time consumption: 9.1804 s. Success=0.993\n",
      "The 1205th set of parameters is tested. Time consumption: 8.6256 s. Success=0.976\n",
      "The 1210th set of parameters is tested. Time consumption: 8.6268 s. Success=0.990\n",
      "The 1215th set of parameters is tested. Time consumption: 9.0110 s. Success=0.987\n",
      "The 1220th set of parameters is tested. Time consumption: 8.7940 s. Success=0.987\n",
      "The 1225th set of parameters is tested. Time consumption: 9.1791 s. Success=0.990\n",
      "The 1230th set of parameters is tested. Time consumption: 8.5769 s. Success=0.994\n",
      "The 1235th set of parameters is tested. Time consumption: 8.6741 s. Success=0.986\n",
      "The 1240th set of parameters is tested. Time consumption: 8.9633 s. Success=0.987\n",
      "The 1245th set of parameters is tested. Time consumption: 9.1795 s. Success=0.991\n",
      "The 1250th set of parameters is tested. Time consumption: 8.7712 s. Success=0.984\n",
      "The 1255th set of parameters is tested. Time consumption: 8.9401 s. Success=0.986\n",
      "The 1260th set of parameters is tested. Time consumption: 9.4924 s. Success=0.986\n",
      "The 1265th set of parameters is tested. Time consumption: 8.9624 s. Success=0.993\n",
      "The 1270th set of parameters is tested. Time consumption: 8.9868 s. Success=0.993\n",
      "The 1275th set of parameters is tested. Time consumption: 8.8905 s. Success=0.986\n",
      "The 1280th set of parameters is tested. Time consumption: 8.8424 s. Success=0.996\n",
      "The 1285th set of parameters is tested. Time consumption: 9.1077 s. Success=0.983\n",
      "The 1290th set of parameters is tested. Time consumption: 8.6499 s. Success=0.986\n",
      "The 1295th set of parameters is tested. Time consumption: 8.8437 s. Success=0.996\n",
      "The 1300th set of parameters is tested. Time consumption: 9.2537 s. Success=0.991\n",
      "The 1305th set of parameters is tested. Time consumption: 9.2775 s. Success=0.991\n",
      "The 1310th set of parameters is tested. Time consumption: 8.8440 s. Success=0.993\n",
      "The 1315th set of parameters is tested. Time consumption: 9.0360 s. Success=0.991\n",
      "The 1320th set of parameters is tested. Time consumption: 8.8679 s. Success=0.987\n",
      "The 1325th set of parameters is tested. Time consumption: 8.8428 s. Success=0.991\n",
      "The 1330th set of parameters is tested. Time consumption: 9.0110 s. Success=0.991\n",
      "The 1335th set of parameters is tested. Time consumption: 9.1072 s. Success=0.993\n",
      "The 1340th set of parameters is tested. Time consumption: 9.1560 s. Success=0.987\n",
      "The 1345th set of parameters is tested. Time consumption: 9.3238 s. Success=0.990\n",
      "The 1350th set of parameters is tested. Time consumption: 8.9629 s. Success=0.990\n",
      "The 1355th set of parameters is tested. Time consumption: 9.1074 s. Success=0.989\n",
      "The 1360th set of parameters is tested. Time consumption: 9.2766 s. Success=0.993\n",
      "The 1365th set of parameters is tested. Time consumption: 9.4208 s. Success=0.981\n",
      "The 1370th set of parameters is tested. Time consumption: 8.9887 s. Success=0.991\n",
      "The 1375th set of parameters is tested. Time consumption: 9.1566 s. Success=0.994\n",
      "The 1380th set of parameters is tested. Time consumption: 8.8428 s. Success=0.986\n",
      "The 1385th set of parameters is tested. Time consumption: 9.1074 s. Success=0.991\n",
      "The 1390th set of parameters is tested. Time consumption: 9.3486 s. Success=0.993\n",
      "The 1395th set of parameters is tested. Time consumption: 9.0114 s. Success=0.987\n",
      "The 1400th set of parameters is tested. Time consumption: 8.9156 s. Success=0.996\n",
      "The 1405th set of parameters is tested. Time consumption: 9.1083 s. Success=0.990\n",
      "The 1410th set of parameters is tested. Time consumption: 9.2291 s. Success=0.980\n",
      "The 1415th set of parameters is tested. Time consumption: 9.0121 s. Success=0.977\n",
      "The 1420th set of parameters is tested. Time consumption: 9.1328 s. Success=0.987\n",
      "The 1425th set of parameters is tested. Time consumption: 9.0603 s. Success=0.989\n",
      "The 1430th set of parameters is tested. Time consumption: 9.0353 s. Success=0.984\n",
      "The 1435th set of parameters is tested. Time consumption: 9.1077 s. Success=0.971\n",
      "The 1440th set of parameters is tested. Time consumption: 9.3969 s. Success=0.983\n",
      "The 1445th set of parameters is tested. Time consumption: 9.0105 s. Success=0.994\n",
      "The 1450th set of parameters is tested. Time consumption: 9.2284 s. Success=0.990\n",
      "The 1455th set of parameters is tested. Time consumption: 9.2275 s. Success=0.990\n",
      "The 1460th set of parameters is tested. Time consumption: 9.0104 s. Success=0.989\n",
      "The 1465th set of parameters is tested. Time consumption: 9.3714 s. Success=0.996\n",
      "The 1470th set of parameters is tested. Time consumption: 8.8668 s. Success=0.987\n",
      "The 1475th set of parameters is tested. Time consumption: 9.1548 s. Success=0.987\n",
      "The 1480th set of parameters is tested. Time consumption: 9.3721 s. Success=0.987\n",
      "The 1485th set of parameters is tested. Time consumption: 9.3960 s. Success=0.991\n",
      "The 1490th set of parameters is tested. Time consumption: 9.3003 s. Success=0.989\n",
      "The 1495th set of parameters is tested. Time consumption: 9.3003 s. Success=0.994\n",
      "The 1500th set of parameters is tested. Time consumption: 9.2037 s. Success=0.986\n",
      "The 1505th set of parameters is tested. Time consumption: 9.3962 s. Success=0.994\n",
      "The 1510th set of parameters is tested. Time consumption: 9.5651 s. Success=0.996\n",
      "The 1515th set of parameters is tested. Time consumption: 9.6849 s. Success=0.991\n",
      "The 1520th set of parameters is tested. Time consumption: 9.3963 s. Success=0.991\n",
      "The 1525th set of parameters is tested. Time consumption: 9.6370 s. Success=0.987\n",
      "The 1530th set of parameters is tested. Time consumption: 9.3236 s. Success=0.991\n",
      "The 1535th set of parameters is tested. Time consumption: 9.3721 s. Success=0.991\n",
      "The 1540th set of parameters is tested. Time consumption: 9.5182 s. Success=0.989\n",
      "The 1545th set of parameters is tested. Time consumption: 9.3014 s. Success=0.991\n",
      "The 1550th set of parameters is tested. Time consumption: 9.1084 s. Success=0.993\n",
      "The 1555th set of parameters is tested. Time consumption: 9.6621 s. Success=0.991\n",
      "The 1560th set of parameters is tested. Time consumption: 9.8071 s. Success=0.991\n",
      "The 1565th set of parameters is tested. Time consumption: 9.8541 s. Success=0.991\n",
      "The 1570th set of parameters is tested. Time consumption: 9.4933 s. Success=0.991\n",
      "The 1575th set of parameters is tested. Time consumption: 9.4926 s. Success=0.987\n",
      "The 1580th set of parameters is tested. Time consumption: 9.8289 s. Success=0.996\n",
      "The 1585th set of parameters is tested. Time consumption: 9.4685 s. Success=0.984\n",
      "The 1590th set of parameters is tested. Time consumption: 9.2752 s. Success=0.993\n",
      "The 1595th set of parameters is tested. Time consumption: 9.5901 s. Success=0.996\n",
      "The 1600th set of parameters is tested. Time consumption: 9.8077 s. Success=0.991\n",
      "The 1605th set of parameters is tested. Time consumption: 9.3002 s. Success=0.994\n",
      "The 1610th set of parameters is tested. Time consumption: 9.9012 s. Success=0.991\n",
      "The 1615th set of parameters is tested. Time consumption: 9.7335 s. Success=0.991\n",
      "The 1620th set of parameters is tested. Time consumption: 9.2994 s. Success=0.993\n",
      "The 1625th set of parameters is tested. Time consumption: 9.7332 s. Success=0.991\n",
      "The 1630th set of parameters is tested. Time consumption: 9.8289 s. Success=0.990\n",
      "The 1635th set of parameters is tested. Time consumption: 9.4438 s. Success=0.991\n",
      "The 1640th set of parameters is tested. Time consumption: 9.7578 s. Success=0.989\n",
      "The 1645th set of parameters is tested. Time consumption: 9.6387 s. Success=0.983\n",
      "The 1650th set of parameters is tested. Time consumption: 9.3252 s. Success=0.994\n",
      "The 1655th set of parameters is tested. Time consumption: 9.3245 s. Success=0.983\n",
      "The 1660th set of parameters is tested. Time consumption: 9.3728 s. Success=0.990\n",
      "The 1665th set of parameters is tested. Time consumption: 10.0478 s. Success=0.987\n",
      "The 1670th set of parameters is tested. Time consumption: 9.5172 s. Success=0.994\n",
      "The 1675th set of parameters is tested. Time consumption: 9.8066 s. Success=0.994\n",
      "The 1680th set of parameters is tested. Time consumption: 9.6858 s. Success=0.990\n",
      "The 1685th set of parameters is tested. Time consumption: 9.8301 s. Success=0.989\n",
      "The 1690th set of parameters is tested. Time consumption: 9.8774 s. Success=0.990\n",
      "The 1695th set of parameters is tested. Time consumption: 9.7332 s. Success=0.993\n",
      "The 1700th set of parameters is tested. Time consumption: 9.3970 s. Success=0.987\n",
      "The 1705th set of parameters is tested. Time consumption: 9.5405 s. Success=0.989\n",
      "The 1710th set of parameters is tested. Time consumption: 9.4920 s. Success=0.983\n",
      "The 1715th set of parameters is tested. Time consumption: 9.7326 s. Success=0.987\n",
      "The 1720th set of parameters is tested. Time consumption: 9.6608 s. Success=0.991\n",
      "The 1725th set of parameters is tested. Time consumption: 10.4074 s. Success=0.991\n",
      "The 1730th set of parameters is tested. Time consumption: 10.1672 s. Success=0.993\n",
      "The 1735th set of parameters is tested. Time consumption: 9.4221 s. Success=0.987\n",
      "The 1740th set of parameters is tested. Time consumption: 9.5407 s. Success=0.993\n",
      "The 1745th set of parameters is tested. Time consumption: 9.4920 s. Success=0.991\n",
      "The 1750th set of parameters is tested. Time consumption: 9.5407 s. Success=0.991\n",
      "The 1755th set of parameters is tested. Time consumption: 9.6622 s. Success=0.993\n",
      "The 1760th set of parameters is tested. Time consumption: 9.6632 s. Success=0.987\n",
      "The 1765th set of parameters is tested. Time consumption: 9.5906 s. Success=0.994\n",
      "The 1770th set of parameters is tested. Time consumption: 9.8791 s. Success=0.991\n",
      "The 1775th set of parameters is tested. Time consumption: 9.9280 s. Success=0.987\n",
      "The 1780th set of parameters is tested. Time consumption: 9.7336 s. Success=0.991\n",
      "The 1785th set of parameters is tested. Time consumption: 9.9503 s. Success=0.989\n",
      "The 1790th set of parameters is tested. Time consumption: 10.3843 s. Success=0.999\n",
      "The 1795th set of parameters is tested. Time consumption: 9.6148 s. Success=0.987\n",
      "The 1800th set of parameters is tested. Time consumption: 9.2997 s. Success=0.990\n",
      "The 1805th set of parameters is tested. Time consumption: 9.9985 s. Success=0.986\n",
      "The 1810th set of parameters is tested. Time consumption: 9.9260 s. Success=0.991\n",
      "The 1815th set of parameters is tested. Time consumption: 10.0708 s. Success=0.994\n",
      "The 1820th set of parameters is tested. Time consumption: 9.7579 s. Success=0.989\n",
      "The 1825th set of parameters is tested. Time consumption: 10.0230 s. Success=0.989\n",
      "The 1830th set of parameters is tested. Time consumption: 10.1904 s. Success=0.984\n",
      "The 1835th set of parameters is tested. Time consumption: 9.5173 s. Success=0.991\n",
      "The 1840th set of parameters is tested. Time consumption: 9.9746 s. Success=0.994\n",
      "The 1845th set of parameters is tested. Time consumption: 9.7093 s. Success=0.994\n",
      "The 1850th set of parameters is tested. Time consumption: 9.6626 s. Success=0.987\n",
      "The 1855th set of parameters is tested. Time consumption: 10.3115 s. Success=0.993\n",
      "The 1860th set of parameters is tested. Time consumption: 10.1914 s. Success=0.991\n",
      "The 1865th set of parameters is tested. Time consumption: 9.8537 s. Success=0.984\n",
      "The 1870th set of parameters is tested. Time consumption: 9.9504 s. Success=0.991\n",
      "The 1875th set of parameters is tested. Time consumption: 10.0226 s. Success=0.994\n",
      "The 1880th set of parameters is tested. Time consumption: 9.8774 s. Success=0.993\n",
      "The 1885th set of parameters is tested. Time consumption: 9.6136 s. Success=0.997\n",
      "The 1890th set of parameters is tested. Time consumption: 9.8535 s. Success=0.991\n",
      "The 1895th set of parameters is tested. Time consumption: 10.1906 s. Success=0.994\n",
      "The 1900th set of parameters is tested. Time consumption: 9.9264 s. Success=0.990\n",
      "The 1905th set of parameters is tested. Time consumption: 10.1671 s. Success=0.999\n",
      "The 1910th set of parameters is tested. Time consumption: 9.9274 s. Success=0.991\n",
      "The 1915th set of parameters is tested. Time consumption: 10.3601 s. Success=0.990\n",
      "The 1920th set of parameters is tested. Time consumption: 10.2650 s. Success=0.993\n",
      "The 1925th set of parameters is tested. Time consumption: 10.3120 s. Success=0.990\n",
      "The 1930th set of parameters is tested. Time consumption: 9.9507 s. Success=0.991\n",
      "The 1935th set of parameters is tested. Time consumption: 9.7814 s. Success=0.986\n",
      "The 1940th set of parameters is tested. Time consumption: 9.8307 s. Success=0.991\n",
      "The 1945th set of parameters is tested. Time consumption: 9.7816 s. Success=0.990\n",
      "The 1950th set of parameters is tested. Time consumption: 10.4326 s. Success=0.996\n",
      "The 1955th set of parameters is tested. Time consumption: 10.2400 s. Success=0.994\n",
      "The 1960th set of parameters is tested. Time consumption: 10.0239 s. Success=0.990\n",
      "The 1965th set of parameters is tested. Time consumption: 10.1686 s. Success=0.994\n",
      "The 1970th set of parameters is tested. Time consumption: 9.9028 s. Success=0.991\n",
      "The 1975th set of parameters is tested. Time consumption: 10.3615 s. Success=0.994\n",
      "The 1980th set of parameters is tested. Time consumption: 9.9756 s. Success=0.989\n",
      "The 1985th set of parameters is tested. Time consumption: 10.1202 s. Success=0.983\n",
      "The 1990th set of parameters is tested. Time consumption: 9.7825 s. Success=0.989\n",
      "The 1995th set of parameters is tested. Time consumption: 10.0234 s. Success=0.984\n",
      "The 2000th set of parameters is tested. Time consumption: 9.6154 s. Success=0.996\n",
      "3405.6514184474945\n"
     ]
    }
   ],
   "source": [
    "#training error\n",
    "\n",
    "training_success_list = []\n",
    "\n",
    "train_phase_0_list = []\n",
    "train_phase_1_list = []\n",
    "\n",
    "T0 = time.time()\n",
    "\n",
    "for k in test_W_ind:\n",
    "    test_ind = []\n",
    "    test_dataL = []\n",
    "    test_targetL = []\n",
    "\n",
    "    for l in range(0,n_digit):\n",
    "        t_ind = np.random.randint(0, train_set_size, test_batch_size)\n",
    "        test_ind.append(t_ind)\n",
    "        test_dataL.append(selected_training_data[l][t_ind, :])\n",
    "        test_targetL.append(selected_training_target[l][t_ind, :])\n",
    "\n",
    "    test_data = jnp.concatenate(test_dataL, axis=0)\n",
    "    test_target = jnp.concatenate(test_targetL, axis=0)\n",
    "\n",
    "    phase_0 = 2*np.pi*(np.random.rand(test_data.shape[0], N) - 0.5) * (batch_size>0)\n",
    "    phase_0[:, input_index] = test_data\n",
    "    phase_0 = jnp.asarray(phase_0)\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    phase1 = v_run_layered_network(phase_0, 100, list(WLL[k]), biasL[k], test_target, layer_model.structure_shape, 0)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    output = jnp.argmax(jnp.sin(phase1[:,layer_model.output_index]), axis=1)\n",
    "    target_output = jnp.argmax(jnp.sin(test_target), axis=1)\n",
    "    success = jnp.sum(output == target_output)/len(output)\n",
    "    training_success_list.append(success)\n",
    "    \n",
    "    train_phase_0_list.append(phase_0)\n",
    "    train_phase_1_list.append(phase1)\n",
    "    \n",
    "    print(\"The {0}th set of parameters is tested. Time consumption: {1:.4f} s. Success={2:.3f}\".format(k, t1-t0, success))\n",
    "    \n",
    "\n",
    "np.save('train_phase0h{0}'.format(Nh), np.asarray(train_phase_0_list))\n",
    "np.save('train_phase1h{0}'.format(Nh), np.asarray(train_phase_1_list))\n",
    "\n",
    "T1 = time.time()\n",
    "print(T1-T0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "96ab4da3-f437-4581-8263-891fb9409097",
   "metadata": {},
   "outputs": [],
   "source": [
    "nslice = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de40f621-ab79-4616-85d6-25ec099e7cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14a68410c610>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nslice = 2000\n",
    "zlim = 0.2\n",
    "plt.imshow(WLL[nslice][0]-WLL[0][0], cmap='seismic', vmin=-zlim, vmax=zlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b53aa2ab-46c1-4f35-bd2a-07cf67a39e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14a1a806ea30>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mat_W = WLL[nslice][0]-WLL[0][0]\n",
    "plt.imshow(mat_W[:,6].reshape(8,8), cmap='seismic', vmin=-zlim, vmax=zlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "30693b08-cae7-462e-8b6e-726491d75a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14a1a8ce2e20>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZCklEQVR4nO3df2xVhd3H8c+F2lul7UWQYvv0Ag0S+VFA1jJXwPkDbdIg0S1juiCrY/7RWX7ZmDn0D81+cNkfW3RxNisj3QjBkmWCLBtgyaS4sW6l2sjQIAxiOwEJRO5t+zwcHtrz/PN4YweUnkO/PZzyfiU32b071/OR1L45vW1vxHVdVwAADLIRQQ8AAAxPBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJjIGOoT9vb26sSJE8rJyVEkEhnq0wMAroHruurs7FRBQYFGjOj/GmXIA3PixAnF4/GhPi0AYBB1dHSosLCw32OGPDA5OTmSpI6mJuVmZw/16a/N+fNBL/Bn796gF/iXMeQfooPjKn+zu279938HvcCf/PygF/g3Y0bQCzxJdXcrXl6e/lzenyH/r/fzL4vlZmeHLzBh/WSXlRX0Av/C+mc+cmTQC/zp7Q16gT+33BL0Av/C9nnw/w3kJY6Q/jULAHC9IzAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADAhK/AvPbaayoqKlJWVpZKSkr0zjvvDPYuAEDIeQ7M1q1btWbNGr3wwgt67733dM8996iiokLt7e0W+wAAIeU5MD//+c/13e9+V0899ZSmTZuml19+WfF4XLW1tRb7AAAh5SkwFy5cUGtrq8rLy/s8Xl5erv3791/2OY7jKJVK9bkBAIY/T4E5c+aMenp6NH78+D6Pjx8/XqdOnbrscxKJhGKxWPoWj8f9rwUAhIavF/kjkUif+67rXvLY59auXatkMpm+dXR0+DklACBkMrwcfNttt2nkyJGXXK2cPn36kquaz0WjUUWjUf8LAQCh5OkKJjMzUyUlJWpsbOzzeGNjo+bNmzeowwAA4ebpCkaSampqtGzZMpWWlqqsrEx1dXVqb29XVVWVxT4AQEh5Dsxjjz2ms2fP6oc//KFOnjyp4uJi/elPf9LEiRMt9gEAQspzYCTp6aef1tNPPz3YWwAAwwi/iwwAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCY8PV+MDesjo6gF/gTjQa9wL+bbw56gT9dXUEv8Gf06KAX+BPWj5NhjisYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACY8B2bfvn1avHixCgoKFIlEtH37doNZAICw8xyY7u5uzZ49W6+++qrFHgDAMJHh9QkVFRWqqKiw2AIAGEY8B8Yrx3HkOE76fiqVsj4lAOA6YP4ifyKRUCwWS9/i8bj1KQEA1wHzwKxdu1bJZDJ96+josD4lAOA6YP4lsmg0qmg0an0aAMB1hp+DAQCY8HwF09XVpaNHj6bvHz9+XG1tbRozZowmTJgwqOMAAOHlOTAHDhzQ/fffn75fU1MjSaqsrNRvfvObQRsGAAg3z4G577775LquxRYAwDDCazAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADAhOf3g7mhOU7QC/zp7g56gX9h3d7VFfQCf8K6e+HCoBf4lxGyT8Me9nIFAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMCEp8AkEgnNnTtXOTk5ysvL06OPPqrDhw9bbQMAhJinwDQ1Nam6ulrNzc1qbGzUxYsXVV5eru7ubqt9AICQyvBy8K5du/rcr6+vV15enlpbW/XVr351UIcBAMLNU2D+UzKZlCSNGTPmisc4jiPHcdL3U6nUtZwSABASvl/kd11XNTU1WrBggYqLi694XCKRUCwWS9/i8bjfUwIAQsR3YFasWKH3339fr7/+er/HrV27VslkMn3r6Ojwe0oAQIj4+hLZypUrtWPHDu3bt0+FhYX9HhuNRhWNRn2NAwCEl6fAuK6rlStXatu2bdq7d6+KioqsdgEAQs5TYKqrq7Vlyxa9+eabysnJ0alTpyRJsVhMN998s8lAAEA4eXoNpra2VslkUvfdd5/y8/PTt61bt1rtAwCElOcvkQEAMBD8LjIAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEx4esOxG965c0Ev8Of8+aAX+BfW7VlZQS/wp7Aw6AX+dHcHvcC/jJB9GvawlysYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAw4SkwtbW1mjVrlnJzc5Wbm6uysjLt3LnTahsAIMQ8BaawsFDr16/XgQMHdODAAT3wwAN65JFHdOjQIat9AICQyvBy8OLFi/vc/8lPfqLa2lo1NzdrxowZgzoMABBungLzRT09Pfrd736n7u5ulZWVXfE4x3HkOE76fiqV8ntKAECIeH6R/+DBg8rOzlY0GlVVVZW2bdum6dOnX/H4RCKhWCyWvsXj8WsaDAAIB8+BufPOO9XW1qbm5mZ973vfU2VlpT744IMrHr927Volk8n0raOj45oGAwDCwfOXyDIzM3XHHXdIkkpLS9XS0qJXXnlFv/rVry57fDQaVTQavbaVAIDQueafg3Fdt89rLAAASB6vYJ5//nlVVFQoHo+rs7NTDQ0N2rt3r3bt2mW1DwAQUp4C8+mnn2rZsmU6efKkYrGYZs2apV27dumhhx6y2gcACClPgdm4caPVDgDAMMPvIgMAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwISnNxy74UWjQS/wJzs76AX+hXX7xYtBL/AnrB/j//u/QS/AZXAFAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJq4pMIlEQpFIRGvWrBmkOQCA4cJ3YFpaWlRXV6dZs2YN5h4AwDDhKzBdXV1aunSpNmzYoFtvvXWwNwEAhgFfgamurtaiRYv04IMPDvYeAMAwkeH1CQ0NDXr33XfV0tIyoOMdx5HjOOn7qVTK6ykBACHk6Qqmo6NDq1ev1ubNm5WVlTWg5yQSCcVisfQtHo/7GgoACJeI67ruQA/evn27vva1r2nkyJHpx3p6ehSJRDRixAg5jtPn/5MufwUTj8eVbG1Vbnb2IPwrDKEBXrVddz79NOgFN56LF4Ne4M+oUUEv8Gf06KAX+Dd3btALPEl1dSlWUqJkMqnc3Nx+j/X0JbKFCxfq4MGDfR77zne+o6lTp+q55567JC6SFI1GFY1GvZwGADAMeApMTk6OiouL+zw2atQojR079pLHAQA3Nn6SHwBgwvN3kf2nvXv3DsIMAMBwwxUMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmrvkNx24oo0cHvcCfv/416AX+ZWUFvcCfwsKgF/jT0xP0An8cJ+gFuAyuYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCY8BSYl156SZFIpM/t9ttvt9oGAAixDK9PmDFjhvbs2ZO+P3LkyEEdBAAYHjwHJiMjg6sWAMBVeX4N5siRIyooKFBRUZEef/xxHTt2rN/jHcdRKpXqcwMADH+eAnP33Xdr06ZN2r17tzZs2KBTp05p3rx5Onv27BWfk0gkFIvF0rd4PH7NowEA17+I67qu3yd3d3dr8uTJ+v73v6+amprLHuM4jhzHSd9PpVKKx+NKtrYqNzvb76mDceRI0Av8+eMfg17gX1ZW0Av8KSwMeoE/GZ6/an59CNvnki9asCDoBZ6kuroUKylRMplUbm5uv8de00fTqFGjNHPmTB3p5xNvNBpVNBq9ltMAAELomn4OxnEcffjhh8rPzx+sPQCAYcJTYJ599lk1NTXp+PHj+vvf/65vfOMbSqVSqqystNoHAAgpT18i+/e//61vfetbOnPmjMaNG6evfOUram5u1sSJE632AQBCylNgGhoarHYAAIYZfhcZAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMOHp/WBueLfeGvQCf6ZODXqBf+fPB73An66uoBf4k5UV9AJ/xo4NeoF/Fy8GvcAbD3u5ggEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBgwnNgPvnkEz3xxBMaO3asbrnlFt11111qbW212AYACLEMLwd/9tlnmj9/vu6//37t3LlTeXl5+te//qXRo0cbzQMAhJWnwPz0pz9VPB5XfX19+rFJkyYN9iYAwDDg6UtkO3bsUGlpqZYsWaK8vDzNmTNHGzZs6Pc5juMolUr1uQEAhj9PgTl27Jhqa2s1ZcoU7d69W1VVVVq1apU2bdp0xeckEgnFYrH0LR6PX/NoAMD1L+K6rjvQgzMzM1VaWqr9+/enH1u1apVaWlr0t7/97bLPcRxHjuOk76dSKcXjcSVbW5WbnX0N0wNw5kzQC/w5cCDoBf6dPx/0An/CujsrK+gF/vzXfwW9wL85c4Je4Emqq0uxu+9WMplUbm5uv8d6uoLJz8/X9OnT+zw2bdo0tbe3X/E50WhUubm5fW4AgOHPU2Dmz5+vw4cP93nso48+0sSJEwd1FAAg/DwF5plnnlFzc7PWrVuno0ePasuWLaqrq1N1dbXVPgBASHkKzNy5c7Vt2za9/vrrKi4u1o9+9CO9/PLLWrp0qdU+AEBIefo5GEl6+OGH9fDDD1tsAQAMI/wuMgCACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATHh+w7EbWnZ20Av8uXgx6AX+jRoV9AJ/MkL6n9a5c0Ev8Mdxgl7g3/nzQS/wxsNermAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMCEp8BMmjRJkUjkklt1dbXVPgBASHl64/CWlhb19PSk7//zn//UQw89pCVLlgz6MABAuHkKzLhx4/rcX79+vSZPnqx77713UEcBAMLPU2C+6MKFC9q8ebNqamoUiUSueJzjOHIcJ30/lUr5PSUAIER8v8i/fft2nTt3Tk8++WS/xyUSCcVisfQtHo/7PSUAIER8B2bjxo2qqKhQQUFBv8etXbtWyWQyfevo6PB7SgBAiPj6EtnHH3+sPXv26I033rjqsdFoVNFo1M9pAAAh5usKpr6+Xnl5eVq0aNFg7wEADBOeA9Pb26v6+npVVlYqI8P39wgAAIY5z4HZs2eP2tvbtXz5cos9AIBhwvMlSHl5uVzXtdgCABhG+F1kAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwMSQvyXl5+8lk+rqGupTX7vz54Ne4E9Yd0tSb2/QC/y5cCHoBf44TtAL/Pmf/wl6gX8h+1yY6u6WpAG9L9iQB6azs1OSFL/33qE+NQBgkHR2dioWi/V7TMQd4ren7O3t1YkTJ5STk6NIJDKo/+xUKqV4PK6Ojg7l5uYO6j/bEruHFruHXli3s/tSruuqs7NTBQUFGjGi/1dZhvwKZsSIESosLDQ9R25ubqg+GD7H7qHF7qEX1u3s7utqVy6f40V+AIAJAgMAMDGsAhONRvXiiy8qGo0GPcUTdg8tdg+9sG5n97UZ8hf5AQA3hmF1BQMAuH4QGACACQIDADBBYAAAJoZNYF577TUVFRUpKytLJSUleuedd4KedFX79u3T4sWLVVBQoEgkou3btwc9aUASiYTmzp2rnJwc5eXl6dFHH9Xhw4eDnnVVtbW1mjVrVvqHz8rKyrRz586gZ3mWSCQUiUS0Zs2aoKf066WXXlIkEulzu/3224OeNSCffPKJnnjiCY0dO1a33HKL7rrrLrW2tgY966omTZp0yZ95JBJRdXV1IHuGRWC2bt2qNWvW6IUXXtB7772ne+65RxUVFWpvbw96Wr+6u7s1e/Zsvfrqq0FP8aSpqUnV1dVqbm5WY2OjLl68qPLycnX//y/Bu14VFhZq/fr1OnDggA4cOKAHHnhAjzzyiA4dOhT0tAFraWlRXV2dZs2aFfSUAZkxY4ZOnjyZvh08eDDoSVf12Wefaf78+brpppu0c+dOffDBB/rZz36m0aNHBz3tqlpaWvr8eTc2NkqSlixZEswgdxj48pe/7FZVVfV5bOrUqe4PfvCDgBZ5J8ndtm1b0DN8OX36tCvJbWpqCnqKZ7feeqv761//OugZA9LZ2elOmTLFbWxsdO+991539erVQU/q14svvujOnj076BmePffcc+6CBQuCnjEoVq9e7U6ePNnt7e0N5Pyhv4K5cOGCWltbVV5e3ufx8vJy7d+/P6BVN5ZkMilJGjNmTMBLBq6np0cNDQ3q7u5WWVlZ0HMGpLq6WosWLdKDDz4Y9JQBO3LkiAoKClRUVKTHH39cx44dC3rSVe3YsUOlpaVasmSJ8vLyNGfOHG3YsCHoWZ5duHBBmzdv1vLlywf9FwsPVOgDc+bMGfX09Gj8+PF9Hh8/frxOnToV0Kobh+u6qqmp0YIFC1RcXBz0nKs6ePCgsrOzFY1GVVVVpW3btmn69OlBz7qqhoYGvfvuu0okEkFPGbC7775bmzZt0u7du7VhwwadOnVK8+bN09mzZ4Oe1q9jx46ptrZWU6ZM0e7du1VVVaVVq1Zp06ZNQU/zZPv27Tp37pyefPLJwDYM+W9TtvKfhXZdN7Bq30hWrFih999/X3/5y1+CnjIgd955p9ra2nTu3Dn9/ve/V2VlpZqamq7ryHR0dGj16tV66623lJWVFfScAauoqEj/75kzZ6qsrEyTJ0/Wb3/7W9XU1AS4rH+9vb0qLS3VunXrJElz5szRoUOHVFtbq29/+9sBrxu4jRs3qqKiQgUFBYFtCP0VzG233aaRI0decrVy+vTpS65qMLhWrlypHTt26O233zZ/C4bBkpmZqTvuuEOlpaVKJBKaPXu2XnnllaBn9au1tVWnT59WSUmJMjIylJGRoaamJv3iF79QRkaGenp6gp44IKNGjdLMmTN15MiRoKf0Kz8//5K/cEybNu26/6ahL/r444+1Z88ePfXUU4HuCH1gMjMzVVJSkv5uic81NjZq3rx5Aa0a3lzX1YoVK/TGG2/oz3/+s4qKioKe5JvrunKu87cJXrhwoQ4ePKi2trb0rbS0VEuXLlVbW5tGjhwZ9MQBcRxHH374ofLz84Oe0q/58+df8m33H330kSZOnBjQIu/q6+uVl5enRYsWBbpjWHyJrKamRsuWLVNpaanKyspUV1en9vZ2VVVVBT2tX11dXTp69Gj6/vHjx9XW1qYxY8ZowoQJAS7rX3V1tbZs2aI333xTOTk56avHWCymm2++OeB1V/b888+roqJC8XhcnZ2damho0N69e7Vr166gp/UrJyfnkte3Ro0apbFjx17Xr3s9++yzWrx4sSZMmKDTp0/rxz/+sVKplCorK4Oe1q9nnnlG8+bN07p16/TNb35T//jHP1RXV6e6urqgpw1Ib2+v6uvrVVlZqYyMgD/FB/K9awZ++ctfuhMnTnQzMzPdL33pS6H4ltm3337blXTJrbKyMuhp/brcZklufX190NP6tXz58vTHyLhx49yFCxe6b731VtCzfAnDtyk/9thjbn5+vnvTTTe5BQUF7te//nX30KFDQc8akD/84Q9ucXGxG41G3alTp7p1dXVBTxqw3bt3u5Lcw4cPBz3F5df1AwBMhP41GADA9YnAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMPF/+Wy97AxqIE4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zlim = 2\n",
    "plt.imshow(np.linalg.norm(mat_W,axis=1).reshape(8,8), cmap='seismic', vmin=-zlim, vmax=zlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3de1e6c8-84c6-4be4-bc45-e426d2b6cf6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14a13bb7f5b0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zlim=1\n",
    "plt.imshow(np.linalg.norm(WLL[1200][0],axis=1).reshape(8,8), cmap='seismic', vmin=-zlim, vmax=zlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "70d1e96f-7f5c-4b5c-8d65-6930fc2091a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nh=300 finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Nh={0} finished\".format(Nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57a85e52-3f5a-4537-8419-7a6c54c30c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nh=100 finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Nh={0} finished\".format(Nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6714777d-a89c-4331-9176-8a04e780f561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nh=100 finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Nh={0} finished\".format(Nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f79694e-f223-4823-b90b-2935851e7eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nh=20 finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Nh={0} finished\".format(Nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a77c2381-c348-41ef-b70a-8b2a79c71a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nh=20 finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Nh={0} finished\".format(Nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d5e94a9-a064-488a-8a19-fbad288ae5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 200x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PP = np.zeros(10)\n",
    "PP[7] = 1\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(2,0.5))\n",
    "x = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "ax.set_xlim(0,10)\n",
    "ax.bar(x, PP)\n",
    "fig.savefig('stddist.pdf', bbox_inches='tight', dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487f708-9b73-40a1-9985-7a45d05e4487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "EqProp2",
   "language": "python",
   "name": "eqprop2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
